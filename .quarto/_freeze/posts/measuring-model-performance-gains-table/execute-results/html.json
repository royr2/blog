{
  "hash": "7273dcda76f7d4fc44d357e1f1e5cb46",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Measuring Model Performance Using a Gains Table\"\ndate: \"2024-01-28\"\ncategories: [R, Credit Risk Analytics, Model Evaluation]\nimage: \"../images/gains.png\"\nexecute:\n  echo: true\n  warning: false\n  message: false\n  eval: true\n---\n\n\n\n# Measuring Model Performance Using a Gains Table\n\nIn credit risk modeling, analysts often use a tool called a **gains table** (or KS table) to measure and quantify the performance of classification models. This post explores how to build and interpret such a table using R.\n\n## What is a Gains Table?\n\nA gains table discretizes the population (typically a test or validation set) into groups based on the model's output (probability, log odds, or scores). Usually, each group represents 10% of the total population (deciles). The table then presents summary statistics for each group and analyzes the cumulative distributions of events (defaults) and non-events to quantify the model's performance.\n\n## Required Libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(scales)\n```\n:::\n\n\n\n## Sample Dataset\n\nWe'll use a sample from the Lending Club dataset, which contains information about loans and their outcomes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the sample data\nsample <- read.csv(\"https://bit.ly/42ypcnJ\")\n\n# Check dimensions\ndim(sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000   153\n```\n\n\n:::\n:::\n\n\n\n## Defining the Target Variable\n\nFirst, we need to create a target (outcome) variable to model. Since this is a credit risk use case, we'll identify borrowers who defaulted on their payments.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check unique loan statuses\nunique(sample$loan_status)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Fully Paid\"                                         \n[2] \"Current\"                                            \n[3] \"Charged Off\"                                        \n[4] \"Late (31-120 days)\"                                 \n[5] \"Late (16-30 days)\"                                  \n[6] \"In Grace Period\"                                    \n[7] \"Does not meet the credit policy. Status:Fully Paid\" \n[8] \"Does not meet the credit policy. Status:Charged Off\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Define \"bad\" loans as those that are charged off\ncodes <- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\n\n# Create a binary flag for defaults\nsample %<>% mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))\n\n# Check overall event rates\nsample %>% \n  summarise(events = sum(bad_flag == 1), \n            non_events = sum(bad_flag == 0)) %>% \n  mutate(event_rate = events/(events + non_events))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  events non_events event_rate\n1   1162       8838     0.1162\n```\n\n\n:::\n:::\n\n\n\n## Building a Simple Model\n\nNext, let's build a quick model, the output of which we'll use to create the gains table.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Replace NA values with a default value\nsample[is.na(sample)] <- -1\n\n# Clean the data\nsample %<>% \n  # Remove cases where home ownership and payment plan are not reported\n  filter(!home_ownership %in% c(\"\", \"NONE\"),\n         pymnt_plan != \"\") %>% \n  # Convert categorical variables to factors\n  mutate(home_ownership = factor(home_ownership), \n         pymnt_plan = factor(pymnt_plan))\n\n# Train-test split (70-30)\nidx <- sample(1:nrow(sample), size = 0.7 * nrow(sample), replace = FALSE)\ntrain <- sample[idx,]\ntest <- sample[-idx,]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build a logistic regression model\nmdl <- glm(\n  formula = bad_flag ~ \n    loan_amnt + term + mths_since_last_delinq + total_pymnt + \n    home_ownership + acc_now_delinq + \n    inq_last_6mths + delinq_amnt + \n    mths_since_last_record + mths_since_recent_revol_delinq + \n    mths_since_last_major_derog + mths_since_recent_inq + \n    mths_since_recent_bc + num_accts_ever_120_pd,\n  family = \"binomial\", \n  data = train\n)\n\n# Generate predictions on the test set\ntest$pred <- predict(mdl, newdata = test)\n```\n:::\n\n\n\n## Creating the Gains Table\n\nNow let's build the gains table step by step:\n\n### Step 1: Discretize Predictions into Bins\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create deciles based on model predictions\nq <- quantile(test$pred, probs = seq(0, 1, length.out = 11))\n\n# Add bins to test dataset\ntest$bins <- cut(test$pred, breaks = q, include.lowest = TRUE, \n                right = TRUE, ordered_result = TRUE)\n\n# Check the bin levels (note they're in increasing order)\nlevels(test$bins)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"[-5.37,-3.3]\"  \"(-3.3,-2.9]\"   \"(-2.9,-2.66]\"  \"(-2.66,-2.45]\"\n [5] \"(-2.45,-2.25]\" \"(-2.25,-2.07]\" \"(-2.07,-1.86]\" \"(-1.86,-1.61]\"\n [9] \"(-1.61,-1.23]\" \"(-1.23,1.6]\"  \n```\n\n\n:::\n:::\n\n\n\n### Step 2: Calculate Basic Statistics for Each Bin\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create initial gains table with counts\ngains_table <- test %>% \n  group_by(bins) %>% \n  summarise(total = n(), \n            events = sum(bad_flag == 1), \n            non_events = sum(bad_flag == 0))\n\n# Add event rate column\ngains_table %<>%\n  mutate(event_rate = percent(events / total, 0.1, 100))\n\n# Display the table\nkable(gains_table)\n```\n\n::: {.cell-output-display}\n\n\n|bins          | total| events| non_events|event_rate |\n|:-------------|-----:|------:|----------:|:----------|\n|[-5.37,-3.3]  |   300|      5|        295|1.7%       |\n|(-3.3,-2.9]   |   300|      8|        292|2.7%       |\n|(-2.9,-2.66]  |   300|      8|        292|2.7%       |\n|(-2.66,-2.45] |   300|     11|        289|3.7%       |\n|(-2.45,-2.25] |   300|     22|        278|7.3%       |\n|(-2.25,-2.07] |   300|     34|        266|11.3%      |\n|(-2.07,-1.86] |   300|     56|        244|18.7%      |\n|(-1.86,-1.61] |   300|     65|        235|21.7%      |\n|(-1.61,-1.23] |   300|     59|        241|19.7%      |\n|(-1.23,1.6]   |   300|     75|        225|25.0%      |\n\n\n:::\n:::\n\n\n\n### Step 3: Add Distribution Metrics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add population percentage and cumulative distributions\ngains_table %<>%\n  mutate(pop_pct = percent(total/sum(total), 0.1, 100), \n         \n         # Calculate cumulative percentages\n         c.events_pct = cumsum(events) / sum(events),\n         c.non_events_pct = cumsum(non_events) / sum(non_events))\n\n# Display the updated table\nkable(gains_table)\n```\n\n::: {.cell-output-display}\n\n\n|bins          | total| events| non_events|event_rate |pop_pct | c.events_pct| c.non_events_pct|\n|:-------------|-----:|------:|----------:|:----------|:-------|------------:|----------------:|\n|[-5.37,-3.3]  |   300|      5|        295|1.7%       |10.0%   |    0.0145773|        0.1110275|\n|(-3.3,-2.9]   |   300|      8|        292|2.7%       |10.0%   |    0.0379009|        0.2209259|\n|(-2.9,-2.66]  |   300|      8|        292|2.7%       |10.0%   |    0.0612245|        0.3308242|\n|(-2.66,-2.45] |   300|     11|        289|3.7%       |10.0%   |    0.0932945|        0.4395935|\n|(-2.45,-2.25] |   300|     22|        278|7.3%       |10.0%   |    0.1574344|        0.5442228|\n|(-2.25,-2.07] |   300|     34|        266|11.3%      |10.0%   |    0.2565598|        0.6443357|\n|(-2.07,-1.86] |   300|     56|        244|18.7%      |10.0%   |    0.4198251|        0.7361686|\n|(-1.86,-1.61] |   300|     65|        235|21.7%      |10.0%   |    0.6093294|        0.8246142|\n|(-1.61,-1.23] |   300|     59|        241|19.7%      |10.0%   |    0.7813411|        0.9153180|\n|(-1.23,1.6]   |   300|     75|        225|25.0%      |10.0%   |    1.0000000|        1.0000000|\n\n\n:::\n:::\n\n\n\n### Step 4: Add Performance Metrics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add KS statistic, capture rate, and cumulative event rate\ngains_table %<>%\n  mutate(\n    # KS statistic (difference between cumulative distributions)\n    ks = round(abs(c.events_pct - c.non_events_pct), 2), \n    \n    # Capture rate (percentage of total events captured)\n    cap_rate = percent(cumsum(events)/sum(events), 1, 100), \n    \n    # Cumulative event rate\n    c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), \n    \n    # Format percentage columns\n    c.events_pct = percent(c.events_pct, 0.1, 100),\n    c.non_events_pct = percent(c.non_events_pct, 0.1, 100))\n\n# Display the final table\nkable(gains_table)\n```\n\n::: {.cell-output-display}\n\n\n|bins          | total| events| non_events|event_rate |pop_pct |c.events_pct |c.non_events_pct |   ks|cap_rate |c_event_rate |\n|:-------------|-----:|------:|----------:|:----------|:-------|:------------|:----------------|----:|:--------|:------------|\n|[-5.37,-3.3]  |   300|      5|        295|1.7%       |10.0%   |1.5%         |11.1%            | 0.10|1%       |1.7%         |\n|(-3.3,-2.9]   |   300|      8|        292|2.7%       |10.0%   |3.8%         |22.1%            | 0.18|4%       |2.2%         |\n|(-2.9,-2.66]  |   300|      8|        292|2.7%       |10.0%   |6.1%         |33.1%            | 0.27|6%       |2.3%         |\n|(-2.66,-2.45] |   300|     11|        289|3.7%       |10.0%   |9.3%         |44.0%            | 0.35|9%       |2.7%         |\n|(-2.45,-2.25] |   300|     22|        278|7.3%       |10.0%   |15.7%        |54.4%            | 0.39|16%      |3.6%         |\n|(-2.25,-2.07] |   300|     34|        266|11.3%      |10.0%   |25.7%        |64.4%            | 0.39|26%      |4.9%         |\n|(-2.07,-1.86] |   300|     56|        244|18.7%      |10.0%   |42.0%        |73.6%            | 0.32|42%      |6.9%         |\n|(-1.86,-1.61] |   300|     65|        235|21.7%      |10.0%   |60.9%        |82.5%            | 0.22|61%      |8.7%         |\n|(-1.61,-1.23] |   300|     59|        241|19.7%      |10.0%   |78.1%        |91.5%            | 0.13|78%      |9.9%         |\n|(-1.23,1.6]   |   300|     75|        225|25.0%      |10.0%   |100.0%       |100.0%           | 0.00|100%     |11.4%        |\n\n\n:::\n:::\n\n\n\n## Creating a Reusable Function\n\nLet's encapsulate all the above steps into a single function that can be reused for any binary classification model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngains_table <- function(act, pred, increasing = TRUE, nBins = 10) {\n  \n  # Create bins based on predictions\n  q <- quantile(pred, probs = seq(0, 1, length.out = nBins + 1))\n  bins <- cut(pred, breaks = q, include.lowest = TRUE, right = TRUE, ordered_result = TRUE)\n  \n  df <- data.frame(act, pred, bins)\n  \n  df %>% \n    # Group by bins and calculate statistics\n    group_by(bins) %>% \n    summarise(total = n(), \n              events = sum(act == 1), \n              non_events = sum(act == 0)) %>% \n    mutate(event_rate = percent(events / total, 0.1, 100)) %>% \n    \n    # Sort the table based on the 'increasing' parameter\n    {if(increasing == TRUE) {\n      arrange(., bins)\n    } else {\n      arrange(., desc(bins))\n    }} %>% \n    \n    # Add all performance metrics\n    mutate(pop_pct = percent(total/sum(total), 0.1, 100), \n           c.events_pct = cumsum(events) / sum(events),\n           c.non_events_pct = cumsum(non_events) / sum(non_events), \n           ks = round(abs(c.events_pct - c.non_events_pct), 2), \n           cap_rate = percent(cumsum(events)/sum(events), 1, 100), \n           c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), \n           c.events_pct = percent(c.events_pct, 0.1, 100),\n           c.non_events_pct = percent(c.non_events_pct, 0.1, 100))\n}\n```\n:::\n\n\n\n### Using the Function\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate a gains table with bins in descending order\ntab <- gains_table(test$bad_flag, test$pred, FALSE, 10)\nkable(tab)\n```\n\n::: {.cell-output-display}\n\n\n|bins          | total| events| non_events|event_rate |pop_pct |c.events_pct |c.non_events_pct |   ks|cap_rate |c_event_rate |\n|:-------------|-----:|------:|----------:|:----------|:-------|:------------|:----------------|----:|:--------|:------------|\n|(-1.23,1.6]   |   300|     75|        225|25.0%      |10.0%   |21.9%        |8.5%             | 0.13|22%      |25.0%        |\n|(-1.61,-1.23] |   300|     59|        241|19.7%      |10.0%   |39.1%        |17.5%            | 0.22|39%      |22.3%        |\n|(-1.86,-1.61] |   300|     65|        235|21.7%      |10.0%   |58.0%        |26.4%            | 0.32|58%      |22.1%        |\n|(-2.07,-1.86] |   300|     56|        244|18.7%      |10.0%   |74.3%        |35.6%            | 0.39|74%      |21.2%        |\n|(-2.25,-2.07] |   300|     34|        266|11.3%      |10.0%   |84.3%        |45.6%            | 0.39|84%      |19.3%        |\n|(-2.45,-2.25] |   300|     22|        278|7.3%       |10.0%   |90.7%        |56.0%            | 0.35|91%      |17.3%        |\n|(-2.66,-2.45] |   300|     11|        289|3.7%       |10.0%   |93.9%        |66.9%            | 0.27|94%      |15.3%        |\n|(-2.9,-2.66]  |   300|      8|        292|2.7%       |10.0%   |96.2%        |77.9%            | 0.18|96%      |13.8%        |\n|(-3.3,-2.9]   |   300|      8|        292|2.7%       |10.0%   |98.5%        |88.9%            | 0.10|99%      |12.5%        |\n|[-5.37,-3.3]  |   300|      5|        295|1.7%       |10.0%   |100.0%       |100.0%           | 0.00|100%     |11.4%        |\n\n\n:::\n:::\n\n\n\n## Interpreting the Gains Table\n\nA gains table provides several key insights into model performance:\n\n1. **Monotonicity**: The event rates should consistently increase (or decrease) across bins. This confirms that the model effectively rank-orders risk.\n\n2. **Bin Consistency**: If bin sizes are not consistent (ideally ~10% each), it suggests the model is assigning the same output/score to many borrowers (clumping), which could pose issues when deciding cutoffs.\n\n3. **KS Statistic**: The maximum value of the KS column indicates the model's discriminatory power. A higher value (closer to 1) indicates better separation between good and bad borrowers.\n\n4. **Capture Rate**: Shows what percentage of all bad accounts are captured at each cutoff point.\n\n5. **Cumulative Event Rate**: Indicates the bad rate among all accounts up to that bin, useful for setting approval thresholds.\n\n## Practical Applications\n\nIn credit risk management, the gains table helps with:\n\n1. **Setting Cutoffs**: Identifying appropriate score thresholds for approving or rejecting applications.\n\n2. **Strategy Development**: Creating tiered strategies (e.g., approve, review, decline) based on risk levels.\n\n3. **Performance Monitoring**: Tracking model performance over time by comparing actual vs. expected distributions.\n\n4. **Model Comparison**: Evaluating different models by comparing their KS statistics and capture rates.\n\nThe gains table is a powerful tool for evaluating binary classification models, especially in credit risk applications. By providing a structured view of how well a model separates good and bad cases across the score distribution, it helps analysts make informed decisions about model quality and operational implementation.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}