{
  "hash": "57f97db86a7273e3c8ba46c879d8b275",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Optimising Approval Rates for Credit Applications\"\ndate: \"2025-03-30\"\ncategories: [R, Credit Risk Analytics, Optimization]\nimage: \"../images/approval_rates.png\"\nexecute:\n  echo: true\n  warning: false\n  message: false\n  eval: true\n---\n\n\n\n\n# Optimising Approval Rates with Segmented Models\n\nIn credit risk modeling, finding the right balance between approval rates and risk is a constant challenge. Financial institutions aim to approve as many creditworthy applicants as possible while maintaining acceptable risk levels. This post demonstrates how developing segmented models can significantly improve this balance compared to using a single population-wide model.\n\nWhile segmentation offers many benefits in credit risk modeling, this post focuses specifically on how it can optimize approval rates without increasing risk exposure. I'll show a practical example using lending data to illustrate the concept.\n\nThe sample dataset used in this analysis is available for download from [GitHub](https://github.com/royr2/blog/blob/main/download/credit_sample.csv), and I'll be building on techniques covered in my previous post on gains tables.\n\n## Required Packages\n\nFirst, let's load the R packages we'll need for our analysis:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(dplyr)     # For data manipulation\nlibrary(magrittr)  # For pipe operators\nlibrary(scales)    # For formatting percentages in plots\nlibrary(pROC)      # For ROC curve analysis\n```\n:::\n\n\n\n\n## Sample Data Preparation\n\nNext, we'll load and prepare our sample dataset, which contains loan application information:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load sample loan data from GitHub\nsmple <- read.csv(\"https://bit.ly/42ypcnJ\")\n\n# Define target variable (1 = bad loan, 0 = good loan)\n# Bad loans are those that were charged off or failed to meet credit policy\ncodes <- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\nsmple %<>% mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))\n\n# Basic data cleaning steps\n# Replace missing values with -1 (a common practice in credit scoring)\nsmple[is.na(smple)] <- -1\n\n# Remove records with missing or invalid categorical values\nsmple %<>% \n  filter(!home_ownership %in% c(\"\", \"NONE\"),  # Remove missing home ownership\n         pymnt_plan != \"\") %>%                 # Remove missing payment plan\n  \n  # Convert categorical variables to factors for modeling\n  mutate(home_ownership = factor(home_ownership), \n         pymnt_plan = factor(pymnt_plan))\n```\n:::\n\n\n\n\n## Creating Segments\n\nIn credit risk modeling, segmentation is a common practice to group customers with similar risk profiles. Typical segments might include \"known goods,\" \"known bads,\" \"thin files,\" or \"new-to-credit\" customers.\n\nFor this demonstration, we'll use the FICO score (a widely used credit score in the US) to create simple segments:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create segments based on FICO score ranges\nsmple %<>%\n  mutate(segment = case_when(\n    fico_range_low >= 700 ~ \"KG\",  # Known Good (high FICO score)\n    fico_range_low <= 600 ~ \"KB\",  # Known Bad (low FICO score)\n    TRUE ~ \"Others\"                # Middle range FICO scores\n  ))\n\n# Check the distribution of records across segments\ntable(smple$segment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    KG Others \n  4211   5788 \n```\n\n\n:::\n:::\n\n\n\n\nFor this analysis, we'll focus on the \"Known Good\" (KG) segment. In practice, most lenders would apply policy filters to automatically reject applicants with very poor credit histories (the KB segment), so optimizing the approval strategy for the better-quality segments often yields the most business value.\n\n## Building Models\n\nTo demonstrate the value of segmentation, we'll build two logistic regression models:\n\n1. **Population model**: Built using all available data\n2. **Segment model**: Built specifically for the \"Known Good\" segment\n\nBoth models will use the same set of predictors, but the segment model will be trained only on data from the KG segment:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build a population-wide model using all data\nmdl_pop <- glm(bad_flag ~ annual_inc + dti + home_ownership + purpose + term, \n               data = smple,                  # Using all data\n               family = \"binomial\")           # Logistic regression\n\n# Build a segment-specific model for Known Good customers only\nmdl_seg <- glm(bad_flag ~ annual_inc + dti + home_ownership + purpose + term, \n               data = filter(smple, segment == \"KG\"),  # Using only KG segment\n               family = \"binomial\") \n\n# Define a function to convert log-odds to credit score range (300-850)\n# This makes the model outputs more interpretable\nscaling_func <- function(x, min_score = 300, max_score = 850) {\n  # Transform log-odds to probability, then scale to credit score range\n  # Higher scores indicate lower risk of default\n  scaled_score <- min_score + (max_score - min_score) * \n                  (1 - (1 / (1 + exp(-x))))\n  return(scaled_score)\n}\n```\n:::\n\n\n\n\nThe models use several common credit risk predictors:\n- `annual_inc`: Annual income\n- `dti`: Debt-to-income ratio\n- `home_ownership`: Housing status (own, rent, etc.)\n- `purpose`: Loan purpose\n- `term`: Loan term length\n\n## Comparing Model Performance\n\nTo evaluate the benefit of segmentation, we'll compare how both models perform specifically on the \"Known Good\" segment. The key question is: Can a segment-specific model approve more customers at the same risk level compared to a population-wide model?\n\nWe'll calculate performance metrics at different approval rate thresholds:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evaluate population model performance on the KG segment\npop_perf <- smple %>%\n  filter(segment == \"KG\") %>%                     # Focus on KG segment only\n  mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions\n         score = scaling_func(pred),             # Convert to credit score scale\n         total = n()) %>%                         # Total number of KG customers\n  arrange(desc(score)) %>%                        # Sort by score (best first)\n  mutate(cum_count = row_number(),               # Cumulative count\n         cum_pct = round(cum_count / total, 2),            # Approval rate\n         cum_bad = cumsum(bad_flag),             # Cumulative bad loans\n         cum_bad_rate = cum_bad / cum_count) %>% # Bad rate at each approval threshold\n  filter(cum_pct %in% seq(0.1, 1, 0.1))          # Sample at 10% intervals\n\n# Evaluate segment model performance on the KG segment\nseg_perf <- smple %>%\n  filter(segment == \"KG\") %>%                     # Same segment\n  mutate(pred = predict(mdl_seg, newdata = .),   # But using segment model\n         score = scaling_func(pred),\n         total = n()) %>%\n  arrange(desc(score)) %>%\n  mutate(cum_count = row_number(),\n         cum_pct = round(cum_count / total, 2),\n         cum_bad = cumsum(bad_flag),\n         cum_bad_rate = cum_bad / cum_count) %>%\n  filter(cum_pct %in% seq(0.1, 1, 0.1))\n```\n:::\n\n\n\n\nThis analysis creates performance tables for both models at different approval rate thresholds (10%, 20%, etc.). For each threshold, we calculate the corresponding bad rate - the percentage of approved applications that would result in default.\n\n## Visualizing the Results\n\nA visual comparison helps us clearly see the difference in performance between the two models:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine results from both models for plotting\npop_perf$model <- \"Population Model\"\nseg_perf$model <- \"Segment Model\"\ncombined <- rbind(pop_perf, seg_perf)\n\n# Create a line plot comparing bad rates at different approval thresholds\nlibrary(ggplot2)\nggplot(combined, aes(x = cum_pct, y = cum_bad_rate, color = model, group = model)) +\n  geom_line(size = 1) +                                  # Connect points with lines\n  geom_point(size = 3) +                                 # Add points at each threshold\n  scale_x_continuous(labels = percent_format(),         # Format x-axis as percentages\n                     breaks = seq(0, 1, 0.1)) +         # Show 10% increments\n  scale_y_continuous(labels = percent_format()) +       # Format y-axis as percentages\n  labs(x = \"Approval Rate\", \n       y = \"Bad Rate\",\n       title = \"Bad Rate by Approval Rate\",\n       subtitle = \"Comparison of Population vs. Segment Model\") +\n  theme_minimal() +                                     # Clean visual theme\n  theme(legend.title = element_blank(),                 # Remove legend title\n        legend.position = \"bottom\")                      # Position legend at bottom\n```\n\n::: {.cell-output-display}\n![](optimising-approval-rates_files/figure-html/visualization-1.png){width=672}\n:::\n:::\n\n\n\n\nThis plot shows the relationship between approval rates (x-axis) and bad rates (y-axis) for both models. Lower curves indicate better performance - the ability to approve more customers while maintaining lower bad rates.\n\n## Key Findings\n\nWhen we compare the performance of both models on the \"Known Good\" segment, several important insights emerge:\n\n1. **Improved risk-approval trade-off**: The segment model typically shows a lower bad rate at the same approval rate compared to the population model.\n\n2. **Business impact option 1 - Increase approvals**: Using the segment model, we can approve more customers while maintaining the same risk level. For example, if a lender has a maximum acceptable bad rate of 3%, the segment model might allow approving 70% of applicants versus only 60% with the population model.\n\n3. **Business impact option 2 - Reduce risk**: Alternatively, we can maintain the same approval rate but reduce the overall bad rate. This translates to fewer defaults and lower credit losses.\n\n4. **Better targeting**: The segment model better captures the specific risk factors relevant to the \"Known Good\" population, rather than being influenced by patterns in the overall population.\n\n## Why Segmentation Works\n\nSegmentation improves model performance for several technical and business reasons:\n\n1. **Different risk drivers**: Different customer segments often have fundamentally different risk drivers. For example, income might be highly predictive for new borrowers but less important for those with established credit histories. A segment-specific model can focus on the variables most relevant to that particular group.\n\n2. **Coefficient stability**: Even when the same variables are predictive across segments, their effect size (coefficients) can vary significantly. For instance, a high debt-to-income ratio might indicate moderate risk for homeowners but severe risk for renters. Segment models capture these nuanced relationships.\n\n3. **Improved discrimination**: By focusing on a more homogeneous population, segment-specific models can better distinguish between good and bad customers within that segment. This is particularly valuable in segments where the overall default rate is low, as in our \"Known Good\" example.\n\n4. **Business alignment**: Segments often naturally align with business processes, product offerings, or customer journeys. This makes segment-specific models easier to implement and explain to stakeholders.\n\n5. **Regulatory considerations**: In some jurisdictions, segmented models may help demonstrate fair lending practices by showing that different customer groups are evaluated using appropriate criteria.\n\n## Practical Implementation Considerations\n\nWhen implementing segmented models in a production environment, consider these best practices:\n\n1. **Segment definition**: Create segments that are stable, meaningful, and large enough to build robust models\n\n2. **Validation**: Thoroughly validate each segment model separately, as well as the overall strategy\n\n3. **Monitoring**: Implement segment-specific monitoring to detect population shifts or model degradation\n\n4. **Fallback strategy**: Develop a fallback approach for applications that don't clearly fit into defined segments\n\n## Conclusion\n\nBuilding segment-specific models can significantly improve approval rates while maintaining acceptable risk levels. In the competitive lending landscape, this approach provides a meaningful advantage by better aligning risk assessment with customer characteristics.\n\nThe example in this post demonstrates how a segment-specific model for \"Known Good\" customers can approve more applicants at the same risk level compared to a population-wide model. This translates directly to business value: more customers, higher revenue, and potentially lower credit losses.\n\nFor organizations looking to optimize their credit risk strategies, segmentation should be a key consideration in the modeling approach. The additional complexity is well justified by the improved performance and business outcomes.\n",
    "supporting": [
      "optimising-approval-rates_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}