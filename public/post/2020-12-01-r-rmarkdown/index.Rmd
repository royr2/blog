---
title: "Measuring model performance using a gains table"
subtitle: "Credit scoring series (Part 1)"
author: "royr2"
date: 2020-06-01
categories: ["R", "Credit Risk Analytics"]
tags: ["R", "dplyr", "credit scoring", "credirt risk"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```

Modelers/analysts developing credit scores generally use something known as the `gains table` (or a `ks table`) to measure and quantify the performance of such models. We'll explore how to build such a table in this post. 

The idea is simple - discretise the population under consideration (say the testing or validation set) into groups based on the model's output (probability/log odds/scores). Typically, this is done in a way such that each group represents 10% of the total population (or deciles). Post which summary statistics are generated for each group and  cumulative distributions of events and non-events are analysed. 

I'll show how to dow this using `dplyr` syntax. I recommend doing it this way since it's easier to read and if you are using `sparklyr` (say within a Hadoop + Spark setup), you don't need to make any changes to the code.


## Packages
Let's get package installation out of the way first

```{r eval = F}
# Pacman is a package management tool 
install.packages("pacman")
```


```{r message = F}
library(pacman)

# p_load automatically installs packages if needed
p_load(dplyr, magrittr, knitr, scales)
```

## Sample dataset

Here's some sample data to play around with. The data set is small sample of the `Lending Club dataset` available on [kaggle](https://www.kaggle.com/wordsforthewise/lending-club).

The file is available for download [here]({{site.url}}/download).

```{r echo = F}
sample <- read.csv("/Github/royr2/download/credit_sample.csv")
```

```{r eval = F}
sample <- read.csv("credit_sample.csv")
```

```{r}
dim(sample)
```

```{r}
class(sample)
```

## Defining a target
First, let's create a target to model for.

```{r}
unique(sample$loan_status)
```

```{r}
# For simplicity we'll just use 
# 1. "Charged Off"
# 2. "Does not meet the credit policy. Status:Charged Off"
codes <- c("Charged Off", "Does not meet the credit policy. Status:Charged Off")

# For details on the %<>% operator please look at the dcumentation for the magrittr 
# package. 
sample %<>% mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))
```

Let's also check for the overall event rates.
```{r}
sample %>% 
  summarise(events = sum(bad_flag == 1), 
            non_events = sum(bad_flag == 0)) %>% 
  mutate(event_rate = events/(events + non_events))
```

## Building a model
Next lets build a quick and dirty model, the output of which we will use to build the `gains table`.

```{r eval = F}
# Check out available features (not shown here for brevity)
colnames(sample)
```

We'll need to do some data cleaning first.
```{r}
# Replace all NA values with a default value
sample[is.na(sample)] <- -1

sample %<>% 
  
  # Remove cases where home ownership and payment plan are not reported
  filter(! home_ownership %in% c("", "NONE"),
         pymnt_plan != "") %>% 
  
  # Convert these two variables into factors
  mutate(home_ownership = factor(home_ownership), 
         pymnt_plan = factor(pymnt_plan))
```

```{r}
# Train Test split
idx <- sample(1:nrow(sample), size = 0.7 * nrow(sample), replace = F)
train <- sample[idx,]
test <- sample[-idx,]
```

```{r}
dim(train)
dim(test)
```

```{r}
# Using a GLM model for simplicity
mdl <- glm(
  formula = bad_flag ~ 
    loan_amnt + term + mths_since_last_delinq + 
    home_ownership + pymnt_plan + dti + dti_joint + 
    inq_last_6mths + delinq_amnt + 
    mths_since_last_record + mths_since_recent_revol_delinq + 
    mths_since_last_major_derog + mths_since_recent_inq + 
    mths_since_recent_bc + num_accts_ever_120_pd,
  family = "binomial", 
  data = train
)
```

While we are here, let's also attach the model predictions to the test dataset.
```{r}
test$pred <- predict(mdl, newdata = test)
```

## Creating the Gains Table
The table has a few important components:

- Bins in decreasing/increasing order of model output (probability/log odds/scores)
- Population percentages contained in each bin 
- Observed event rates in each bin 
- Cumulative events and non events distributions

```{r}
# Bin predictions based on quantiles
q <- quantile(test$pred, probs = seq(0, 1, length.out = 11))
test$bins <- cut(test$pred, breaks = q, include.lowest = T, right = T, ordered_result = T)
```

{{< alert "Note that the output from cut is arranged in increasing order of value" >}}

```{r}
levels(test$bins)
```

Using the bins we created above, we can now start to put the table together

```{r}
# Start with the test dataset and start to summarise
gains_table <- test %>% 
  group_by(bins) %>% 
  summarise(total = n(), 
            events = sum(bad_flag == 1), 
            non_events = sum(bad_flag == 0))
```

At this point the table should look something like this:
```{r}
kable(gains_table)
```

Next, we'll add the event rate columns. Let's also make the table presentable - I'll use the `percent()` function in the scales package to show numbers as percentages. 
```{r}
gains_table %<>%
  mutate(event_rate = percent(events / total, 0.1, 100))

kable(gains_table)
```

To this, we'll add some columns quantifying how events and non events are distributed across each bin.
```{r}
gains_table %<>%
  mutate(pop_pct = percent(total/sum(total), 0.1, 100), 
         
         # Not formatting these as percents just yet
         c.events_pct = cumsum(events) / sum(events),
         c.non_events_pct = cumsum(non_events) / sum(non_events))

kable(gains_table) 
```

Almost done - we just need a few more columns namely:

- A column computing the difference between the two cumulative distribution columns we computed previously. The maximum value of this column will become the primary performance metric nown as the `KS statistic`.
- Two additional columns computing the `event capture rates` and the `cumulative event rate`.

```{r results = 'asis'}
gains_table %<>%
  mutate(ks = round(abs(c.events_pct - c.non_events_pct), 2), 
         cap_rate = percent(cumsum(events)/sum(events), 1, 100), 
         c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), 
         
         #Finally format the remaining columns
         c.events_pct = percent(c.events_pct, 0.1, 100),
         c.non_events_pct = percent(c.non_events_pct, 0.1, 100))
  
kable(gains_table)
```
