[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "This page lists all the blog posts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Variability in Credit Score Predictions\n\n\n\n\n\n\nR\n\n\nCredit Risk Analytics\n\n\nBootstrapping\n\n\n\n\n\n\n\n\n\nNov 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Bayesian Optimization to Tune XGBoost Models in R\n\n\n\n\n\n\nR\n\n\nAnalytics\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Particle Swarm Optimizer from Scratch in R\n\n\n\n\n\n\nR\n\n\nOptimization\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCustom Charting Functions Using ggplot2\n\n\n\n\n\n\nR\n\n\nData Visualization\n\n\nggplot2\n\n\n\n\n\n\n\n\n\nMay 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating Correlated Random Numbers in R from Scratch\n\n\n\n\n\n\nR\n\n\nStatistics\n\n\nSimulation\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMeasuring Model Performance Using a Gains Table\n\n\n\n\n\n\nR\n\n\nCredit Risk Analytics\n\n\nModel Evaluation\n\n\n\n\n\n\n\n\n\nJan 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPortfolio Optimization Using Particle Swarm Optimization in R\n\n\n\n\n\n\nR\n\n\nFinance\n\n\nOptimization\n\n\n\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R for Analytics\n\n\n\n\n\n\nR\n\n\nAnalytics\n\n\nIntroduction\n\n\n\n\n\n\n\n\n\nMar 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMonotonic Binning Using XGBoost\n\n\n\n\n\n\nR\n\n\nCredit Risk Analytics\n\n\nXGBoost\n\n\n\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with Python using R and reticulate\n\n\n\n\n\n\nR\n\n\nPython\n\n\nreticulate\n\n\n\n\n\n\n\n\n\nJan 15, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html",
    "href": "posts/monotonic-binning-using-xgboost.html",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "Monotonic binning is a technique where variable values are grouped into bins such that event rates increase or decrease consistently across these bins. This approach is particularly valuable in credit risk modeling for two key reasons:\n\nModel Stability: Monotonic relationships add robustness to models, making them less susceptible to overfitting and more reliable when deployed in production\nInterpretability: Monotonic relationships are easier to explain to stakeholders and regulators, as they ensure consistent and logical relationships between variables and outcomes\n\n\n\nWe’ll use the following R packages for this demonstration:\n\nlibrary(recipes)  # For data preprocessing\nlibrary(dplyr)    # For data manipulation\nlibrary(xgboost)  # For creating monotonic bins\nlibrary(ggplot2)  # For visualization\n\n\n\n\nFor this demonstration, we’ll use a sample from the Lending Club dataset, which contains loan information including whether loans defaulted:\n\n# Load sample data from Lending Club dataset\nsample &lt;- read.csv(\"https://bit.ly/42ypcnJ\")\n\n# Check dimensions of the dataset\ndim(sample)\n\n[1] 10000   153\n\n\n\n\n\nFirst, we need to create a binary target variable that indicates whether a loan defaulted (1) or not (0):\n\n# Define loan statuses that represent defaults\ncodes &lt;- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\n\n# Create binary target variable\nmodel_data &lt;- sample %&gt;%\n  mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))\n\n\n\n\nNext, we’ll preprocess the data using the recipes package to: 1. Select only numeric variables 2. Impute missing values with median values\n\n# Create a recipe for preprocessing\nrec &lt;- recipe(bad_flag ~ ., data = model_data) %&gt;%\n  step_select(where(is.numeric)) %&gt;%  # Keep only numeric variables\n  step_impute_median(all_predictors())  # Fill missing values with medians\n\n# Apply the preprocessing steps\nrec &lt;- prep(rec, training = model_data)\ntrain &lt;- bake(rec, new_data = model_data)\n\n\n\n\nBefore creating monotonic bins, it’s helpful to visualize the raw relationship between a predictor variable and the target. Let’s examine how the number of credit inquiries in the past 6 months relates to default rates:\n\n# Create dataframe with inquiries and default flag\ndata.frame(x = model_data$inq_last_6mths,\n           y = model_data$bad_flag) %&gt;%\n  filter(x &lt;= 5) %&gt;%  # Focus on 0-5 inquiries for clarity\n  group_by(x) %&gt;% \n  summarise(count = n(),  # Count observations in each group\n            events = sum(y)) %&gt;%  # Count defaults in each group\n  mutate(pct = events/count) %&gt;%  # Calculate default rate\n  ggplot(aes(x = factor(x), y = pct)) + \n  geom_col() + \n  theme_minimal() + \n  labs(x = \"# of inquiries in past 6 months\", \n       y = \"Default rate\",\n       title = \"Default rate vs number of inquiries\")\n\n\n\n\n\n\n\n\nNotice that while there’s a general upward trend (more inquiries correlate with higher default rates), the relationship isn’t perfectly monotonic. This is where our binning approach will help.\n\n\n\nNow we’ll leverage XGBoost’s monotonicity constraints to create bins that have a strictly increasing relationship with default rates. The key parameter is monotone_constraints = 1, which forces the model to create splits that maintain a positive relationship with the target:\n\n# Train XGBoost model with monotonicity constraint\nmdl &lt;- xgboost(\n  data = train %&gt;%\n    select(inq_last_6mths) %&gt;%  # Use only the inquiries variable\n    as.matrix(),  \n  label = train[[\"bad_flag\"]],  # Target variable\n  nrounds = 5,  # Number of boosting rounds\n  params = list(\n    booster = \"gbtree\",\n    objective = \"binary:logistic\",\n    monotone_constraints = 1,  # Force positive relationship\n    max_depth = 1  # Simple trees with single splits\n  ),\n  verbose = 0  # Suppress output\n)\n\n\n\n\nAfter training the model, we can extract the split points that XGBoost identified and use them to create our monotonic bins:\n\n# Extract split points from the model\nsplits &lt;- xgb.model.dt.tree(model = mdl)  \n\n# Create bin boundaries including -Inf and Inf for complete coverage\ncuts &lt;- c(-Inf, unique(sort(splits$Split)), Inf)\n\n# Create and visualize the monotonic bins\ndata.frame(target = train$bad_flag,\n           buckets = cut(train$inq_last_6mths, \n                         breaks = cuts, \n                         include.lowest = TRUE, \n                         right = TRUE)) %&gt;% \n  group_by(buckets) %&gt;%\n  summarise(total = n(),  # Count observations in each bin\n            events = sum(target == 1)) %&gt;%  # Count defaults in each bin\n  mutate(pct = events/total) %&gt;%  # Calculate default rate\n  ggplot(aes(x = buckets, y = pct)) + \n  geom_col() + \n  theme_minimal() + \n  labs(x = \"Bins\", \n       y = \"Default rate\",\n       title = \"Monotonic Bins for Inquiries\")\n\n\n\n\n\n\n\n\nNotice how the default rates now increase monotonically across the bins, making the relationship clearer and more interpretable compared to the raw data we visualized earlier.\n\n\n\nTo make this process more efficient for multiple variables, let’s create a reusable function that handles the entire binning workflow:\n\ncreate_bins &lt;- function(var, outcome, max_depth = 10, plot = TRUE){\n  # Determine relationship direction automatically\n  corr &lt;- cor(var, outcome, method = \"spearman\")\n  direction &lt;- ifelse(corr &gt; 0, 1, -1)  # 1 for positive, -1 for negative correlation\n  \n  # Build XGBoost model with appropriate monotonicity constraint\n  mdl &lt;- xgboost(\n    verbose = 0,\n    data = as.matrix(var),\n    label = outcome,\n    nrounds = 100,  # Single round is sufficient for binning\n    params = list(objective = \"binary:logistic\",\n                  monotone_constraints = direction,  # Apply constraint based on correlation\n                  max_depth = max_depth))  # Control tree complexity\n  \n  # Extract and return split points\n  splits &lt;- xgb.model.dt.tree(model = mdl)\n  cuts &lt;- c(-Inf, sort(unique(splits$Split)), Inf)  # Include boundaries for complete coverage\n  \n  # Optionally visualize the bins\n  if(plot) {\n    data.frame(target = outcome,\n               buckets = cut(var, \n                            breaks = cuts, \n                            include.lowest = TRUE, \n                            right = TRUE)) %&gt;% \n      group_by(buckets) %&gt;%\n      summarise(total = n(),\n                events = sum(target == 1)) %&gt;%\n      mutate(pct = events/total) %&gt;%\n      ggplot(aes(x = buckets, y = pct)) + \n      geom_col() + \n      theme_minimal() + \n      labs(x = \"Bins\", \n           y = \"Default rate\",\n           title = \"Monotonic Bins\")\n  }\n  \n  return(cuts)  # Return the bin boundaries\n}\n\n\n\n\nYou can use this function to create monotonic bins for any numeric variable by passing the variable and outcome columns:\n\n# Example: Create monotonic bins for annual income\nincome_bins &lt;- create_bins(\n  var = train$annual_inc,\n  outcome = train$bad_flag,\n  max_depth = 5\n)"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#required-libraries",
    "href": "posts/monotonic-binning-using-xgboost.html#required-libraries",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "We’ll use the following R packages for this demonstration:\n\nlibrary(recipes)  # For data preprocessing\nlibrary(dplyr)    # For data manipulation\nlibrary(xgboost)  # For creating monotonic bins\nlibrary(ggplot2)  # For visualization"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#sample-dataset",
    "href": "posts/monotonic-binning-using-xgboost.html#sample-dataset",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "For this demonstration, we’ll use a sample from the Lending Club dataset, which contains loan information including whether loans defaulted:\n\n# Load sample data from Lending Club dataset\nsample &lt;- read.csv(\"https://bit.ly/42ypcnJ\")\n\n# Check dimensions of the dataset\ndim(sample)\n\n[1] 10000   153"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#creating-a-target-variable",
    "href": "posts/monotonic-binning-using-xgboost.html#creating-a-target-variable",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "First, we need to create a binary target variable that indicates whether a loan defaulted (1) or not (0):\n\n# Define loan statuses that represent defaults\ncodes &lt;- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\n\n# Create binary target variable\nmodel_data &lt;- sample %&gt;%\n  mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#data-preparation",
    "href": "posts/monotonic-binning-using-xgboost.html#data-preparation",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "Next, we’ll preprocess the data using the recipes package to: 1. Select only numeric variables 2. Impute missing values with median values\n\n# Create a recipe for preprocessing\nrec &lt;- recipe(bad_flag ~ ., data = model_data) %&gt;%\n  step_select(where(is.numeric)) %&gt;%  # Keep only numeric variables\n  step_impute_median(all_predictors())  # Fill missing values with medians\n\n# Apply the preprocessing steps\nrec &lt;- prep(rec, training = model_data)\ntrain &lt;- bake(rec, new_data = model_data)"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#analyzing-directional-trends",
    "href": "posts/monotonic-binning-using-xgboost.html#analyzing-directional-trends",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "Before creating monotonic bins, it’s helpful to visualize the raw relationship between a predictor variable and the target. Let’s examine how the number of credit inquiries in the past 6 months relates to default rates:\n\n# Create dataframe with inquiries and default flag\ndata.frame(x = model_data$inq_last_6mths,\n           y = model_data$bad_flag) %&gt;%\n  filter(x &lt;= 5) %&gt;%  # Focus on 0-5 inquiries for clarity\n  group_by(x) %&gt;% \n  summarise(count = n(),  # Count observations in each group\n            events = sum(y)) %&gt;%  # Count defaults in each group\n  mutate(pct = events/count) %&gt;%  # Calculate default rate\n  ggplot(aes(x = factor(x), y = pct)) + \n  geom_col() + \n  theme_minimal() + \n  labs(x = \"# of inquiries in past 6 months\", \n       y = \"Default rate\",\n       title = \"Default rate vs number of inquiries\")\n\n\n\n\n\n\n\n\nNotice that while there’s a general upward trend (more inquiries correlate with higher default rates), the relationship isn’t perfectly monotonic. This is where our binning approach will help."
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#creating-monotonic-bins-with-xgboost",
    "href": "posts/monotonic-binning-using-xgboost.html#creating-monotonic-bins-with-xgboost",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "Now we’ll leverage XGBoost’s monotonicity constraints to create bins that have a strictly increasing relationship with default rates. The key parameter is monotone_constraints = 1, which forces the model to create splits that maintain a positive relationship with the target:\n\n# Train XGBoost model with monotonicity constraint\nmdl &lt;- xgboost(\n  data = train %&gt;%\n    select(inq_last_6mths) %&gt;%  # Use only the inquiries variable\n    as.matrix(),  \n  label = train[[\"bad_flag\"]],  # Target variable\n  nrounds = 5,  # Number of boosting rounds\n  params = list(\n    booster = \"gbtree\",\n    objective = \"binary:logistic\",\n    monotone_constraints = 1,  # Force positive relationship\n    max_depth = 1  # Simple trees with single splits\n  ),\n  verbose = 0  # Suppress output\n)"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#retrieving-split-points-and-creating-bins",
    "href": "posts/monotonic-binning-using-xgboost.html#retrieving-split-points-and-creating-bins",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "After training the model, we can extract the split points that XGBoost identified and use them to create our monotonic bins:\n\n# Extract split points from the model\nsplits &lt;- xgb.model.dt.tree(model = mdl)  \n\n# Create bin boundaries including -Inf and Inf for complete coverage\ncuts &lt;- c(-Inf, unique(sort(splits$Split)), Inf)\n\n# Create and visualize the monotonic bins\ndata.frame(target = train$bad_flag,\n           buckets = cut(train$inq_last_6mths, \n                         breaks = cuts, \n                         include.lowest = TRUE, \n                         right = TRUE)) %&gt;% \n  group_by(buckets) %&gt;%\n  summarise(total = n(),  # Count observations in each bin\n            events = sum(target == 1)) %&gt;%  # Count defaults in each bin\n  mutate(pct = events/total) %&gt;%  # Calculate default rate\n  ggplot(aes(x = buckets, y = pct)) + \n  geom_col() + \n  theme_minimal() + \n  labs(x = \"Bins\", \n       y = \"Default rate\",\n       title = \"Monotonic Bins for Inquiries\")\n\n\n\n\n\n\n\n\nNotice how the default rates now increase monotonically across the bins, making the relationship clearer and more interpretable compared to the raw data we visualized earlier."
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#creating-a-reusable-function",
    "href": "posts/monotonic-binning-using-xgboost.html#creating-a-reusable-function",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "To make this process more efficient for multiple variables, let’s create a reusable function that handles the entire binning workflow:\n\ncreate_bins &lt;- function(var, outcome, max_depth = 10, plot = TRUE){\n  # Determine relationship direction automatically\n  corr &lt;- cor(var, outcome, method = \"spearman\")\n  direction &lt;- ifelse(corr &gt; 0, 1, -1)  # 1 for positive, -1 for negative correlation\n  \n  # Build XGBoost model with appropriate monotonicity constraint\n  mdl &lt;- xgboost(\n    verbose = 0,\n    data = as.matrix(var),\n    label = outcome,\n    nrounds = 100,  # Single round is sufficient for binning\n    params = list(objective = \"binary:logistic\",\n                  monotone_constraints = direction,  # Apply constraint based on correlation\n                  max_depth = max_depth))  # Control tree complexity\n  \n  # Extract and return split points\n  splits &lt;- xgb.model.dt.tree(model = mdl)\n  cuts &lt;- c(-Inf, sort(unique(splits$Split)), Inf)  # Include boundaries for complete coverage\n  \n  # Optionally visualize the bins\n  if(plot) {\n    data.frame(target = outcome,\n               buckets = cut(var, \n                            breaks = cuts, \n                            include.lowest = TRUE, \n                            right = TRUE)) %&gt;% \n      group_by(buckets) %&gt;%\n      summarise(total = n(),\n                events = sum(target == 1)) %&gt;%\n      mutate(pct = events/total) %&gt;%\n      ggplot(aes(x = buckets, y = pct)) + \n      geom_col() + \n      theme_minimal() + \n      labs(x = \"Bins\", \n           y = \"Default rate\",\n           title = \"Monotonic Bins\")\n  }\n  \n  return(cuts)  # Return the bin boundaries\n}"
  },
  {
    "objectID": "posts/monotonic-binning-using-xgboost.html#example-usage",
    "href": "posts/monotonic-binning-using-xgboost.html#example-usage",
    "title": "Monotonic Binning Using XGBoost",
    "section": "",
    "text": "You can use this function to create monotonic bins for any numeric variable by passing the variable and outcome columns:\n\n# Example: Create monotonic bins for annual income\nincome_bins &lt;- create_bins(\n  var = train$annual_inc,\n  outcome = train$bad_flag,\n  max_depth = 5\n)"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html",
    "href": "posts/intro-to-r-analytics.html",
    "title": "Introduction to R for Analytics",
    "section": "",
    "text": "R is a powerful language specifically designed for data analysis and visualization. This guide will walk you through practical examples of using R for real-world analytics tasks."
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#exploring-your-first-dataset",
    "href": "posts/intro-to-r-analytics.html#exploring-your-first-dataset",
    "title": "Introduction to R for Analytics",
    "section": "Exploring Your First Dataset",
    "text": "Exploring Your First Dataset\nR comes with several built-in datasets perfect for practice. Let’s start by examining the mtcars dataset:\n\n# View the first few rows\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n# Quick summary of the dataset structure\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n# Statistical summary of key variables\nsummary(mtcars[, c(\"mpg\", \"wt\", \"hp\")])\n\n      mpg              wt              hp       \n Min.   :10.40   Min.   :1.513   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:2.581   1st Qu.: 96.5  \n Median :19.20   Median :3.325   Median :123.0  \n Mean   :20.09   Mean   :3.217   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:3.610   3rd Qu.:180.0  \n Max.   :33.90   Max.   :5.424   Max.   :335.0  \n\n\nThe mtcars dataset contains information about 32 cars from Motor Trend magazine, including fuel efficiency (mpg), weight (wt), and horsepower (hp)."
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#effective-data-visualization",
    "href": "posts/intro-to-r-analytics.html#effective-data-visualization",
    "title": "Introduction to R for Analytics",
    "section": "Effective Data Visualization",
    "text": "Effective Data Visualization\nVisualization is essential for understanding patterns in your data. Let’s create some informative plots:\n\nlibrary(ggplot2)\n\n# 1. A scatter plot with regression line\np1 &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point(aes(size = hp, color = factor(cyl)), alpha = 0.7) +\n  geom_smooth(method = \"lm\", formula = y ~ x, color = \"#2c3e50\") +\n  labs(title = \"Car Weight vs. Fuel Efficiency\",\n       subtitle = \"Size represents horsepower, color represents cylinders\",\n       x = \"Weight (1000 lbs)\",\n       y = \"Miles Per Gallon\") +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Set1\", name = \"Cylinders\")\n\n# 2. Distribution of fuel efficiency\np2 &lt;- ggplot(mtcars, aes(x = mpg, fill = factor(cyl))) +\n  geom_histogram(bins = 10, alpha = 0.7, position = \"identity\") +\n  labs(title = \"Distribution of Fuel Efficiency\",\n       x = \"Miles Per Gallon\",\n       y = \"Count\") +\n  scale_fill_brewer(palette = \"Set1\", name = \"Cylinders\") +\n  theme_minimal()\n\n# Display plots (if using patchwork)\nlibrary(patchwork)\np1 / p2\n\n\n\n\n\n\n\n\nThese visualizations reveal:\n\nA clear negative correlation between car weight and fuel efficiency\nHigher cylinder cars tend to be heavier with lower MPG\nThe MPG distribution varies significantly by cylinder count"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#practical-data-transformation",
    "href": "posts/intro-to-r-analytics.html#practical-data-transformation",
    "title": "Introduction to R for Analytics",
    "section": "Practical Data Transformation",
    "text": "Practical Data Transformation\nData rarely comes in the exact format you need. The dplyr package makes transformations straightforward:\n\n# Load required packages\nlibrary(dplyr)\nlibrary(tibble)  # For rownames_to_column function\n\n# Create an enhanced version of the dataset\nmtcars_enhanced &lt;- mtcars %&gt;%\n  # Add car names as a column (they're currently row names)\n  rownames_to_column(\"car_name\") %&gt;%\n  # Create useful derived metrics\n  mutate(\n    # Efficiency ratio (higher is better)\n    efficiency_ratio = mpg / wt,\n    \n    # Power-to-weight ratio (higher is better)\n    power_to_weight = hp / wt,\n    \n    # Categorize cars by efficiency\n    efficiency_category = case_when(\n      mpg &gt; 25 ~ \"High Efficiency\",\n      mpg &gt; 15 ~ \"Medium Efficiency\",\n      TRUE ~ \"Low Efficiency\"\n    )\n  ) %&gt;%\n  # Arrange from most to least efficient\n  arrange(desc(efficiency_ratio))\n\n# Display the top 5 most efficient cars\nhead(mtcars_enhanced[, c(\"car_name\", \"mpg\", \"wt\", \"hp\", \"efficiency_ratio\", \"efficiency_category\")], 5)\n\n        car_name  mpg    wt  hp efficiency_ratio efficiency_category\n1   Lotus Europa 30.4 1.513 113         20.09253     High Efficiency\n2    Honda Civic 30.4 1.615  52         18.82353     High Efficiency\n3 Toyota Corolla 33.9 1.835  65         18.47411     High Efficiency\n4       Fiat 128 32.4 2.200  66         14.72727     High Efficiency\n5      Fiat X1-9 27.3 1.935  66         14.10853     High Efficiency"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#answering-business-questions-with-data",
    "href": "posts/intro-to-r-analytics.html#answering-business-questions-with-data",
    "title": "Introduction to R for Analytics",
    "section": "Answering Business Questions with Data",
    "text": "Answering Business Questions with Data\nLet’s use our enhanced dataset to answer some practical questions:\n\n# Question 1: What are the average characteristics by cylinder count?\ncylinder_analysis &lt;- mtcars_enhanced %&gt;%\n  group_by(cyl) %&gt;%\n  summarize(\n    count = n(),\n    avg_mpg = mean(mpg),\n    avg_weight = mean(wt),\n    avg_horsepower = mean(hp),\n    avg_efficiency_ratio = mean(efficiency_ratio),\n    avg_power_to_weight = mean(power_to_weight)\n  ) %&gt;%\n  arrange(cyl)\n\n# Display the results\ncylinder_analysis\n\n# A tibble: 3 × 7\n    cyl count avg_mpg avg_weight avg_horsepower avg_efficiency_ratio\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;                &lt;dbl&gt;\n1     4    11    26.7       2.29           82.6                12.7 \n2     6     7    19.7       3.12          122.                  6.44\n3     8    14    15.1       4.00          209.                  3.95\n# ℹ 1 more variable: avg_power_to_weight &lt;dbl&gt;\n\n# Question 2: Which transmission type is more fuel efficient?\ntransmission_efficiency &lt;- mtcars_enhanced %&gt;%\n  # am: 0 = automatic, 1 = manual\n  mutate(transmission = if_else(am == 1, \"Manual\", \"Automatic\")) %&gt;%\n  group_by(transmission) %&gt;%\n  summarize(\n    count = n(),\n    avg_mpg = mean(mpg),\n    median_mpg = median(mpg),\n    mpg_std_dev = sd(mpg)\n  )\n\n# Display the results\ntransmission_efficiency\n\n# A tibble: 2 × 5\n  transmission count avg_mpg median_mpg mpg_std_dev\n  &lt;chr&gt;        &lt;int&gt;   &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1 Automatic       19    17.1       17.3        3.83\n2 Manual          13    24.4       22.8        6.17\n\n# Visualize the difference\nggplot(mtcars, aes(x = factor(am, labels = c(\"Automatic\", \"Manual\")), y = mpg, fill = factor(am))) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(title = \"Fuel Efficiency by Transmission Type\",\n       x = \"Transmission Type\",\n       y = \"Miles Per Gallon\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#correlation-analysis-for-decision-making",
    "href": "posts/intro-to-r-analytics.html#correlation-analysis-for-decision-making",
    "title": "Introduction to R for Analytics",
    "section": "Correlation Analysis for Decision Making",
    "text": "Correlation Analysis for Decision Making\nUnderstanding relationships between variables is crucial for business decisions:\n\n# Calculate correlations\ncor_matrix &lt;- cor(mtcars[, c(\"mpg\", \"wt\", \"hp\", \"disp\", \"qsec\")])\ncor_df &lt;- round(cor_matrix, 2)\n\n# Display correlation matrix\ncor_df\n\n       mpg    wt    hp  disp  qsec\nmpg   1.00 -0.87 -0.78 -0.85  0.42\nwt   -0.87  1.00  0.66  0.89 -0.17\nhp   -0.78  0.66  1.00  0.79 -0.71\ndisp -0.85  0.89  0.79  1.00 -0.43\nqsec  0.42 -0.17 -0.71 -0.43  1.00\n\n# Visualize correlations (requires the corrplot package)\nlibrary(corrplot)\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", \n         tl.col = \"black\", tl.srt = 45, addCoef.col = \"black\")\n\n\n\n\n\n\n\n# Scatter plot matrix of key variables\npairs(mtcars[, c(\"mpg\", \"wt\", \"hp\", \"disp\")], \n      main = \"Scatter Plot Matrix of Key Variables\",\n      pch = 21, bg = \"lightblue\", cex = 1.2)"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#working-with-real-world-datasets",
    "href": "posts/intro-to-r-analytics.html#working-with-real-world-datasets",
    "title": "Introduction to R for Analytics",
    "section": "Working with Real-World Datasets",
    "text": "Working with Real-World Datasets\nLet’s analyze the famous Iris dataset to demonstrate a complete workflow:\n\n# Load packages\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Examine the dataset\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n# Calculate summary statistics by species\niris_stats &lt;- iris %&gt;%\n  group_by(Species) %&gt;%\n  summarize(across(where(is.numeric), \n                   list(mean = mean, \n                        median = median,\n                        sd = sd,\n                        min = min,\n                        max = max)))\n\n# View summary for Sepal.Length\niris_stats %&gt;% select(Species, starts_with(\"Sepal.Length\"))\n\n# A tibble: 3 × 6\n  Species Sepal.Length_mean Sepal.Length_median Sepal.Length_sd Sepal.Length_min\n  &lt;fct&gt;               &lt;dbl&gt;               &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1 setosa               5.01                 5             0.352              4.3\n2 versic…              5.94                 5.9           0.516              4.9\n3 virgin…              6.59                 6.5           0.636              4.9\n# ℹ 1 more variable: Sepal.Length_max &lt;dbl&gt;\n\n# Create a visualization comparing all measurements across species\niris_long &lt;- iris %&gt;%\n  pivot_longer(\n    cols = -Species,\n    names_to = \"Measurement\",\n    values_to = \"Value\"\n  )\n\n# Box plots with data points\nggplot(iris_long, aes(x = Species, y = Value, fill = Species)) +\n  geom_boxplot(alpha = 0.6) +\n  geom_jitter(width = 0.15, alpha = 0.5, color = \"darkgrey\") +\n  facet_wrap(~Measurement, scales = \"free_y\") +\n  labs(title = \"Iris Measurements Across Species\",\n       subtitle = \"Box plots with individual observations\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n# Find the most distinguishing features between species\niris_wide &lt;- iris %&gt;%\n  pivot_longer(cols = -Species, names_to = \"Measurement\", values_to = \"Value\") %&gt;%\n  group_by(Measurement, Species) %&gt;%\n  summarise(mean_value = mean(Value), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = Species, values_from = mean_value) %&gt;%\n  mutate(versicolor_vs_setosa = abs(versicolor - setosa),\n         virginica_vs_setosa = abs(virginica - setosa),\n         virginica_vs_versicolor = abs(virginica - versicolor),\n         max_difference = pmax(versicolor_vs_setosa, virginica_vs_setosa, virginica_vs_versicolor))\n\n# Display the results ordered by maximum difference\niris_wide %&gt;% arrange(desc(max_difference))\n\n# A tibble: 4 × 8\n  Measurement  setosa versicolor virginica versicolor_vs_setosa\n  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;                &lt;dbl&gt;\n1 Petal.Length  1.46        4.26      5.55                2.80 \n2 Petal.Width   0.246       1.33      2.03                1.08 \n3 Sepal.Length  5.01        5.94      6.59                0.93 \n4 Sepal.Width   3.43        2.77      2.97                0.658\n# ℹ 3 more variables: virginica_vs_setosa &lt;dbl&gt;, virginica_vs_versicolor &lt;dbl&gt;,\n#   max_difference &lt;dbl&gt;"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#handling-missing-data-in-practice",
    "href": "posts/intro-to-r-analytics.html#handling-missing-data-in-practice",
    "title": "Introduction to R for Analytics",
    "section": "Handling Missing Data in Practice",
    "text": "Handling Missing Data in Practice\nLet’s tackle the common challenge of missing data using a practical example:\n\n# Create a simulated customer dataset with missing values\nset.seed(123) # For reproducibility\n\ncustomers &lt;- data.frame(\n  customer_id = 1:100,\n  age = sample(18:70, 100, replace = TRUE),\n  income = round(rnorm(100, 50000, 15000)),\n  years_as_customer = sample(0:20, 100, replace = TRUE),\n  purchase_frequency = sample(1:10, 100, replace = TRUE)\n)\n\n# Introduce missing values randomly\nset.seed(456)\ncustomers$age[sample(1:100, 10)] &lt;- NA\ncustomers$income[sample(1:100, 15)] &lt;- NA\ncustomers$purchase_frequency[sample(1:100, 5)] &lt;- NA\n\n# 1. Identify missing data\nmissing_summary &lt;- sapply(customers, function(x) sum(is.na(x)))\nmissing_summary\n\n       customer_id                age             income  years_as_customer \n                 0                 10                 15                  0 \npurchase_frequency \n                 5 \n\n# 2. Visualize the pattern of missing data\nlibrary(naniar) # May need to install this package\nvis_miss(customers)\n\n\n\n\n\n\n\n# 3. Handle missing data with multiple approaches\n\n# Option A: Remove rows with any missing values\nclean_customers &lt;- na.omit(customers)\nnrow(customers) - nrow(clean_customers) # Number of rows removed\n\n[1] 26\n\n# Option B: Impute with mean/median (numeric variables only)\nimputed_customers &lt;- customers %&gt;%\n  mutate(\n    age = ifelse(is.na(age), median(age, na.rm = TRUE), age),\n    income = ifelse(is.na(income), mean(income, na.rm = TRUE), income),\n    purchase_frequency = ifelse(is.na(purchase_frequency), \n                               median(purchase_frequency, na.rm = TRUE), \n                               purchase_frequency)\n  )\n\n# Option C: Predictive imputation (using age to predict income)\nlibrary(mice) # For more sophisticated imputation\n# Quick imputation model - in practice you'd use more parameters\nimputed_data &lt;- mice(customers, m = 5, method = \"pmm\", printFlag = FALSE)\ncustomers_complete &lt;- complete(imputed_data)\n\n# Compare results by calculating customer value score\ncalculate_value &lt;- function(df) {\n  df %&gt;%\n    mutate(customer_value = (income/10000) * (purchase_frequency/10) * log(years_as_customer + 1)) %&gt;%\n    arrange(desc(customer_value)) %&gt;%\n    select(customer_id, customer_value, everything())\n}\n\n# Top 5 customers by value (original with NAs removed)\nhead(calculate_value(clean_customers), 5)\n\n  customer_id customer_value age income years_as_customer purchase_frequency\n1           7       24.63960  67  82249                19                 10\n2          54       15.73965  22  70961                15                  8\n3          59       15.67045  50  70649                15                  8\n4          84       15.09251  21  55732                14                 10\n5          72       14.27848  23  61853                12                  9\n\n# Top 5 customers by value (with imputed values)\nhead(calculate_value(customers_complete), 5)\n\n  customer_id customer_value age income years_as_customer purchase_frequency\n1           7       24.63960  67  82249                19                 10\n2          54       15.73965  22  70961                15                  8\n3          59       15.67045  50  70649                15                  8\n4          84       15.09251  21  55732                14                 10\n5          72       14.27848  23  61853                12                  9"
  },
  {
    "objectID": "posts/intro-to-r-analytics.html#time-series-analysis-for-business-trends",
    "href": "posts/intro-to-r-analytics.html#time-series-analysis-for-business-trends",
    "title": "Introduction to R for Analytics",
    "section": "Time Series Analysis for Business Trends",
    "text": "Time Series Analysis for Business Trends\nTime series analysis is essential for understanding business trends and forecasting:\n\n# Load packages\nlibrary(forecast)\nlibrary(tseries)\n\n# Examine the built-in AirPassengers dataset (monthly air passengers from 1949 to 1960)\ndata(AirPassengers)\nclass(AirPassengers)\n\n[1] \"ts\"\n\n# Plot the time series\nautoplots &lt;- autoplot(AirPassengers) +\n  labs(title = \"Monthly Air Passengers (1949-1960)\",\n       y = \"Passenger Count\",\n       x = \"Year\") +\n  theme_minimal()\n\n# Decompose the time series into seasonal components\ndecomposed &lt;- decompose(AirPassengers, \"multiplicative\")\nautoplot(decomposed) +\n  labs(title = \"Decomposition of Air Passengers Time Series\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Forecasting future values using auto.arima\nfit &lt;- auto.arima(AirPassengers)\nforecasts &lt;- forecast(fit, h = 24) # Forecast 2 years ahead\n\n# Plot the forecasts\nplot(forecasts, \n     main = \"Air Passengers Forecast (24 months)\",\n     xlab = \"Year\", \n     ylab = \"Passenger Count\")\n\n\n\n\n\n\n\n# Summary of the forecast model\nsummary(fit)\n\nSeries: AirPassengers \nARIMA(2,1,1)(0,1,0)[12] \n\nCoefficients:\n         ar1     ar2      ma1\n      0.5960  0.2143  -0.9819\ns.e.  0.0888  0.0880   0.0292\n\nsigma^2 = 132.3:  log likelihood = -504.92\nAIC=1017.85   AICc=1018.17   BIC=1029.35\n\nTraining set error measures:\n                 ME     RMSE     MAE      MPE     MAPE     MASE        ACF1\nTraining set 1.3423 10.84619 7.86754 0.420698 2.800458 0.245628 -0.00124847"
  },
  {
    "objectID": "posts/generating-correlated-random-numbers.html",
    "href": "posts/generating-correlated-random-numbers.html",
    "title": "Generating Correlated Random Numbers in R from Scratch",
    "section": "",
    "text": "Need random data with specific correlation patterns for your simulations? This post shows you how to generate correlated random numbers in R using a simple matrix approach – perfect for testing algorithms or creating realistic synthetic datasets."
  },
  {
    "objectID": "posts/generating-correlated-random-numbers.html#the-cholesky-method-in-four-steps",
    "href": "posts/generating-correlated-random-numbers.html#the-cholesky-method-in-four-steps",
    "title": "Generating Correlated Random Numbers in R from Scratch",
    "section": "The Cholesky Method in Four Steps",
    "text": "The Cholesky Method in Four Steps\n\n# 1. Define your target correlation matrix\ncor_mat &lt;- matrix(c(1, 0.3, \n                   0.3, 1), nrow = 2, byrow = TRUE)\n\n# 2. Apply Cholesky decomposition\nchol_mat &lt;- chol(cor_mat)\n\n# 3. Generate uncorrelated random numbers\nold_random &lt;- matrix(rnorm(2000), ncol = 2)\n\n# 4. Transform to create correlation\nnew_random &lt;- old_random %*% chol_mat\n\n# Verify the correlation\ncor(new_random)\n\n          [,1]      [,2]\n[1,] 1.0000000 0.3206961\n[2,] 0.3206961 1.0000000\n\n\nThat’s it! The new_random matrix now contains values with approximately your target correlation structure. This technique uses Cholesky decomposition to create a transformation matrix that induces the desired correlation when applied to uncorrelated data."
  },
  {
    "objectID": "posts/generating-correlated-random-numbers.html#watch-out-for-these-pitfalls",
    "href": "posts/generating-correlated-random-numbers.html#watch-out-for-these-pitfalls",
    "title": "Generating Correlated Random Numbers in R from Scratch",
    "section": "Watch Out for These Pitfalls",
    "text": "Watch Out for These Pitfalls\n\n1. Start with Truly Random Data\nYour input data must be uncorrelated for this method to work correctly:\n\n# What happens with already correlated input?\nsimulate_correlation &lt;- function(input_correlation, target = 0.3) {\n  results &lt;- replicate(1000, {\n    # Create input with specified correlation\n    x &lt;- rnorm(1000)\n    y &lt;- input_correlation * x + rnorm(1000, sd = sqrt(1 - input_correlation^2))\n    \n    # Apply our method\n    old_random &lt;- cbind(x, y)\n    chol_mat &lt;- chol(matrix(c(1, target, target, 1), ncol = 2))\n    new_random &lt;- old_random %*% chol_mat\n    \n    # Return resulting correlation\n    cor(new_random)[1,2]\n  })\n  return(results)\n}\n\n# Compare results with different input correlations\npar(mfrow = c(1, 2))\nhist(simulate_correlation(0.8), main = \"Starting with Correlated Data\",\n     xlim = c(0, 1), col = \"salmon\")\nhist(simulate_correlation(0.001), main = \"Starting with Random Data\",\n     xlim = c(0, 1), col = \"lightblue\")\n\n\n\n\n\n\n\n\nWhen your input data already has correlation patterns, the Cholesky method can’t properly override them to create your target correlation.\n\n\n2. Use the Same Distribution for All Variables\n\n# Different distributions cause problems\nset.seed(123)\nx1 &lt;- rchisq(1000, df = 3)  # Chi-squared (skewed)\ny1 &lt;- rnorm(1000)           # Normal (symmetric)\nold_mixed &lt;- cbind(x1, y1)\n\n# Same distribution works better\nx2 &lt;- rchisq(1000, df = 3)\ny2 &lt;- rchisq(1000, df = 3)\nold_same &lt;- cbind(x2, y2)\n\n# Apply the same transformation to both\nchol_mat &lt;- chol(matrix(c(1, 0.7, 0.7, 1), ncol = 2))\nnew_mixed &lt;- old_mixed %*% chol_mat\nnew_same &lt;- old_same %*% chol_mat\n\n# Compare results\ncat(\"Target correlation: 0.7\\n\")\n\nTarget correlation: 0.7\n\ncat(\"Mixed distributions result:\", round(cor(new_mixed)[1,2], 3), \"\\n\")\n\nMixed distributions result: 0.915 \n\ncat(\"Same distribution result:\", round(cor(new_same)[1,2], 3))\n\nSame distribution result: 0.699\n\n\nMixing different distributions (like normal and chi-squared) can lead to unexpected correlation patterns after transformation.\n\n\n3. Distribution Properties Can Change\n\n# Original positive-only distribution\nx &lt;- rchisq(1000, df = 3)  # Always positive\ny &lt;- rchisq(1000, df = 3)  # Always positive\nold_random &lt;- cbind(x, y)\n\n# Apply negative correlation\nchol_mat &lt;- chol(matrix(c(1, -0.7, -0.7, 1), ncol = 2))\nnew_random &lt;- old_random %*% chol_mat\n\n# Check what happened\ncat(\"Original data range:\", round(range(old_random), 2), \"\\n\")\n\nOriginal data range: 0.02 19.93 \n\ncat(\"Transformed data range:\", round(range(new_random), 2), \"\\n\")\n\nTransformed data range: -12.81 19.93 \n\ncat(\"Negative values in result:\", sum(new_random &lt; 0), \"out of\", length(new_random))\n\nNegative values in result: 488 out of 2000\n\n\nThe Cholesky transformation can fundamentally change your data’s properties - like introducing negative values into a previously positive-only distribution."
  },
  {
    "objectID": "posts/generating-correlated-random-numbers.html#the-easy-way-using-mvtnorm",
    "href": "posts/generating-correlated-random-numbers.html#the-easy-way-using-mvtnorm",
    "title": "Generating Correlated Random Numbers in R from Scratch",
    "section": "The Easy Way: Using mvtnorm",
    "text": "The Easy Way: Using mvtnorm\nFor most real applications, the mvtnorm package offers a simpler solution:\n\n# Load the package\nlibrary(mvtnorm)\n\n# Define means and covariance matrix\nmeans &lt;- c(10, 20)  # Mean for each variable\nsigma &lt;- matrix(c(4, 2,   # Covariance matrix\n                  2, 3), ncol = 2)\n\n# See the implied correlation\ncov2cor(sigma)\n\n          [,1]      [,2]\n[1,] 1.0000000 0.5773503\n[2,] 0.5773503 1.0000000\n\n# Generate correlated normal data in one step\nx &lt;- rmvnorm(n = 1000, mean = means, sigma = sigma)\n\n# Verify the result\nround(cor(x), 3)\n\n      [,1]  [,2]\n[1,] 1.000 0.613\n[2,] 0.613 1.000"
  },
  {
    "objectID": "posts/generating-correlated-random-numbers.html#when-to-use-each-method",
    "href": "posts/generating-correlated-random-numbers.html#when-to-use-each-method",
    "title": "Generating Correlated Random Numbers in R from Scratch",
    "section": "When to Use Each Method",
    "text": "When to Use Each Method\nUse the Cholesky method when: - You need to understand the mathematical principles - You’re working with non-normal distributions - You need to create custom correlation structures\nUse mvtnorm when: - You need multivariate normal data quickly - You want precise control over means and variances - You’re working with many variables"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html",
    "href": "posts/building-particle-swarm-optimizer.html",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "",
    "text": "Nature-inspired algorithms can solve complex optimization problems with surprising efficiency. This post shows you how to build a Particle Swarm Optimizer (PSO) from scratch in R – mimicking how birds flock or fish school to efficiently search for food."
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#required-libraries",
    "href": "posts/building-particle-swarm-optimizer.html#required-libraries",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "Required Libraries",
    "text": "Required Libraries\n\n# Load required packages\nlibrary(dplyr)     # For data manipulation\nlibrary(ggplot2)   # For visualization\nlibrary(gganimate) # For animations\nlibrary(metR)      # For geom_arrow"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#the-challenge-a-complex-optimization-surface",
    "href": "posts/building-particle-swarm-optimizer.html#the-challenge-a-complex-optimization-surface",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "The Challenge: A Complex Optimization Surface",
    "text": "The Challenge: A Complex Optimization Surface\nWe’ll test our optimizer on Ackley’s function – a challenging benchmark with many local minima that can trap optimization algorithms:\n\nobj_func &lt;- function(x, y){\n  # Modified Ackley function with global minimum at (1,1)\n  -20 * exp(-0.2 * sqrt(0.5 *((x-1)^2 + (y-1)^2))) - \n    exp(0.5*(cos(2*pi*x) + cos(2*pi*y))) + exp(1) + 20\n}\n\n# Create a visualization grid\nx &lt;- seq(-5, 5, length.out = 50)\ny &lt;- seq(-5, 5, length.out = 50)\ngrid &lt;- expand.grid(x, y, stringsAsFactors = FALSE)\ngrid$z &lt;- obj_func(grid[,1], grid[,2])\n\n# Create a contour plot\ncontour_plot &lt;- ggplot(grid, aes(x = Var1, y = Var2)) +\n  geom_contour_filled(aes(z = z), color = \"black\", alpha = 0.5) +\n  scale_fill_brewer(palette = \"Spectral\") + \n  theme_minimal() + \n  labs(x = \"x\", y = \"y\", title = \"Ackley's Function\")\n\ncontour_plot"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#how-pso-works",
    "href": "posts/building-particle-swarm-optimizer.html#how-pso-works",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "How PSO Works",
    "text": "How PSO Works\nPSO mimics how birds find food by combining individual memory with social information:\n\nScatter random “particles” across the search space\nEach particle remembers its personal best position\nThe swarm shares information about the global best position\nParticles adjust their movement based on both personal and swarm knowledge\n\nThe movement equation balances three forces:\n\\[v_{new} = w \\cdot v_{current} + c_1 \\cdot r_1 \\cdot (p_{best} - p_{current}) + c_2 \\cdot r_2 \\cdot (g_{best} - p_{current})\\]\nWhere: - w: Inertia weight (momentum) - c1: Personal influence (memory) - c2: Social influence (cooperation) - r1,r2: Random values adding exploration"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#building-pso-step-by-step",
    "href": "posts/building-particle-swarm-optimizer.html#building-pso-step-by-step",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "Building PSO Step by Step",
    "text": "Building PSO Step by Step\n\nStep 1: Initialize the Swarm\nFirst, we create a random swarm of particles and place them across our search space:\n\n# Set parameters\nn_particles &lt;- 20\nw &lt;- 0.5     # Inertia weight\nc1 &lt;- 0.05   # Personal learning rate\nc2 &lt;- 0.1    # Social learning rate\n\n# Create random particle positions\nx_range &lt;- seq(-5, 5, length.out = 20)\ny_range &lt;- seq(-5, 5, length.out = 20)\nX &lt;- data.frame(\n  x = sample(x_range, n_particles, replace = FALSE),\n  y = sample(y_range, n_particles, replace = FALSE)\n)\n\n# Visualize initial positions\ncontour_plot + \n  geom_point(data = X, aes(x, y), color = \"red\", size = 2.5) + \n  labs(title = \"Initial Particle Positions\")\n\n\n\n\n\n\n\n\n\n\nStep 2: Track Best Positions and Initialize Velocities\nNext, we track each particle’s personal best position and the swarm’s global best position:\n\n# Initialize random velocities\ndX &lt;- matrix(runif(n_particles * 2), ncol = 2) * w\n\n# Set initial personal best positions\npbest &lt;- X\npbest_obj &lt;- obj_func(X[,1], X[,2])\n\n# Find global best position\ngbest &lt;- pbest[which.min(pbest_obj),]\ngbest_obj &lt;- min(pbest_obj)\n\n# Visualize with arrows showing pull toward global best\nX_dir &lt;- X %&gt;% \n  mutate(g_x = gbest[1,1], \n         g_y = gbest[1,2], \n         angle = atan((g_y - y)/(g_x - x))*180/pi,\n         angle = ifelse(g_x &lt; x, 180 + angle, angle))\n\ncontour_plot + \n  geom_point(data = X, aes(x, y), color = \"red\", size = 2.5) + \n  geom_segment(data = X_dir, \n               aes(x = x, y = y, \n                   xend = x + 0.5*cos(angle*pi/180), \n                   yend = y + 0.5*sin(angle*pi/180)), \n               arrow = arrow(length = unit(0.1, \"cm\")), \n               color = \"blue\") + \n  labs(title = \"Forces Acting on Particles\")\n\n\n\n\n\n\n\n\n\n\nStep 3: Update Particle Positions\nNow we update each particle’s position based on its velocity and the forces acting on it:\n\n# Calculate new velocities using PSO equation\ndX &lt;- w * dX + \n      c1*runif(1)*(pbest - X) + \n      c2*runif(1)*(as.matrix(gbest) - X)\n\n# Update positions\nX &lt;- X + dX\n\n# Evaluate function at new positions\nobj &lt;- obj_func(X[,1], X[,2])\n\n# Update personal best positions if improved\nidx &lt;- which(obj &lt;= pbest_obj)\npbest[idx,] &lt;- X[idx,]\npbest_obj[idx] &lt;- obj[idx]\n\n# Update global best position\nidx &lt;- which.min(pbest_obj)\ngbest &lt;- pbest[idx,]\ngbest_obj &lt;- min(pbest_obj)\n\n# Visualize updated positions\nX_dir &lt;- X %&gt;% \n  mutate(g_x = gbest[1,1], \n         g_y = gbest[1,2], \n         angle = atan((g_y - y)/(g_x - x))*180/pi,\n         angle = ifelse(g_x &lt; x, 180 + angle, angle))\n\ncontour_plot + \n  geom_point(data = X, aes(x, y), color = \"red\", size = 2.5) + \n  geom_segment(data = X_dir, \n               aes(x = x, y = y, \n                   xend = x + 0.5*cos(angle*pi/180), \n                   yend = y + 0.5*sin(angle*pi/180)), \n               arrow = arrow(length = unit(0.1, \"cm\")), \n               color = \"blue\") + \n  labs(title = \"Particles After First Update\")"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#complete-pso-implementation",
    "href": "posts/building-particle-swarm-optimizer.html#complete-pso-implementation",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "Complete PSO Implementation",
    "text": "Complete PSO Implementation\nNow let’s package everything into a reusable function:\n\npso_optim &lt;- function(obj_func,      # Function to minimize\n                      c1 = 0.05,      # Personal learning rate\n                      c2 = 0.05,      # Social learning rate\n                      w = 0.8,        # Inertia weight\n                      n_particles = 20,  # Swarm size\n                      init_fact = 0.1,   # Initial velocity factor\n                      n_iter = 50        # Maximum iterations\n){\n  # Define search domain\n  x &lt;- seq(-5, 5, length.out = 100)\n  y &lt;- seq(-5, 5, length.out = 100)\n  \n  # Initialize particles\n  X &lt;- cbind(sample(x, n_particles, replace = FALSE),\n             sample(y, n_particles, replace = FALSE))\n  dX &lt;- matrix(runif(n_particles * 2) * init_fact, ncol = 2)\n  \n  # Initialize best positions\n  pbest &lt;- X\n  pbest_obj &lt;- obj_func(x = X[,1], y = X[,2])\n  gbest &lt;- pbest[which.min(pbest_obj),]\n  gbest_obj &lt;- min(pbest_obj)\n  \n  # Store positions for visualization\n  loc_df &lt;- data.frame(X, iter = 0)\n  iter &lt;- 1\n  \n  # Main optimization loop\n  while(iter &lt; n_iter){\n    # Update velocities\n    dX &lt;- w * dX + \n          c1*runif(1)*(pbest - X) + \n          c2*runif(1)*t(gbest - t(X))\n    \n    # Update positions\n    X &lt;- X + dX\n    \n    # Evaluate and update best positions\n    obj &lt;- obj_func(x = X[,1], y = X[,2])\n    idx &lt;- which(obj &lt;= pbest_obj)\n    pbest[idx,] &lt;- X[idx,]\n    pbest_obj[idx] &lt;- obj[idx]\n    \n    # Update global best\n    idx &lt;- which.min(pbest_obj)\n    gbest &lt;- pbest[idx,]\n    gbest_obj &lt;- min(pbest_obj)\n    \n    # Store for visualization\n    iter &lt;- iter + 1\n    loc_df &lt;- rbind(loc_df, data.frame(X, iter = iter))\n  }\n  \n  return(list(X = loc_df, \n              obj = gbest_obj, \n              obj_loc = paste0(gbest, collapse = \",\")))\n}\n\nLet’s test our optimizer on the Ackley function:\n\n# Run the PSO algorithm\nout &lt;- pso_optim(obj_func,\n                 c1 = 0.01,    # Low personal influence\n                 c2 = 0.05,    # Moderate social influence\n                 w = 0.5,      # Medium inertia\n                 n_particles = 50,\n                 init_fact = 0.1,\n                 n_iter = 200)\n\n# Check the result (global minimum should be at (1,1))\nout$obj_loc\n\n[1] \"1.0000238436846,0.999984789266684\""
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#visualizing-the-swarm-in-action",
    "href": "posts/building-particle-swarm-optimizer.html#visualizing-the-swarm-in-action",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "Visualizing the Swarm in Action",
    "text": "Visualizing the Swarm in Action\nThe real beauty of PSO is watching the particles converge on the solution:\n\n# Create animation of the optimization process\nggplot(out$X) +\n  geom_contour(data = grid, aes(x = Var1, y = Var2, z = z), color = \"black\") +\n  geom_point(aes(X1, X2)) +\n  labs(x = \"X\", y = \"Y\") +\n  transition_time(iter) +\n  ease_aes(\"linear\")"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#fine-tuning-your-swarm",
    "href": "posts/building-particle-swarm-optimizer.html#fine-tuning-your-swarm",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "Fine-Tuning Your Swarm",
    "text": "Fine-Tuning Your Swarm\nThe PSO algorithm’s behavior can be dramatically altered by adjusting three key parameters:\n\nInertia Weight (w)\n\nHigh values (&gt;0.8): Particles maintain momentum and explore widely\nLow values (&lt;0.4): Particles slow down and focus on refining solutions\n\nPersonal Learning Rate (c1)\n\nHigh values: Particles favor their own discoveries\nLow values: Particles ignore their history\n\nSocial Learning Rate (c2)\n\nHigh values: Particles rush toward the global best\nLow values: Particles explore independently\n\n\nCommon parameter combinations: - Exploration focus: High w (0.9), balanced c1/c2 (0.5/0.5) - Exploitation focus: Low w (0.4), higher c2 than c1 (0.1/0.7)"
  },
  {
    "objectID": "posts/building-particle-swarm-optimizer.html#enhancing-your-pso-implementation",
    "href": "posts/building-particle-swarm-optimizer.html#enhancing-your-pso-implementation",
    "title": "Building a Particle Swarm Optimizer from Scratch in R",
    "section": "Enhancing Your PSO Implementation",
    "text": "Enhancing Your PSO Implementation\nFor real-world applications, consider these improvements:\n\nAdd boundary constraints to keep particles within valid regions\nImplement adaptive parameters that change during optimization\nAdd convergence-based stopping criteria\nExtend to higher dimensions for more complex problems\n\nThe R package pso offers a production-ready implementation!"
  },
  {
    "objectID": "posts/assessing-score-reliability.html",
    "href": "posts/assessing-score-reliability.html",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "",
    "text": "Credit scoring models work well in the middle of the score distribution but often become less reliable at the extremes where data is sparse. This post shows how to use bootstrapping to measure prediction variability across different score ranges – helping you identify where your model is most dependable."
  },
  {
    "objectID": "posts/assessing-score-reliability.html#why-estimation-variance-matters",
    "href": "posts/assessing-score-reliability.html#why-estimation-variance-matters",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Why Estimation Variance Matters",
    "text": "Why Estimation Variance Matters\nSmaller sample sizes lead to higher variance in estimates, especially for extreme values. While statistics like means remain stable with limited data, tail percentiles (95th, 99th) show much more volatility. This matters for credit scoring, where very high and very low scores represent these unstable tail regions.\n\n# Number of samples to be drawn from a probability distribution\nn_samples &lt;- 1000\n\n# Number of times, sampling should be repeated\nrepeats &lt;- 100\n\n# Mean and std-dev for a standard normal distribution\nmu &lt;- 5\nstd_dev &lt;- 2\n\n# Sample\nsamples &lt;- rnorm(n_samples * repeats, mean = 10)\n\n# Fit into a matrix like object with `n_samples' number of rows \n# and `repeats` number of columns\nsamples &lt;- matrix(samples, nrow = n_samples, ncol = repeats)\n\n# Compute mean across each column\nsample_means &lt;- apply(samples, 1, mean)\n\n# Similarly, compute 75% and 95% quantile across each column\nsample_75_quantile &lt;- apply(samples, 1, quantile, p = 0.75)\nsample_95_quantile &lt;- apply(samples, 1, quantile, p = 0.95)\nsample_99_quantile &lt;- apply(samples, 1, quantile, p = 0.99)\n\n# Compare coefficient of variation\nsd(sample_means)/mean(sample_means)\n\n[1] 0.01017306\n\nsd(sample_75_quantile)/mean(sample_75_quantile)\n\n[1] 0.0127586\n\nsd(sample_95_quantile)/mean(sample_75_quantile)\n\n[1] 0.01873297\n\n# Plot the distributions\ncombined_vec &lt;- c(sample_means, sample_75_quantile, sample_95_quantile, sample_99_quantile)\n\nplot(density(sample_means), \n     col = \"#6F69AC\", \n     lwd = 3, \n     main = \"Estimating the mean vs tail quantiles\", \n     xlab = \"\", \n     xlim = c(min(combined_vec), max(combined_vec)))\n\nlines(density(sample_75_quantile), col = \"#95DAC1\", lwd = 3)\nlines(density(sample_95_quantile), col = \"#FFEBA1\", lwd = 3)\nlines(density(sample_99_quantile), col = \"#FD6F96\", lwd = 3)\ngrid()\n\nlegend(\"topright\", \n       fill = c(\"#6F69AC\", \"#95DAC1\", \"#FFEBA1\", \"#FD6F96\"), \n       legend = c(\"Mean\", \"75% Quantile\", \"95% Quantile\", \"99% Quantile\"), \n       cex = 0.7)\n\n\n\n\n\n\n\n\nThe plot shows how uncertainty increases dramatically when estimating extreme values. The distribution for the mean (purple) is much narrower than for the 99th percentile (pink). This directly translates to credit scoring – where very high or low scores have greater uncertainty.\n\n# Load required packages\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(rsample)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/assessing-score-reliability.html#data-acquisition-and-preprocessing",
    "href": "posts/assessing-score-reliability.html#data-acquisition-and-preprocessing",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Data Acquisition and Preprocessing",
    "text": "Data Acquisition and Preprocessing\n\n# Load sample data (sample of the lending club data)\nsample &lt;- read.csv(\"http://bit.ly/42ypcnJ\")\n\n# Mark which loan status will be tagged as default\ncodes &lt;- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\n\n# Apply above codes and create target\nsample %&lt;&gt;% mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))\n\n# Replace missing values with a default value\nsample[is.na(sample)] &lt;- -1\n\n# Get summary tally\ntable(sample$bad_flag)\n\n\n   0    1 \n8838 1162 \n\n\nWe’re using Lending Club data with charged-off loans marked as defaults. The class imbalance shown is typical in credit portfolios and contributes to prediction challenges at distribution extremes."
  },
  {
    "objectID": "posts/assessing-score-reliability.html#implementing-bootstrap-resampling-strategy",
    "href": "posts/assessing-score-reliability.html#implementing-bootstrap-resampling-strategy",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Implementing Bootstrap Resampling Strategy",
    "text": "Implementing Bootstrap Resampling Strategy\nWe’ll create 100 bootstrap samples to measure how model predictions vary across the score range. This technique creates multiple simulated datasets to measure prediction uncertainty without collecting additional data.\n\n# Create 100 samples\nboot_sample &lt;- bootstraps(data = sample, times = 100)\n\nhead(boot_sample, 3)\n\n# A tibble: 3 × 2\n  splits               id          \n  &lt;list&gt;               &lt;chr&gt;       \n1 &lt;split [10000/3707]&gt; Bootstrap001\n2 &lt;split [10000/3688]&gt; Bootstrap002\n3 &lt;split [10000/3694]&gt; Bootstrap003\n\n# Each row represents a separate bootstrapped sample with an analysis set and assessment set\nboot_sample$splits[[1]]\n\n&lt;Analysis/Assess/Total&gt;\n&lt;10000/3707/10000&gt;\n\n# Show the first 5 rows and 5 columns of the first sample\nanalysis(boot_sample$splits[[1]]) %&gt;% .[1:5, 1:5]\n\n     V1       id member_id loan_amnt funded_amnt\n1 99086 11295404        -1     24000       24000\n2 88986   747883        -1     30000       30000\n3 69923 21741383        -1     14000       14000\n4 30931 10588167        -1      3500        3500\n5 64867 24044848        -1      6000        6000\n\n\nEach bootstrap sample contains random draws (with replacement) from our original data, creating slight variations that reveal model sensitivity to different data compositions."
  },
  {
    "objectID": "posts/assessing-score-reliability.html#developing-the-predictive-model-framework",
    "href": "posts/assessing-score-reliability.html#developing-the-predictive-model-framework",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Developing the Predictive Model Framework",
    "text": "Developing the Predictive Model Framework\nWe’ll use logistic regression – the standard for credit risk models due to its interpretability and regulatory acceptance. Our model includes typical credit variables like loan amount, income, and credit history metrics.\n\nglm_model &lt;- function(df){\n  \n  # Fit a simple model with a set specification\n  mdl &lt;- glm(bad_flag ~\n               loan_amnt + funded_amnt + annual_inc + delinq_2yrs +\n               inq_last_6mths + mths_since_last_delinq + fico_range_low +\n               mths_since_last_record + revol_util + total_pymnt,\n             family = \"binomial\",\n             data = df)\n  \n  # Return fitted values\n  return(predict(mdl))\n}\n\n# Test the function\n# Retrieve a data frame\ntrain &lt;- analysis(boot_sample$splits[[1]])\n\n# Predict\npred &lt;- glm_model(train)\n\n# Check output\nrange(pred)  # Output is on log odds scale\n\n[1] -20.022728   1.124628\n\n\nThe function returns predictions in log-odds, which we’ll later convert to a more intuitive credit score scale."
  },
  {
    "objectID": "posts/assessing-score-reliability.html#iterative-model-training-and-prediction-collection",
    "href": "posts/assessing-score-reliability.html#iterative-model-training-and-prediction-collection",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Iterative Model Training and Prediction Collection",
    "text": "Iterative Model Training and Prediction Collection\n\n# First apply the glm fitting function to each of the sample\n# Note the use of lapply\noutput &lt;- lapply(boot_sample$splits, function(x){\n  train &lt;- analysis(x)\n  pred &lt;- glm_model(train)\n\n  return(pred)\n})\n\n# Collate all predictions into a vector \nboot_preds &lt;- do.call(c, output)\nrange(boot_preds)\n\n[1] -141.189195    8.873295\n\n# Get outliers\nq_high &lt;- quantile(boot_preds, 0.99)\nq_low &lt;- quantile(boot_preds, 0.01)\n\n# Truncate the overall distribution to within the lower 1% and upper 1% quantiles\n# Doing this since it creates issues later on when scaling the output\nboot_preds[boot_preds &gt; q_high] &lt;- q_high\nboot_preds[boot_preds &lt; q_low] &lt;- q_low\n\nrange(boot_preds)\n\n[1] -5.0581226 -0.2312987\n\n# Convert to a data frame\nboot_preds &lt;- data.frame(pred = boot_preds, \n                         id = rep(1:length(boot_sample$splits), each = nrow(sample)))\nhead(boot_preds)\n\n        pred id\n1 -3.5243889  1\n2 -5.0220877  1\n3 -1.7385793  1\n4 -1.9862655  1\n5 -1.5898113  1\n6 -0.5679697  1\n\n\nWe apply our model to each bootstrap sample and collect the predictions, then truncate extreme values (beyond 1st and 99th percentiles) to remove outliers – similar to capping techniques used in production credit models."
  },
  {
    "objectID": "posts/assessing-score-reliability.html#transforming-predictions-to-credit-score-scale",
    "href": "posts/assessing-score-reliability.html#transforming-predictions-to-credit-score-scale",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Transforming Predictions to Credit Score Scale",
    "text": "Transforming Predictions to Credit Score Scale\nNow we’ll convert log-odds to a recognizable credit score using the industry-standard Points to Double Odds (PDO) method. Using parameters similar to real credit systems (PDO=30, Anchor=700), we transform our predictions into intuitive scores where higher numbers indicate lower risk.\n\nscaling_func &lt;- function(vec, PDO = 30, OddsAtAnchor = 5, Anchor = 700){\n  beta &lt;- PDO / log(2)\n  alpha &lt;- Anchor - PDO * OddsAtAnchor\n  \n  # Simple linear scaling of the log odds\n  scr &lt;- alpha - beta * vec  \n  \n  # Round off\n  return(round(scr, 0))\n}\n\nboot_preds$scores &lt;- scaling_func(boot_preds$pred, 30, 2, 700)\n\n# Chart the distribution of predictions across all the samples\nggplot(boot_preds, aes(x = scores, color = factor(id))) + \n  geom_density() + \n  theme_minimal() + \n  theme(legend.position = \"none\") + \n  scale_color_grey() + \n  labs(title = \"Predictions from bootstrapped samples\", \n       subtitle = \"Density function\", \n       x = \"Predictions (Log odds)\", \n       y = \"Density\")\n\n\n\n\n\n\n\n\nEach gray line shows the score distribution from a different bootstrap sample. Where lines cluster tightly, our predictions are stable; where they diverge, we have higher uncertainty."
  },
  {
    "objectID": "posts/assessing-score-reliability.html#quantifying-prediction-uncertainty-across-score-ranges",
    "href": "posts/assessing-score-reliability.html#quantifying-prediction-uncertainty-across-score-ranges",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Quantifying Prediction Uncertainty Across Score Ranges",
    "text": "Quantifying Prediction Uncertainty Across Score Ranges\nNow we can directly measure how prediction reliability varies across score ranges by calculating standard deviation within each score bin. This approach quantifies uncertainty at different score levels.\n\n# Create bins using quantiles\nbreaks &lt;- quantile(boot_preds$scores, probs = seq(0, 1, length.out = 20))\nboot_preds$bins &lt;- cut(boot_preds$scores, breaks = unique(breaks), include.lowest = T, right = T)\n\n# Chart standard deviation of model predictions across each score bin\nboot_preds %&gt;%\n  group_by(bins) %&gt;%\n  summarise(std_dev = sd(scores)) %&gt;%\n  ggplot(aes(x = bins, y = std_dev)) +\n  geom_col(color = \"black\", fill = \"#90AACB\") +\n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 90)) + \n  theme(legend.position = \"none\") + \n  labs(title = \"Variability in model predictions across samples\", \n       subtitle = \"(measured using standard deviation)\", \n       x = \"Score Range\", \n       y = \"Standard Deviation\")\n\n\n\n\n\n\n\n\nAs expected, the model’s predictions are more reliable within a certain range of values (700-800) whereas there is significant variability in the model’s predictions in the lowest and highest score buckets.\nThe chart reveals a clear “U-shape” pattern of prediction variability—a common phenomenon in credit risk modeling. The highest uncertainty appears in the extreme score ranges (very high and very low scores), while predictions in the middle range show greater stability. The chart confirms our hypothesis: variability is highest at score extremes and lowest in the middle range (600-800). This directly informs credit policy – scores in the middle range are most reliable, while decisions at the extremes should incorporate additional caution due to higher uncertainty.\nThese findings have direct business applications:\n\nFor extremely high scores, add verification steps before auto-approval\nFor very low scores, consider manual review rather than automatic rejection"
  },
  {
    "objectID": "posts/assessing-score-reliability.html#advanced-approach-isolating-training-data-effects",
    "href": "posts/assessing-score-reliability.html#advanced-approach-isolating-training-data-effects",
    "title": "Understanding Variability in Credit Score Predictions",
    "section": "Advanced Approach: Isolating Training Data Effects",
    "text": "Advanced Approach: Isolating Training Data Effects\nCredit: Richard Warnung\nFor a more controlled analysis, we can train models on bootstrap samples but evaluate them on the same validation set. This isolates the impact of training data variation:\n\nVs &lt;- function(boot_split){\n  # Train model on the bootstrapped data\n  train &lt;- analysis(boot_split)\n  \n  # Fit model\n  mdl &lt;- glm(bad_flag ~\n               loan_amnt + funded_amnt + annual_inc + delinq_2yrs +\n               inq_last_6mths + mths_since_last_delinq + fico_range_low +\n               mths_since_last_record + revol_util + total_pymnt,\n             family = \"binomial\",\n             data = train)\n  \n  # Apply to a common validation set\n  validate_preds &lt;- predict(mdl, newdata = validate_set)\n  \n  # Return predictions\n  return(validate_preds)\n}\n\nThis method provides a clearer picture of how variations in training data affect model predictions, which is valuable when evaluating model updates in production."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R'tichoke",
    "section": "",
    "text": "R’tichoke is a repository of R programming content, tutorials, and resources. Whether you’re just starting your journey with R or you’re an experienced data scientist looking to expand your toolkit, you’ll find valuable content here to help you grow your skills."
  },
  {
    "objectID": "index.html#welcome-to-rtichoke",
    "href": "index.html#welcome-to-rtichoke",
    "title": "R'tichoke",
    "section": "",
    "text": "R’tichoke is a repository of R programming content, tutorials, and resources. Whether you’re just starting your journey with R or you’re an experienced data scientist looking to expand your toolkit, you’ll find valuable content here to help you grow your skills."
  },
  {
    "objectID": "index.html#latest-articles",
    "href": "index.html#latest-articles",
    "title": "R'tichoke",
    "section": "Latest Articles",
    "text": "Latest Articles\nCheck out our blog for the latest tutorials, case studies, and tips on R programming."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "R'tichoke",
    "section": "Getting Started",
    "text": "Getting Started\nNew to R? Start here:\n\nInstalling R and RStudio - Set up your development environment\nIntroduction to Analytics with R - Learn the basics\nData Wrangling with dplyr - Level up your data manipulation skills"
  },
  {
    "objectID": "get-started/reading-data.html",
    "href": "get-started/reading-data.html",
    "title": "Reading Data into R",
    "section": "",
    "text": "R provides several built-in functions for importing data from various file formats. Here’s how to use the most common ones:\n\n\nComma-separated values (CSV) files are one of the most common data formats:\n\n# Create a sample CSV file\nwrite.csv(mtcars[1:5, ], \"sample_cars.csv\", row.names = TRUE)\n\n# Read the CSV file\ncars_data &lt;- read.csv(\"sample_cars.csv\")\nhead(cars_data)\n\n                  X  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n# Read with specific options\ncars_data2 &lt;- read.csv(\"sample_cars.csv\", \n                      header = TRUE,       # First row contains column names\n                      sep = \",\",           # Separator is a comma\n                      stringsAsFactors = FALSE, # Don't convert strings to factors\n                      na.strings = c(\"NA\", \"N/A\", \"\")) # Values to treat as NA\nhead(cars_data2)\n\n                  X  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\nTab-delimited files are another common format:\n\n# Create a sample tab-delimited file\nwrite.table(mtcars[1:5, ], \"sample_cars.txt\", sep = \"\\t\", row.names = TRUE)\n\n# Read the tab-delimited file\ncars_data_tab &lt;- read.delim(\"sample_cars.txt\")\nhead(cars_data_tab)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n# Or use read.table with tab separator\ncars_data_tab2 &lt;- read.table(\"sample_cars.txt\", \n                            header = TRUE, \n                            sep = \"\\t\")\nhead(cars_data_tab2)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\nFixed-width files have fields of consistent width:\n\n# Create a sample fixed-width file\ncat(\"John  Smith 35\\nMary  Jones 28\\nDavid Brown 42\\n\", file = \"sample_people.txt\")\n\n# Read the fixed-width file\npeople_data &lt;- read.fwf(\"sample_people.txt\", \n                       widths = c(5, 6, 3),  # Width of each column\n                       col.names = c(\"First\", \"Last\", \"Age\"))\npeople_data\n\n  First   Last Age\n1 John   Smith  35\n2 Mary   Jones  28\n3 David  Brown  42\n\n\n\n\n\nR has its own binary file format for saving and loading R objects:\n\n# Save R objects to a file\nsample_data &lt;- list(x = 1:10, y = letters[1:10])\nsave(sample_data, file = \"sample_data.RData\")\n\n# Load the saved objects\nload(\"sample_data.RData\")\nsample_data\n\n$x\n [1]  1  2  3  4  5  6  7  8  9 10\n\n$y\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n\n# Save a single object\nsaveRDS(mtcars[1:5, ], \"sample_cars.rds\")\n\n# Read the saved object\ncars_subset &lt;- readRDS(\"sample_cars.rds\")\nhead(cars_subset)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\nYou can read data directly from the web:\n\n# Read CSV from a URL (example with a small dataset)\nurl &lt;- \"https://raw.githubusercontent.com/datasets/iris/master/data/iris.csv\"\niris_data &lt;- try(read.csv(url), silent = TRUE)\n\n# Check if the data was loaded successfully\nif (!inherits(iris_data, \"try-error\")) {\n  head(iris_data)\n} else {\n  print(\"Could not access the URL. Check your internet connection.\")\n}\n\n[1] \"Could not access the URL. Check your internet connection.\"\n\n\n\n\n\nWhile not part of base R, the readxl package is commonly used:\n\n# Check if readxl is installed\nif (!requireNamespace(\"readxl\", quietly = TRUE)) {\n  message(\"The readxl package is not installed. You can install it with: install.packages('readxl')\")\n} else {\n  library(readxl)\n  # This would read an Excel file if it existed\n  # excel_data &lt;- read_excel(\"sample.xlsx\", sheet = 1)\n}\n\n\n\n\nBase R provides the DBI package for database connections:\n\n# Example of connecting to SQLite (not run)\n# if (!requireNamespace(\"RSQLite\", quietly = TRUE)) {\n#   message(\"The RSQLite package is not installed\")\n# } else {\n#   library(DBI)\n#   con &lt;- dbConnect(RSQLite::SQLite(), \":memory:\")\n#   dbWriteTable(con, \"mtcars\", mtcars)\n#   data &lt;- dbGetQuery(con, \"SELECT * FROM mtcars WHERE cyl = 4\")\n#   dbDisconnect(con)\n# }\n\n\n\n\nR provides functions to work with file paths:\n\n# Get current working directory\ngetwd()\n\n[1] \"C:/Users/riddh/OneDrive/Desktop/rtichoke/get-started\"\n\n# List files in the current directory\nlist.files(pattern = \".csv\")\n\n[1] \"sample_cars.csv\"\n\n# Check if a file exists\nfile.exists(\"sample_cars.csv\")\n\n[1] TRUE\n\n# Get full path to a file\nnormalizePath(\"sample_cars.csv\", mustWork = FALSE)\n\n[1] \"C:\\\\Users\\\\riddh\\\\OneDrive\\\\Desktop\\\\rtichoke\\\\get-started\\\\sample_cars.csv\"\n\n\n\n\n\nLet’s remove the sample files we created:\n\n# List of files to remove\nfiles_to_remove &lt;- c(\"sample_cars.csv\", \"sample_cars.txt\", \n                    \"sample_people.txt\", \"sample_data.RData\", \n                    \"sample_cars.rds\")\n\n# Remove files\nfor (file in files_to_remove) {\n  if (file.exists(file)) {\n    file.remove(file)\n  }\n}\n\nRemember to check the documentation with ?read.csv or similar commands to explore all available options for these functions."
  },
  {
    "objectID": "get-started/reading-data.html#reading-data-into-r-using-base-functions",
    "href": "get-started/reading-data.html#reading-data-into-r-using-base-functions",
    "title": "Reading Data into R",
    "section": "",
    "text": "R provides several built-in functions for importing data from various file formats. Here’s how to use the most common ones:\n\n\nComma-separated values (CSV) files are one of the most common data formats:\n\n# Create a sample CSV file\nwrite.csv(mtcars[1:5, ], \"sample_cars.csv\", row.names = TRUE)\n\n# Read the CSV file\ncars_data &lt;- read.csv(\"sample_cars.csv\")\nhead(cars_data)\n\n                  X  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n# Read with specific options\ncars_data2 &lt;- read.csv(\"sample_cars.csv\", \n                      header = TRUE,       # First row contains column names\n                      sep = \",\",           # Separator is a comma\n                      stringsAsFactors = FALSE, # Don't convert strings to factors\n                      na.strings = c(\"NA\", \"N/A\", \"\")) # Values to treat as NA\nhead(cars_data2)\n\n                  X  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\nTab-delimited files are another common format:\n\n# Create a sample tab-delimited file\nwrite.table(mtcars[1:5, ], \"sample_cars.txt\", sep = \"\\t\", row.names = TRUE)\n\n# Read the tab-delimited file\ncars_data_tab &lt;- read.delim(\"sample_cars.txt\")\nhead(cars_data_tab)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n# Or use read.table with tab separator\ncars_data_tab2 &lt;- read.table(\"sample_cars.txt\", \n                            header = TRUE, \n                            sep = \"\\t\")\nhead(cars_data_tab2)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\nFixed-width files have fields of consistent width:\n\n# Create a sample fixed-width file\ncat(\"John  Smith 35\\nMary  Jones 28\\nDavid Brown 42\\n\", file = \"sample_people.txt\")\n\n# Read the fixed-width file\npeople_data &lt;- read.fwf(\"sample_people.txt\", \n                       widths = c(5, 6, 3),  # Width of each column\n                       col.names = c(\"First\", \"Last\", \"Age\"))\npeople_data\n\n  First   Last Age\n1 John   Smith  35\n2 Mary   Jones  28\n3 David  Brown  42\n\n\n\n\n\nR has its own binary file format for saving and loading R objects:\n\n# Save R objects to a file\nsample_data &lt;- list(x = 1:10, y = letters[1:10])\nsave(sample_data, file = \"sample_data.RData\")\n\n# Load the saved objects\nload(\"sample_data.RData\")\nsample_data\n\n$x\n [1]  1  2  3  4  5  6  7  8  9 10\n\n$y\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n\n# Save a single object\nsaveRDS(mtcars[1:5, ], \"sample_cars.rds\")\n\n# Read the saved object\ncars_subset &lt;- readRDS(\"sample_cars.rds\")\nhead(cars_subset)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\n\n\n\nYou can read data directly from the web:\n\n# Read CSV from a URL (example with a small dataset)\nurl &lt;- \"https://raw.githubusercontent.com/datasets/iris/master/data/iris.csv\"\niris_data &lt;- try(read.csv(url), silent = TRUE)\n\n# Check if the data was loaded successfully\nif (!inherits(iris_data, \"try-error\")) {\n  head(iris_data)\n} else {\n  print(\"Could not access the URL. Check your internet connection.\")\n}\n\n[1] \"Could not access the URL. Check your internet connection.\"\n\n\n\n\n\nWhile not part of base R, the readxl package is commonly used:\n\n# Check if readxl is installed\nif (!requireNamespace(\"readxl\", quietly = TRUE)) {\n  message(\"The readxl package is not installed. You can install it with: install.packages('readxl')\")\n} else {\n  library(readxl)\n  # This would read an Excel file if it existed\n  # excel_data &lt;- read_excel(\"sample.xlsx\", sheet = 1)\n}\n\n\n\n\nBase R provides the DBI package for database connections:\n\n# Example of connecting to SQLite (not run)\n# if (!requireNamespace(\"RSQLite\", quietly = TRUE)) {\n#   message(\"The RSQLite package is not installed\")\n# } else {\n#   library(DBI)\n#   con &lt;- dbConnect(RSQLite::SQLite(), \":memory:\")\n#   dbWriteTable(con, \"mtcars\", mtcars)\n#   data &lt;- dbGetQuery(con, \"SELECT * FROM mtcars WHERE cyl = 4\")\n#   dbDisconnect(con)\n# }\n\n\n\n\nR provides functions to work with file paths:\n\n# Get current working directory\ngetwd()\n\n[1] \"C:/Users/riddh/OneDrive/Desktop/rtichoke/get-started\"\n\n# List files in the current directory\nlist.files(pattern = \".csv\")\n\n[1] \"sample_cars.csv\"\n\n# Check if a file exists\nfile.exists(\"sample_cars.csv\")\n\n[1] TRUE\n\n# Get full path to a file\nnormalizePath(\"sample_cars.csv\", mustWork = FALSE)\n\n[1] \"C:\\\\Users\\\\riddh\\\\OneDrive\\\\Desktop\\\\rtichoke\\\\get-started\\\\sample_cars.csv\"\n\n\n\n\n\nLet’s remove the sample files we created:\n\n# List of files to remove\nfiles_to_remove &lt;- c(\"sample_cars.csv\", \"sample_cars.txt\", \n                    \"sample_people.txt\", \"sample_data.RData\", \n                    \"sample_cars.rds\")\n\n# Remove files\nfor (file in files_to_remove) {\n  if (file.exists(file)) {\n    file.remove(file)\n  }\n}\n\nRemember to check the documentation with ?read.csv or similar commands to explore all available options for these functions."
  },
  {
    "objectID": "get-started/loops.html",
    "href": "get-started/loops.html",
    "title": "Loops and Apply Functions in R",
    "section": "",
    "text": "R offers several ways to perform repetitive tasks through loops and the more efficient apply family of functions.\n\n\nThe for loop iterates over elements in a sequence:\n\n# Basic for loop\nfor (i in 1:5) {\n  print(paste(\"Iteration:\", i))\n}\n\n[1] \"Iteration: 1\"\n[1] \"Iteration: 2\"\n[1] \"Iteration: 3\"\n[1] \"Iteration: 4\"\n[1] \"Iteration: 5\"\n\n# Looping through a vector\nfruits &lt;- c(\"apple\", \"banana\", \"cherry\")\nfor (fruit in fruits) {\n  print(paste(\"I like\", fruit))\n}\n\n[1] \"I like apple\"\n[1] \"I like banana\"\n[1] \"I like cherry\"\n\n\n\n\n\nThe while loop continues until a condition becomes false:\n\n# Basic while loop\ncounter &lt;- 1\nwhile (counter &lt;= 5) {\n  print(paste(\"Count:\", counter))\n  counter &lt;- counter + 1\n}\n\n[1] \"Count: 1\"\n[1] \"Count: 2\"\n[1] \"Count: 3\"\n[1] \"Count: 4\"\n[1] \"Count: 5\"\n\n\n\n\n\nThe repeat loop runs indefinitely until a break statement:\n\n# Repeat loop with break\ncounter &lt;- 1\nrepeat {\n  print(paste(\"Count:\", counter))\n  counter &lt;- counter + 1\n  if (counter &gt; 5) {\n    break\n  }\n}\n\n[1] \"Count: 1\"\n[1] \"Count: 2\"\n[1] \"Count: 3\"\n[1] \"Count: 4\"\n[1] \"Count: 5\"\n\n\n\n\n\nUse break to exit a loop and next to skip to the next iteration:\n\n# Using next to skip iterations\nfor (i in 1:10) {\n  if (i %% 2 == 0) {  # Skip even numbers\n    next\n  }\n  print(paste(\"Odd number:\", i))\n}\n\n[1] \"Odd number: 1\"\n[1] \"Odd number: 3\"\n[1] \"Odd number: 5\"\n[1] \"Odd number: 7\"\n[1] \"Odd number: 9\""
  },
  {
    "objectID": "get-started/loops.html#loops-and-apply-functions-in-r",
    "href": "get-started/loops.html#loops-and-apply-functions-in-r",
    "title": "Loops and Apply Functions in R",
    "section": "",
    "text": "R offers several ways to perform repetitive tasks through loops and the more efficient apply family of functions.\n\n\nThe for loop iterates over elements in a sequence:\n\n# Basic for loop\nfor (i in 1:5) {\n  print(paste(\"Iteration:\", i))\n}\n\n[1] \"Iteration: 1\"\n[1] \"Iteration: 2\"\n[1] \"Iteration: 3\"\n[1] \"Iteration: 4\"\n[1] \"Iteration: 5\"\n\n# Looping through a vector\nfruits &lt;- c(\"apple\", \"banana\", \"cherry\")\nfor (fruit in fruits) {\n  print(paste(\"I like\", fruit))\n}\n\n[1] \"I like apple\"\n[1] \"I like banana\"\n[1] \"I like cherry\"\n\n\n\n\n\nThe while loop continues until a condition becomes false:\n\n# Basic while loop\ncounter &lt;- 1\nwhile (counter &lt;= 5) {\n  print(paste(\"Count:\", counter))\n  counter &lt;- counter + 1\n}\n\n[1] \"Count: 1\"\n[1] \"Count: 2\"\n[1] \"Count: 3\"\n[1] \"Count: 4\"\n[1] \"Count: 5\"\n\n\n\n\n\nThe repeat loop runs indefinitely until a break statement:\n\n# Repeat loop with break\ncounter &lt;- 1\nrepeat {\n  print(paste(\"Count:\", counter))\n  counter &lt;- counter + 1\n  if (counter &gt; 5) {\n    break\n  }\n}\n\n[1] \"Count: 1\"\n[1] \"Count: 2\"\n[1] \"Count: 3\"\n[1] \"Count: 4\"\n[1] \"Count: 5\"\n\n\n\n\n\nUse break to exit a loop and next to skip to the next iteration:\n\n# Using next to skip iterations\nfor (i in 1:10) {\n  if (i %% 2 == 0) {  # Skip even numbers\n    next\n  }\n  print(paste(\"Odd number:\", i))\n}\n\n[1] \"Odd number: 1\"\n[1] \"Odd number: 3\"\n[1] \"Odd number: 5\"\n[1] \"Odd number: 7\"\n[1] \"Odd number: 9\""
  },
  {
    "objectID": "get-started/loops.html#apply-functions",
    "href": "get-started/loops.html#apply-functions",
    "title": "Loops and Apply Functions in R",
    "section": "Apply Functions",
    "text": "Apply Functions\nThe apply family of functions offers a more efficient and concise way to perform iterations in R.\n\napply() - For matrices and arrays\n\n# Create a matrix\nmat &lt;- matrix(1:9, nrow = 3)\nprint(mat)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n# Apply sum function to each row\napply(mat, 1, sum)  # MARGIN=1 for rows\n\n[1] 12 15 18\n\n# Apply mean function to each column\napply(mat, 2, mean)  # MARGIN=2 for columns\n\n[1] 2 5 8\n\n\n\n\nlapply() - For lists, returns a list\n\n# List of vectors\nmy_list &lt;- list(a = 1:3, b = 4:6, c = 7:9)\n\n# Apply function to each element\nlapply(my_list, sum)\n\n$a\n[1] 6\n\n$b\n[1] 15\n\n$c\n[1] 24\n\n\n\n\nsapply() - Simplified apply, returns vector or matrix\n\n# Same as above but with simplified output\nsapply(my_list, sum)\n\n a  b  c \n 6 15 24 \n\n# Using with a custom function\nsapply(my_list, function(x) x * 2)\n\n     a  b  c\n[1,] 2  8 14\n[2,] 4 10 16\n[3,] 6 12 18\n\n\n\n\nvapply() - Like sapply but with pre-specified output type\n\n# Specify the output type for safety\nvapply(my_list, sum, FUN.VALUE = numeric(1))\n\n a  b  c \n 6 15 24 \n\n\n\n\ntapply() - Apply function to subsets of a vector\n\n# Vector and grouping factor\nvalues &lt;- c(1, 2, 3, 4, 5, 6, 7, 8)\ngroups &lt;- c(\"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\")\n\n# Calculate mean by group\ntapply(values, groups, mean)\n\nA B \n4 5 \n\n\n\n\nmapply() - Multivariate version of sapply\n\n# Apply function to multiple lists in parallel\nmapply(sum, list(1:3), list(4:6), list(7:9))\n\n[1] 45\n\n# Create strings with multiple inputs\nmapply(paste, \"X\", 1:5, \"Y\", SIMPLIFY = TRUE)\n\n      X    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt;    &lt;NA&gt; \n\"X 1 Y\" \"X 2 Y\" \"X 3 Y\" \"X 4 Y\" \"X 5 Y\" \n\n\nThe apply family of functions is generally preferred over loops in R because they are: 1. More concise and readable 2. Often faster for large datasets 3. Aligned with R’s vectorized approach to data processing"
  },
  {
    "objectID": "get-started/ggplot2.html",
    "href": "get-started/ggplot2.html",
    "title": "Introduction to ggplot2 Graphics",
    "section": "",
    "text": "The ggplot2 package, part of the tidyverse, implements the Grammar of Graphics to create elegant and complex plots with a consistent syntax. It’s one of the most popular visualization packages in R.\n\n\nFirst, let’s install and load the package:\n\n# Install if needed (uncomment to run)\n# install.packages(\"ggplot2\")\n\n# Load the package\nlibrary(ggplot2)\n\n# We'll use the built-in mtcars dataset\ndata(mtcars)\n\n\n\n\nggplot2 is based on the idea that you can build any plot from the same components:\n\nData: The dataset you want to visualize\nAesthetics: Mapping of variables to visual properties\nGeometries: Visual elements representing data points\nFacets: For creating small multiples\nStatistics: Statistical transformations of the data\nCoordinates: The coordinate system\nThemes: Controlling the visual style\n\n\n\n\nEvery ggplot2 plot starts with the ggplot() function and builds with layers:\n\n# Basic scatter plot\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Enhanced scatter plot\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl), size = hp)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    title = \"Car Weight vs. Fuel Efficiency\",\n    subtitle = \"Colored by cylinder count, sized by horsepower\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles Per Gallon\",\n    color = \"Cylinders\",\n    size = \"Horsepower\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n# Create sample time series data\ntime_data &lt;- data.frame(\n  time = 1:20,\n  value = cumsum(rnorm(20))\n)\n\n# Line plot\nggplot(time_data, aes(x = time, y = value)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_point(color = \"steelblue\", size = 2) +\n  labs(title = \"Time Series Plot\", x = \"Time\", y = \"Value\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Count of cars by cylinder\nggplot(mtcars, aes(x = factor(cyl))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Count of Cars by Cylinder\", x = \"Cylinders\", y = \"Count\")\n\n\n\n\n\n\n\n# Bar chart with values\ncyl_summary &lt;- as.data.frame(table(mtcars$cyl))\nnames(cyl_summary) &lt;- c(\"cyl\", \"count\")\n\nggplot(cyl_summary, aes(x = cyl, y = count)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = count), vjust = -0.5) +\n  labs(title = \"Count of Cars by Cylinder\", x = \"Cylinders\", y = \"Count\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Histogram\nggplot(mtcars, aes(x = mpg)) +\n  geom_histogram(bins = 10, fill = \"steelblue\", color = \"white\") +\n  labs(title = \"Distribution of Fuel Efficiency\", x = \"Miles Per Gallon\", y = \"Count\")\n\n\n\n\n\n\n\n# Density plot\nggplot(mtcars, aes(x = mpg)) +\n  geom_density(fill = \"steelblue\", alpha = 0.5) +\n  labs(title = \"Density of Fuel Efficiency\", x = \"Miles Per Gallon\", y = \"Density\")\n\n\n\n\n\n\n\n# Combined histogram and density\nggplot(mtcars, aes(x = mpg)) +\n  geom_histogram(aes(y = ..density..), bins = 10, fill = \"lightblue\", color = \"white\") +\n  geom_density(color = \"darkblue\", size = 1) +\n  labs(title = \"Distribution of Fuel Efficiency\", x = \"Miles Per Gallon\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Box plot\nggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"lightblue\") +\n  labs(title = \"Fuel Efficiency by Cylinder Count\", x = \"Cylinders\", y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\n# Box plot with points\nggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"lightblue\", outlier.shape = NA) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(title = \"Fuel Efficiency by Cylinder Count\", x = \"Cylinders\", y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\n\n\n\n\n\nYou can map variables to various aesthetic properties:\n\n# Multiple aesthetics\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl), shape = factor(am), size = hp)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    title = \"Car Weight vs. Fuel Efficiency\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles Per Gallon\",\n    color = \"Cylinders\",\n    shape = \"Transmission\",\n    size = \"Horsepower\"\n  ) +\n  scale_shape_discrete(labels = c(\"Automatic\", \"Manual\"))\n\n\n\n\n\n\n\n\n\n\n\nFaceting creates separate plots for subsets of data:\n\n# Facet by transmission type\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() +\n  facet_wrap(~am, labeller = labeller(am = c(\"0\" = \"Automatic\", \"1\" = \"Manual\"))) +\n  labs(title = \"Weight vs. MPG by Transmission Type\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\")\n\n\n\n\n\n\n\n# Facet grid with two variables\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  facet_grid(vs ~ gear, labeller = labeller(\n    vs = c(\"0\" = \"V-Engine\", \"1\" = \"Straight Engine\"),\n    gear = c(\"3\" = \"3 Gears\", \"4\" = \"4 Gears\", \"5\" = \"5 Gears\")\n  )) +\n  labs(title = \"Weight vs. MPG by Engine Type and Gear Count\")\n\n\n\n\n\n\n\n\n\n\n\nggplot2 can add statistical summaries to plots:\n\n# Scatter plot with linear regression line\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"Weight vs. MPG with Linear Trend\", x = \"Weight\", y = \"MPG\")\n\n\n\n\n\n\n\n# Scatter plot with different smoothing methods by cylinder\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Weight vs. MPG by Cylinder\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\")\n\n\n\n\n\n\n\n\n\n\n\nChange how the data is mapped to the plotting area:\n\n# Flip coordinates\nggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"lightblue\") +\n  coord_flip() +\n  labs(title = \"Fuel Efficiency by Cylinder Count\", x = \"Cylinders\", y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\n# Polar coordinates for a pie chart\nggplot(cyl_summary, aes(x = \"\", y = count, fill = cyl)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  labs(title = \"Cars by Cylinder Count\", fill = \"Cylinders\") +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nThemes control the non-data elements of the plot:\n\n# Default theme\np &lt;- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() +\n  labs(title = \"Weight vs. MPG by Cylinder Count\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\")\n\n# Different built-in themes\np + theme_minimal()\n\n\n\n\n\n\n\np + theme_classic()\n\n\n\n\n\n\n\np + theme_dark()\n\n\n\n\n\n\n\np + theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nYou can customize specific theme elements:\n\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Custom Themed Plot\",\n    subtitle = \"Weight vs. MPG by Cylinder Count\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles Per Gallon\",\n    color = \"Cylinders\"\n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, color = \"gray50\"),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    legend.position = \"top\",\n    legend.background = element_rect(fill = \"lightyellow\", color = \"gray\"),\n    panel.background = element_rect(fill = \"white\"),\n    panel.grid.major = element_line(color = \"gray90\"),\n    panel.grid.minor = element_line(color = \"gray95\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nThe patchwork package makes it easy to combine multiple ggplots:\n\n# Create three different plots\nif (requireNamespace(\"patchwork\", quietly = TRUE)) {\n  library(patchwork)\n  \n  p1 &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +\n    geom_point() +\n    labs(title = \"Weight vs. MPG\")\n  \n  p2 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) +\n    geom_point(color = \"red\") +\n    labs(title = \"Horsepower vs. MPG\")\n  \n  p3 &lt;- ggplot(mtcars, aes(x = factor(cyl))) +\n    geom_bar(fill = \"steelblue\") +\n    labs(title = \"Count by Cylinders\")\n  \n  # Combine plots\n  p1 + p2 + p3 + plot_layout(ncol = 2)\n} else {\n  message(\"The patchwork package is not installed. Install with: install.packages('patchwork')\")\n}\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a plot to save\np &lt;- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  labs(title = \"Weight vs. MPG\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\") +\n  theme_minimal()\n\n# Example of how to save (not run)\n# ggsave(\"my_ggplot.png\", plot = p, width = 8, height = 6, dpi = 300)\n# ggsave(\"my_ggplot.pdf\", plot = p, width = 8, height = 6)\n\nggplot2 offers a powerful and flexible system for creating visualizations in R. Its consistent syntax and layered approach make it possible to create both simple and complex plots with the same basic structure."
  },
  {
    "objectID": "get-started/ggplot2.html#introduction-to-ggplot2-graphics",
    "href": "get-started/ggplot2.html#introduction-to-ggplot2-graphics",
    "title": "Introduction to ggplot2 Graphics",
    "section": "",
    "text": "The ggplot2 package, part of the tidyverse, implements the Grammar of Graphics to create elegant and complex plots with a consistent syntax. It’s one of the most popular visualization packages in R.\n\n\nFirst, let’s install and load the package:\n\n# Install if needed (uncomment to run)\n# install.packages(\"ggplot2\")\n\n# Load the package\nlibrary(ggplot2)\n\n# We'll use the built-in mtcars dataset\ndata(mtcars)\n\n\n\n\nggplot2 is based on the idea that you can build any plot from the same components:\n\nData: The dataset you want to visualize\nAesthetics: Mapping of variables to visual properties\nGeometries: Visual elements representing data points\nFacets: For creating small multiples\nStatistics: Statistical transformations of the data\nCoordinates: The coordinate system\nThemes: Controlling the visual style\n\n\n\n\nEvery ggplot2 plot starts with the ggplot() function and builds with layers:\n\n# Basic scatter plot\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Enhanced scatter plot\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl), size = hp)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    title = \"Car Weight vs. Fuel Efficiency\",\n    subtitle = \"Colored by cylinder count, sized by horsepower\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles Per Gallon\",\n    color = \"Cylinders\",\n    size = \"Horsepower\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n# Create sample time series data\ntime_data &lt;- data.frame(\n  time = 1:20,\n  value = cumsum(rnorm(20))\n)\n\n# Line plot\nggplot(time_data, aes(x = time, y = value)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_point(color = \"steelblue\", size = 2) +\n  labs(title = \"Time Series Plot\", x = \"Time\", y = \"Value\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Count of cars by cylinder\nggplot(mtcars, aes(x = factor(cyl))) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Count of Cars by Cylinder\", x = \"Cylinders\", y = \"Count\")\n\n\n\n\n\n\n\n# Bar chart with values\ncyl_summary &lt;- as.data.frame(table(mtcars$cyl))\nnames(cyl_summary) &lt;- c(\"cyl\", \"count\")\n\nggplot(cyl_summary, aes(x = cyl, y = count)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = count), vjust = -0.5) +\n  labs(title = \"Count of Cars by Cylinder\", x = \"Cylinders\", y = \"Count\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Histogram\nggplot(mtcars, aes(x = mpg)) +\n  geom_histogram(bins = 10, fill = \"steelblue\", color = \"white\") +\n  labs(title = \"Distribution of Fuel Efficiency\", x = \"Miles Per Gallon\", y = \"Count\")\n\n\n\n\n\n\n\n# Density plot\nggplot(mtcars, aes(x = mpg)) +\n  geom_density(fill = \"steelblue\", alpha = 0.5) +\n  labs(title = \"Density of Fuel Efficiency\", x = \"Miles Per Gallon\", y = \"Density\")\n\n\n\n\n\n\n\n# Combined histogram and density\nggplot(mtcars, aes(x = mpg)) +\n  geom_histogram(aes(y = ..density..), bins = 10, fill = \"lightblue\", color = \"white\") +\n  geom_density(color = \"darkblue\", size = 1) +\n  labs(title = \"Distribution of Fuel Efficiency\", x = \"Miles Per Gallon\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Box plot\nggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"lightblue\") +\n  labs(title = \"Fuel Efficiency by Cylinder Count\", x = \"Cylinders\", y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\n# Box plot with points\nggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"lightblue\", outlier.shape = NA) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(title = \"Fuel Efficiency by Cylinder Count\", x = \"Cylinders\", y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\n\n\n\n\n\nYou can map variables to various aesthetic properties:\n\n# Multiple aesthetics\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl), shape = factor(am), size = hp)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    title = \"Car Weight vs. Fuel Efficiency\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles Per Gallon\",\n    color = \"Cylinders\",\n    shape = \"Transmission\",\n    size = \"Horsepower\"\n  ) +\n  scale_shape_discrete(labels = c(\"Automatic\", \"Manual\"))\n\n\n\n\n\n\n\n\n\n\n\nFaceting creates separate plots for subsets of data:\n\n# Facet by transmission type\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() +\n  facet_wrap(~am, labeller = labeller(am = c(\"0\" = \"Automatic\", \"1\" = \"Manual\"))) +\n  labs(title = \"Weight vs. MPG by Transmission Type\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\")\n\n\n\n\n\n\n\n# Facet grid with two variables\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  facet_grid(vs ~ gear, labeller = labeller(\n    vs = c(\"0\" = \"V-Engine\", \"1\" = \"Straight Engine\"),\n    gear = c(\"3\" = \"3 Gears\", \"4\" = \"4 Gears\", \"5\" = \"5 Gears\")\n  )) +\n  labs(title = \"Weight vs. MPG by Engine Type and Gear Count\")\n\n\n\n\n\n\n\n\n\n\n\nggplot2 can add statistical summaries to plots:\n\n# Scatter plot with linear regression line\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"Weight vs. MPG with Linear Trend\", x = \"Weight\", y = \"MPG\")\n\n\n\n\n\n\n\n# Scatter plot with different smoothing methods by cylinder\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() +\n  geom_smooth(se = FALSE) +\n  labs(title = \"Weight vs. MPG by Cylinder\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\")\n\n\n\n\n\n\n\n\n\n\n\nChange how the data is mapped to the plotting area:\n\n# Flip coordinates\nggplot(mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot(fill = \"lightblue\") +\n  coord_flip() +\n  labs(title = \"Fuel Efficiency by Cylinder Count\", x = \"Cylinders\", y = \"Miles Per Gallon\")\n\n\n\n\n\n\n\n# Polar coordinates for a pie chart\nggplot(cyl_summary, aes(x = \"\", y = count, fill = cyl)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  labs(title = \"Cars by Cylinder Count\", fill = \"Cylinders\") +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nThemes control the non-data elements of the plot:\n\n# Default theme\np &lt;- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point() +\n  labs(title = \"Weight vs. MPG by Cylinder Count\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\")\n\n# Different built-in themes\np + theme_minimal()\n\n\n\n\n\n\n\np + theme_classic()\n\n\n\n\n\n\n\np + theme_dark()\n\n\n\n\n\n\n\np + theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nYou can customize specific theme elements:\n\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  labs(\n    title = \"Custom Themed Plot\",\n    subtitle = \"Weight vs. MPG by Cylinder Count\",\n    x = \"Weight (1000 lbs)\",\n    y = \"Miles Per Gallon\",\n    color = \"Cylinders\"\n  ) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, color = \"gray50\"),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    legend.position = \"top\",\n    legend.background = element_rect(fill = \"lightyellow\", color = \"gray\"),\n    panel.background = element_rect(fill = \"white\"),\n    panel.grid.major = element_line(color = \"gray90\"),\n    panel.grid.minor = element_line(color = \"gray95\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nThe patchwork package makes it easy to combine multiple ggplots:\n\n# Create three different plots\nif (requireNamespace(\"patchwork\", quietly = TRUE)) {\n  library(patchwork)\n  \n  p1 &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +\n    geom_point() +\n    labs(title = \"Weight vs. MPG\")\n  \n  p2 &lt;- ggplot(mtcars, aes(x = hp, y = mpg)) +\n    geom_point(color = \"red\") +\n    labs(title = \"Horsepower vs. MPG\")\n  \n  p3 &lt;- ggplot(mtcars, aes(x = factor(cyl))) +\n    geom_bar(fill = \"steelblue\") +\n    labs(title = \"Count by Cylinders\")\n  \n  # Combine plots\n  p1 + p2 + p3 + plot_layout(ncol = 2)\n} else {\n  message(\"The patchwork package is not installed. Install with: install.packages('patchwork')\")\n}\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a plot to save\np &lt;- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  labs(title = \"Weight vs. MPG\", x = \"Weight\", y = \"MPG\", color = \"Cylinders\") +\n  theme_minimal()\n\n# Example of how to save (not run)\n# ggsave(\"my_ggplot.png\", plot = p, width = 8, height = 6, dpi = 300)\n# ggsave(\"my_ggplot.pdf\", plot = p, width = 8, height = 6)\n\nggplot2 offers a powerful and flexible system for creating visualizations in R. Its consistent syntax and layered approach make it possible to create both simple and complex plots with the same basic structure."
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html",
    "href": "get-started/data-wrangling-with-dplyr.html",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "The dplyr package is part of the tidyverse and provides a grammar for data manipulation in R. This post will demonstrate some essential data wrangling techniques using built-in datasets.\n\n\nFirst, let’s load the necessary packages:\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)\n\n\n\n\nWe’ll use the built-in mtcars dataset for our examples:\n\n# Look at the mtcars data\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n\n\n\n\n\n# Find all cars with 6 cylinders\nsix_cyl &lt;- mtcars %&gt;% \n  filter(cyl == 6)\n\n# Show the first few rows\nhead(six_cyl) %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\n\n\n\n\n\n\n\n# Select only specific columns\ncar_data &lt;- mtcars %&gt;% \n  select(mpg, cyl, hp, wt)\n\nhead(car_data) %&gt;%\n  kable()\n\n\n\n\n\nmpg\ncyl\nhp\nwt\n\n\n\n\nMazda RX4\n21.0\n6\n110\n2.620\n\n\nMazda RX4 Wag\n21.0\n6\n110\n2.875\n\n\nDatsun 710\n22.8\n4\n93\n2.320\n\n\nHornet 4 Drive\n21.4\n6\n110\n3.215\n\n\nHornet Sportabout\n18.7\n8\n175\n3.440\n\n\nValiant\n18.1\n6\n105\n3.460\n\n\n\n\n\n\n\n\n\n# Find the cars with best fuel efficiency\nmost_efficient &lt;- mtcars %&gt;% \n  arrange(desc(mpg)) %&gt;%\n  select(mpg, cyl, hp, wt)\n\nhead(most_efficient) %&gt;%\n  kable()\n\n\n\n\n\nmpg\ncyl\nhp\nwt\n\n\n\n\nToyota Corolla\n33.9\n4\n65\n1.835\n\n\nFiat 128\n32.4\n4\n66\n2.200\n\n\nHonda Civic\n30.4\n4\n52\n1.615\n\n\nLotus Europa\n30.4\n4\n113\n1.513\n\n\nFiat X1-9\n27.3\n4\n66\n1.935\n\n\nPorsche 914-2\n26.0\n4\n91\n2.140\n\n\n\n\n\n\n\n\n\n# Calculate power-to-weight ratio\ncar_stats &lt;- mtcars %&gt;% \n  mutate(\n    power_to_weight = hp / wt,\n    efficiency_score = mpg * (1/wt)\n  ) %&gt;%\n  select(mpg, hp, wt, power_to_weight, efficiency_score)\n\nhead(car_stats) %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\nhp\nwt\npower_to_weight\nefficiency_score\n\n\n\n\nMazda RX4\n21.0\n110\n2.620\n41.98473\n8.015267\n\n\nMazda RX4 Wag\n21.0\n110\n2.875\n38.26087\n7.304348\n\n\nDatsun 710\n22.8\n93\n2.320\n40.08621\n9.827586\n\n\nHornet 4 Drive\n21.4\n110\n3.215\n34.21462\n6.656299\n\n\nHornet Sportabout\n18.7\n175\n3.440\n50.87209\n5.436046\n\n\nValiant\n18.1\n105\n3.460\n30.34682\n5.231214\n\n\n\n\n\n\n\n\n\n# Calculate average stats by cylinder count\ncyl_stats &lt;- mtcars %&gt;% \n  group_by(cyl) %&gt;%\n  summarize(\n    avg_mpg = mean(mpg),\n    avg_hp = mean(hp),\n    count = n()\n  ) %&gt;%\n  arrange(cyl)\n\ncyl_stats %&gt;%\n  kable()\n\n\n\n\ncyl\navg_mpg\navg_hp\ncount\n\n\n\n\n4\n26.66364\n82.63636\n11\n\n\n6\n19.74286\n122.28571\n7\n\n\n8\n15.10000\n209.21429\n14\n\n\n\n\n\n\n\n\n\n\n# Plot average mpg by cylinder count\nggplot(cyl_stats, aes(x = factor(cyl), y = avg_mpg)) +\n  geom_col(aes(fill = avg_hp)) +\n  geom_text(aes(label = round(avg_mpg, 1)), vjust = -0.5) +\n  scale_fill_viridis_c() +\n  labs(\n    title = \"Average Fuel Efficiency by Cylinder Count\",\n    subtitle = \"Color indicates average horsepower\",\n    x = \"Number of Cylinders\",\n    y = \"Average MPG\",\n    fill = \"Avg. Horsepower\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nLet’s also explore another built-in dataset, iris:\n\n# Look at the iris data\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\n\n\n\n# Calculate average measurements by species\niris_stats &lt;- iris %&gt;%\n  group_by(Species) %&gt;%\n  summarize(\n    avg_sepal_length = mean(Sepal.Length),\n    avg_sepal_width = mean(Sepal.Width),\n    avg_petal_length = mean(Petal.Length),\n    avg_petal_width = mean(Petal.Width),\n    count = n()\n  )\n\niris_stats %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies\navg_sepal_length\navg_sepal_width\navg_petal_length\navg_petal_width\ncount\n\n\n\n\nsetosa\n5.006\n3.428\n1.462\n0.246\n50\n\n\nversicolor\n5.936\n2.770\n4.260\n1.326\n50\n\n\nvirginica\n6.588\n2.974\n5.552\n2.026\n50\n\n\n\n\n\n\n\n\n\n# Create a scatter plot with multiple dimensions\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Iris Dataset: Sepal Dimensions by Species\",\n    x = \"Sepal Length (cm)\",\n    y = \"Sepal Width (cm)\"\n  ) +\n  theme_minimal() +\n  facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\n\n\n\nThe dplyr package provides a consistent and intuitive way to manipulate data in R. By mastering these basic functions, you’ll be well on your way to efficient data analysis workflows.\nIn the next post, we’ll explore how to combine these techniques with other packages in the tidyverse for even more powerful data analysis."
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html#setup",
    "href": "get-started/data-wrangling-with-dplyr.html#setup",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "First, let’s load the necessary packages:\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(knitr)"
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html#working-with-the-mtcars-dataset",
    "href": "get-started/data-wrangling-with-dplyr.html#working-with-the-mtcars-dataset",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "We’ll use the built-in mtcars dataset for our examples:\n\n# Look at the mtcars data\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…"
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html#basic-dplyr-functions",
    "href": "get-started/data-wrangling-with-dplyr.html#basic-dplyr-functions",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "# Find all cars with 6 cylinders\nsix_cyl &lt;- mtcars %&gt;% \n  filter(cyl == 6)\n\n# Show the first few rows\nhead(six_cyl) %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\n\n\n\n\n\n\n\n# Select only specific columns\ncar_data &lt;- mtcars %&gt;% \n  select(mpg, cyl, hp, wt)\n\nhead(car_data) %&gt;%\n  kable()\n\n\n\n\n\nmpg\ncyl\nhp\nwt\n\n\n\n\nMazda RX4\n21.0\n6\n110\n2.620\n\n\nMazda RX4 Wag\n21.0\n6\n110\n2.875\n\n\nDatsun 710\n22.8\n4\n93\n2.320\n\n\nHornet 4 Drive\n21.4\n6\n110\n3.215\n\n\nHornet Sportabout\n18.7\n8\n175\n3.440\n\n\nValiant\n18.1\n6\n105\n3.460\n\n\n\n\n\n\n\n\n\n# Find the cars with best fuel efficiency\nmost_efficient &lt;- mtcars %&gt;% \n  arrange(desc(mpg)) %&gt;%\n  select(mpg, cyl, hp, wt)\n\nhead(most_efficient) %&gt;%\n  kable()\n\n\n\n\n\nmpg\ncyl\nhp\nwt\n\n\n\n\nToyota Corolla\n33.9\n4\n65\n1.835\n\n\nFiat 128\n32.4\n4\n66\n2.200\n\n\nHonda Civic\n30.4\n4\n52\n1.615\n\n\nLotus Europa\n30.4\n4\n113\n1.513\n\n\nFiat X1-9\n27.3\n4\n66\n1.935\n\n\nPorsche 914-2\n26.0\n4\n91\n2.140\n\n\n\n\n\n\n\n\n\n# Calculate power-to-weight ratio\ncar_stats &lt;- mtcars %&gt;% \n  mutate(\n    power_to_weight = hp / wt,\n    efficiency_score = mpg * (1/wt)\n  ) %&gt;%\n  select(mpg, hp, wt, power_to_weight, efficiency_score)\n\nhead(car_stats) %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\nhp\nwt\npower_to_weight\nefficiency_score\n\n\n\n\nMazda RX4\n21.0\n110\n2.620\n41.98473\n8.015267\n\n\nMazda RX4 Wag\n21.0\n110\n2.875\n38.26087\n7.304348\n\n\nDatsun 710\n22.8\n93\n2.320\n40.08621\n9.827586\n\n\nHornet 4 Drive\n21.4\n110\n3.215\n34.21462\n6.656299\n\n\nHornet Sportabout\n18.7\n175\n3.440\n50.87209\n5.436046\n\n\nValiant\n18.1\n105\n3.460\n30.34682\n5.231214\n\n\n\n\n\n\n\n\n\n# Calculate average stats by cylinder count\ncyl_stats &lt;- mtcars %&gt;% \n  group_by(cyl) %&gt;%\n  summarize(\n    avg_mpg = mean(mpg),\n    avg_hp = mean(hp),\n    count = n()\n  ) %&gt;%\n  arrange(cyl)\n\ncyl_stats %&gt;%\n  kable()\n\n\n\n\ncyl\navg_mpg\navg_hp\ncount\n\n\n\n\n4\n26.66364\n82.63636\n11\n\n\n6\n19.74286\n122.28571\n7\n\n\n8\n15.10000\n209.21429\n14"
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html#visualizing-the-results",
    "href": "get-started/data-wrangling-with-dplyr.html#visualizing-the-results",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "# Plot average mpg by cylinder count\nggplot(cyl_stats, aes(x = factor(cyl), y = avg_mpg)) +\n  geom_col(aes(fill = avg_hp)) +\n  geom_text(aes(label = round(avg_mpg, 1)), vjust = -0.5) +\n  scale_fill_viridis_c() +\n  labs(\n    title = \"Average Fuel Efficiency by Cylinder Count\",\n    subtitle = \"Color indicates average horsepower\",\n    x = \"Number of Cylinders\",\n    y = \"Average MPG\",\n    fill = \"Avg. Horsepower\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html#working-with-the-iris-dataset",
    "href": "get-started/data-wrangling-with-dplyr.html#working-with-the-iris-dataset",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "Let’s also explore another built-in dataset, iris:\n\n# Look at the iris data\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\n\n\n\n# Calculate average measurements by species\niris_stats &lt;- iris %&gt;%\n  group_by(Species) %&gt;%\n  summarize(\n    avg_sepal_length = mean(Sepal.Length),\n    avg_sepal_width = mean(Sepal.Width),\n    avg_petal_length = mean(Petal.Length),\n    avg_petal_width = mean(Petal.Width),\n    count = n()\n  )\n\niris_stats %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies\navg_sepal_length\navg_sepal_width\navg_petal_length\navg_petal_width\ncount\n\n\n\n\nsetosa\n5.006\n3.428\n1.462\n0.246\n50\n\n\nversicolor\n5.936\n2.770\n4.260\n1.326\n50\n\n\nvirginica\n6.588\n2.974\n5.552\n2.026\n50\n\n\n\n\n\n\n\n\n\n# Create a scatter plot with multiple dimensions\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"Iris Dataset: Sepal Dimensions by Species\",\n    x = \"Sepal Length (cm)\",\n    y = \"Sepal Width (cm)\"\n  ) +\n  theme_minimal() +\n  facet_wrap(~Species)"
  },
  {
    "objectID": "get-started/data-wrangling-with-dplyr.html#conclusion",
    "href": "get-started/data-wrangling-with-dplyr.html#conclusion",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "The dplyr package provides a consistent and intuitive way to manipulate data in R. By mastering these basic functions, you’ll be well on your way to efficient data analysis workflows.\nIn the next post, we’ll explore how to combine these techniques with other packages in the tidyverse for even more powerful data analysis."
  },
  {
    "objectID": "get-started/base-graphics.html",
    "href": "get-started/base-graphics.html",
    "title": "Introduction to Base Graphics in R",
    "section": "",
    "text": "R comes with a powerful built-in graphics system known as “base graphics.” These functions provide a straightforward way to create a wide variety of plots without requiring additional packages.\n\n\n\n\n\n# Basic scatter plot\nplot(mtcars$wt, mtcars$mpg, \n     main = \"Car Weight vs. Fuel Efficiency\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     pch = 19,  # Solid circle point type\n     col = \"blue\")\n\n# Add a grid\ngrid()\n\n# Add a trend line\nabline(lm(mpg ~ wt, data = mtcars), col = \"red\", lwd = 2)\n\n# Add a legend\nlegend(\"topright\", \n       legend = \"Trend Line\", \n       col = \"red\", \n       lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create some data\nx &lt;- 1:10\ny &lt;- x^2\n\n# Basic line plot\nplot(x, y, \n     type = \"l\",  # 'l' for line\n     main = \"Line Plot Example\",\n     xlab = \"X Values\",\n     ylab = \"Y Values\",\n     col = \"darkgreen\",\n     lwd = 2)\n\n# Add points to the line\npoints(x, y, pch = 19, col = \"darkgreen\")\n\n# Add another line\nlines(x, 2*x, col = \"blue\", lwd = 2)\n\n# Add a legend\nlegend(\"topleft\", \n       legend = c(\"y = x^2\", \"y = 2x\"), \n       col = c(\"darkgreen\", \"blue\"), \n       lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a simple frequency table\ncylinders &lt;- table(mtcars$cyl)\n\n# Basic bar plot\nbarplot(cylinders,\n        main = \"Car Cylinders Distribution\",\n        xlab = \"Number of Cylinders\",\n        ylab = \"Frequency\",\n        col = c(\"lightblue\", \"skyblue\", \"steelblue\"),\n        border = \"white\")\n\n\n\n\n\n\n\n# Add text labels on top of bars\ntext(x = barplot(cylinders), \n     y = cylinders + 1, \n     labels = cylinders, \n     col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Basic histogram\nhist(mtcars$mpg,\n     main = \"Distribution of Fuel Efficiency\",\n     xlab = \"Miles Per Gallon\",\n     col = \"lightgreen\",\n     border = \"white\",\n     breaks = 10)  # Number of bins\n\n\n\n\n\n\n\n# Add a density curve\nhist(mtcars$mpg,\n     main = \"Distribution with Density Curve\",\n     xlab = \"Miles Per Gallon\",\n     col = \"lightgreen\",\n     border = \"white\",\n     freq = FALSE)  # Show density instead of frequency\n\n# Add a normal density curve\ncurve(dnorm(x, mean = mean(mtcars$mpg), sd = sd(mtcars$mpg)),\n      add = TRUE, col = \"darkred\", lwd = 2)\n\n# Add a legend\nlegend(\"topright\", \n       legend = \"Normal Distribution\", \n       col = \"darkred\", \n       lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n# Basic box plot\nboxplot(mpg ~ cyl, data = mtcars,\n        main = \"Fuel Efficiency by Cylinder Count\",\n        xlab = \"Number of Cylinders\",\n        ylab = \"Miles Per Gallon\",\n        col = c(\"lightpink\", \"lightblue\", \"lightgreen\"))\n\n# Add a title to the plot\ntitle(\"Comparison of MPG Distribution\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a customized scatter plot\nplot(mtcars$wt, mtcars$mpg,\n     main = \"Customized Scatter Plot\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     pch = 16,       # Point type\n     col = \"purple\", # Point color\n     cex = 1.5,      # Point size\n     type = \"p\",     # Plot type ('p' for points)\n     lwd = 2,        # Line width\n     bty = \"l\",      # Box type ('l' for L-shaped)\n     xlim = c(1, 6), # X-axis limits\n     ylim = c(10, 35) # Y-axis limits\n)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a plot showing different point types and colors\nplot(1:20, 1:20, \n     type = \"n\",  # 'n' for no plotting\n     main = \"Point Types (pch) in R\",\n     xlab = \"Point Type (pch value)\",\n     ylab = \"\")\n\n# Add points with different pch values\nfor (i in 1:20) {\n  points(i, 10, pch = i, cex = 2)\n  text(i, 12, labels = i)\n}\n\n\n\n\n\n\n\n# Show different colors\nplot(1:8, rep(1, 8), \n     type = \"n\",\n     main = \"Basic Colors in R\",\n     xlab = \"\", ylab = \"\",\n     xlim = c(0.5, 8.5), ylim = c(0, 2),\n     axes = FALSE)\n\ncolors &lt;- c(\"black\", \"red\", \"green\", \"blue\", \"cyan\", \"magenta\", \"yellow\", \"gray\")\nfor (i in 1:8) {\n  points(i, 1, pch = 19, col = colors[i], cex = 3)\n  text(i, 0.7, labels = colors[i])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Set up a 2x2 plotting area\npar(mfrow = c(2, 2))\n\n# Plot 1: Scatter plot\nplot(mtcars$wt, mtcars$mpg, main = \"Weight vs MPG\", pch = 19)\n\n# Plot 2: Histogram\nhist(mtcars$mpg, main = \"MPG Distribution\", col = \"lightblue\")\n\n# Plot 3: Box plot\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightgreen\")\n\n# Plot 4: Bar plot\nbarplot(table(mtcars$gear), main = \"Gear Count\", col = \"salmon\")\n\n\n\n\n\n\n\n# Reset to 1x1 plotting area\npar(mfrow = c(1, 1))\n\n\n\n\n\n# Create a basic plot\nplot(mtcars$wt, mtcars$mpg, \n     type = \"n\",  # Start with an empty plot\n     main = \"Car Weight vs. Fuel Efficiency\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\")\n\n# Add points with different colors by cylinder\ncyl_colors &lt;- c(\"red\", \"green\", \"blue\")\nfor (i in unique(mtcars$cyl)) {\n  subset_idx &lt;- mtcars$cyl == i\n  points(mtcars$wt[subset_idx], mtcars$mpg[subset_idx], \n         col = cyl_colors[i/4],  # 4,6,8 cylinders mapped to colors\n         pch = 19)\n}\n\n# Add a legend\nlegend(\"topright\", \n       legend = c(\"4 cylinders\", \"6 cylinders\", \"8 cylinders\"), \n       col = cyl_colors, \n       pch = 19)\n\n# Add text annotations\ntext(mtcars$wt[mtcars$mpg &gt; 30], mtcars$mpg[mtcars$mpg &gt; 30], \n     labels = rownames(mtcars)[mtcars$mpg &gt; 30],\n     pos = 4)  # Position 4 is to the right\n\n# Add a horizontal line at mean MPG\nabline(h = mean(mtcars$mpg), lty = 2, col = \"darkgray\")\ntext(5, mean(mtcars$mpg) + 1, \"Mean MPG\", col = \"darkgray\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Example of how to save a plot (not run)\n# png(\"my_plot.png\", width = 800, height = 600)\nplot(mtcars$wt, mtcars$mpg, main = \"Plot to Save\", pch = 19, col = \"blue\")\n\n\n\n\n\n\n\n# dev.off()  # Close the device to save the file\n\n# Other formats\n# pdf(\"my_plot.pdf\", width = 8, height = 6)\n# jpeg(\"my_plot.jpg\", width = 800, height = 600, quality = 100)\n# svg(\"my_plot.svg\", width = 8, height = 6)\n\nBase graphics in R provide a solid foundation for creating a wide variety of plots. While newer packages like ggplot2 offer more sophisticated options, base graphics remain valuable for quick visualizations and for understanding the fundamentals of plotting in R."
  },
  {
    "objectID": "get-started/base-graphics.html#introduction-to-base-graphics-in-r",
    "href": "get-started/base-graphics.html#introduction-to-base-graphics-in-r",
    "title": "Introduction to Base Graphics in R",
    "section": "",
    "text": "R comes with a powerful built-in graphics system known as “base graphics.” These functions provide a straightforward way to create a wide variety of plots without requiring additional packages.\n\n\n\n\n\n# Basic scatter plot\nplot(mtcars$wt, mtcars$mpg, \n     main = \"Car Weight vs. Fuel Efficiency\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     pch = 19,  # Solid circle point type\n     col = \"blue\")\n\n# Add a grid\ngrid()\n\n# Add a trend line\nabline(lm(mpg ~ wt, data = mtcars), col = \"red\", lwd = 2)\n\n# Add a legend\nlegend(\"topright\", \n       legend = \"Trend Line\", \n       col = \"red\", \n       lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create some data\nx &lt;- 1:10\ny &lt;- x^2\n\n# Basic line plot\nplot(x, y, \n     type = \"l\",  # 'l' for line\n     main = \"Line Plot Example\",\n     xlab = \"X Values\",\n     ylab = \"Y Values\",\n     col = \"darkgreen\",\n     lwd = 2)\n\n# Add points to the line\npoints(x, y, pch = 19, col = \"darkgreen\")\n\n# Add another line\nlines(x, 2*x, col = \"blue\", lwd = 2)\n\n# Add a legend\nlegend(\"topleft\", \n       legend = c(\"y = x^2\", \"y = 2x\"), \n       col = c(\"darkgreen\", \"blue\"), \n       lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a simple frequency table\ncylinders &lt;- table(mtcars$cyl)\n\n# Basic bar plot\nbarplot(cylinders,\n        main = \"Car Cylinders Distribution\",\n        xlab = \"Number of Cylinders\",\n        ylab = \"Frequency\",\n        col = c(\"lightblue\", \"skyblue\", \"steelblue\"),\n        border = \"white\")\n\n\n\n\n\n\n\n# Add text labels on top of bars\ntext(x = barplot(cylinders), \n     y = cylinders + 1, \n     labels = cylinders, \n     col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Basic histogram\nhist(mtcars$mpg,\n     main = \"Distribution of Fuel Efficiency\",\n     xlab = \"Miles Per Gallon\",\n     col = \"lightgreen\",\n     border = \"white\",\n     breaks = 10)  # Number of bins\n\n\n\n\n\n\n\n# Add a density curve\nhist(mtcars$mpg,\n     main = \"Distribution with Density Curve\",\n     xlab = \"Miles Per Gallon\",\n     col = \"lightgreen\",\n     border = \"white\",\n     freq = FALSE)  # Show density instead of frequency\n\n# Add a normal density curve\ncurve(dnorm(x, mean = mean(mtcars$mpg), sd = sd(mtcars$mpg)),\n      add = TRUE, col = \"darkred\", lwd = 2)\n\n# Add a legend\nlegend(\"topright\", \n       legend = \"Normal Distribution\", \n       col = \"darkred\", \n       lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n# Basic box plot\nboxplot(mpg ~ cyl, data = mtcars,\n        main = \"Fuel Efficiency by Cylinder Count\",\n        xlab = \"Number of Cylinders\",\n        ylab = \"Miles Per Gallon\",\n        col = c(\"lightpink\", \"lightblue\", \"lightgreen\"))\n\n# Add a title to the plot\ntitle(\"Comparison of MPG Distribution\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a customized scatter plot\nplot(mtcars$wt, mtcars$mpg,\n     main = \"Customized Scatter Plot\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\",\n     pch = 16,       # Point type\n     col = \"purple\", # Point color\n     cex = 1.5,      # Point size\n     type = \"p\",     # Plot type ('p' for points)\n     lwd = 2,        # Line width\n     bty = \"l\",      # Box type ('l' for L-shaped)\n     xlim = c(1, 6), # X-axis limits\n     ylim = c(10, 35) # Y-axis limits\n)\n\n\n\n\n\n\n\n\n\n\n\n\n# Create a plot showing different point types and colors\nplot(1:20, 1:20, \n     type = \"n\",  # 'n' for no plotting\n     main = \"Point Types (pch) in R\",\n     xlab = \"Point Type (pch value)\",\n     ylab = \"\")\n\n# Add points with different pch values\nfor (i in 1:20) {\n  points(i, 10, pch = i, cex = 2)\n  text(i, 12, labels = i)\n}\n\n\n\n\n\n\n\n# Show different colors\nplot(1:8, rep(1, 8), \n     type = \"n\",\n     main = \"Basic Colors in R\",\n     xlab = \"\", ylab = \"\",\n     xlim = c(0.5, 8.5), ylim = c(0, 2),\n     axes = FALSE)\n\ncolors &lt;- c(\"black\", \"red\", \"green\", \"blue\", \"cyan\", \"magenta\", \"yellow\", \"gray\")\nfor (i in 1:8) {\n  points(i, 1, pch = 19, col = colors[i], cex = 3)\n  text(i, 0.7, labels = colors[i])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Set up a 2x2 plotting area\npar(mfrow = c(2, 2))\n\n# Plot 1: Scatter plot\nplot(mtcars$wt, mtcars$mpg, main = \"Weight vs MPG\", pch = 19)\n\n# Plot 2: Histogram\nhist(mtcars$mpg, main = \"MPG Distribution\", col = \"lightblue\")\n\n# Plot 3: Box plot\nboxplot(mpg ~ cyl, data = mtcars, main = \"MPG by Cylinders\", col = \"lightgreen\")\n\n# Plot 4: Bar plot\nbarplot(table(mtcars$gear), main = \"Gear Count\", col = \"salmon\")\n\n\n\n\n\n\n\n# Reset to 1x1 plotting area\npar(mfrow = c(1, 1))\n\n\n\n\n\n# Create a basic plot\nplot(mtcars$wt, mtcars$mpg, \n     type = \"n\",  # Start with an empty plot\n     main = \"Car Weight vs. Fuel Efficiency\",\n     xlab = \"Weight (1000 lbs)\",\n     ylab = \"Miles Per Gallon\")\n\n# Add points with different colors by cylinder\ncyl_colors &lt;- c(\"red\", \"green\", \"blue\")\nfor (i in unique(mtcars$cyl)) {\n  subset_idx &lt;- mtcars$cyl == i\n  points(mtcars$wt[subset_idx], mtcars$mpg[subset_idx], \n         col = cyl_colors[i/4],  # 4,6,8 cylinders mapped to colors\n         pch = 19)\n}\n\n# Add a legend\nlegend(\"topright\", \n       legend = c(\"4 cylinders\", \"6 cylinders\", \"8 cylinders\"), \n       col = cyl_colors, \n       pch = 19)\n\n# Add text annotations\ntext(mtcars$wt[mtcars$mpg &gt; 30], mtcars$mpg[mtcars$mpg &gt; 30], \n     labels = rownames(mtcars)[mtcars$mpg &gt; 30],\n     pos = 4)  # Position 4 is to the right\n\n# Add a horizontal line at mean MPG\nabline(h = mean(mtcars$mpg), lty = 2, col = \"darkgray\")\ntext(5, mean(mtcars$mpg) + 1, \"Mean MPG\", col = \"darkgray\")\n\n\n\n\n\n\n\n\n\n\n\n\n# Example of how to save a plot (not run)\n# png(\"my_plot.png\", width = 800, height = 600)\nplot(mtcars$wt, mtcars$mpg, main = \"Plot to Save\", pch = 19, col = \"blue\")\n\n\n\n\n\n\n\n# dev.off()  # Close the device to save the file\n\n# Other formats\n# pdf(\"my_plot.pdf\", width = 8, height = 6)\n# jpeg(\"my_plot.jpg\", width = 800, height = 600, quality = 100)\n# svg(\"my_plot.svg\", width = 8, height = 6)\n\nBase graphics in R provide a solid foundation for creating a wide variety of plots. While newer packages like ggplot2 offer more sophisticated options, base graphics remain valuable for quick visualizations and for understanding the fundamentals of plotting in R."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "R’tichoke is a dedicated repository of R programming content, tutorials, and resources.\nFeel free to reach out on LinkedIn!"
  },
  {
    "objectID": "about.html#about-rtichoke",
    "href": "about.html#about-rtichoke",
    "title": "About",
    "section": "",
    "text": "R’tichoke is a dedicated repository of R programming content, tutorials, and resources.\nFeel free to reach out on LinkedIn!"
  },
  {
    "objectID": "about.html#how-this-site-works",
    "href": "about.html#how-this-site-works",
    "title": "About",
    "section": "How This Site Works",
    "text": "How This Site Works\nAll content on this site is created using Quarto, a next-generation version of R Markdown. This allows us to:\n\nWrite content in .qmd files (Quarto Markdown)\nInclude executable R code chunks\nGenerate beautiful, interactive web pages\nCreate a consistent, organized structure"
  },
  {
    "objectID": "about.html#r-resources",
    "href": "about.html#r-resources",
    "title": "About",
    "section": "R Resources",
    "text": "R Resources\nHere are some additional resources for learning R:\n\nR Project for Statistical Computing\nRStudio\nTidyverse\nR for Data Science\nR-bloggers"
  },
  {
    "objectID": "get-started/data-table.html",
    "href": "get-started/data-table.html",
    "title": "Introduction to data.table",
    "section": "",
    "text": "The data.table package is a high-performance extension of R’s data.frame that provides a concise syntax for data manipulation. It’s particularly efficient for large datasets.\n\n\nFirst, let’s install and load the package:\n\n# Install if needed (uncomment to run)\n# install.packages(\"data.table\")\n\n# Load the package\nlibrary(data.table)\n\n# Convert the built-in mtcars dataset to a data.table\ndt_cars &lt;- as.data.table(mtcars, keep.rownames = TRUE)\nsetnames(dt_cars, \"rn\", \"model\")  # Rename the rownames column\ndt_cars\n\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     0     1\n 2:       Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     0     1\n 3:          Datsun 710  22.8     4 108.0    93  3.85 2.320 18.61     1     1\n 4:      Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0\n 5:   Hornet Sportabout  18.7     8 360.0   175  3.15 3.440 17.02     0     0\n 6:             Valiant  18.1     6 225.0   105  2.76 3.460 20.22     1     0\n 7:          Duster 360  14.3     8 360.0   245  3.21 3.570 15.84     0     0\n 8:           Merc 240D  24.4     4 146.7    62  3.69 3.190 20.00     1     0\n 9:            Merc 230  22.8     4 140.8    95  3.92 3.150 22.90     1     0\n10:            Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     1     0\n11:           Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     1     0\n12:          Merc 450SE  16.4     8 275.8   180  3.07 4.070 17.40     0     0\n13:          Merc 450SL  17.3     8 275.8   180  3.07 3.730 17.60     0     0\n14:         Merc 450SLC  15.2     8 275.8   180  3.07 3.780 18.00     0     0\n15:  Cadillac Fleetwood  10.4     8 472.0   205  2.93 5.250 17.98     0     0\n16: Lincoln Continental  10.4     8 460.0   215  3.00 5.424 17.82     0     0\n17:   Chrysler Imperial  14.7     8 440.0   230  3.23 5.345 17.42     0     0\n18:            Fiat 128  32.4     4  78.7    66  4.08 2.200 19.47     1     1\n19:         Honda Civic  30.4     4  75.7    52  4.93 1.615 18.52     1     1\n20:      Toyota Corolla  33.9     4  71.1    65  4.22 1.835 19.90     1     1\n21:       Toyota Corona  21.5     4 120.1    97  3.70 2.465 20.01     1     0\n22:    Dodge Challenger  15.5     8 318.0   150  2.76 3.520 16.87     0     0\n23:         AMC Javelin  15.2     8 304.0   150  3.15 3.435 17.30     0     0\n24:          Camaro Z28  13.3     8 350.0   245  3.73 3.840 15.41     0     0\n25:    Pontiac Firebird  19.2     8 400.0   175  3.08 3.845 17.05     0     0\n26:           Fiat X1-9  27.3     4  79.0    66  4.08 1.935 18.90     1     1\n27:       Porsche 914-2  26.0     4 120.3    91  4.43 2.140 16.70     0     1\n28:        Lotus Europa  30.4     4  95.1   113  3.77 1.513 16.90     1     1\n29:      Ford Pantera L  15.8     8 351.0   264  4.22 3.170 14.50     0     1\n30:        Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     0     1\n31:       Maserati Bora  15.0     8 301.0   335  3.54 3.570 14.60     0     1\n32:          Volvo 142E  21.4     4 121.0   109  4.11 2.780 18.60     1     1\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n     gear  carb\n    &lt;num&gt; &lt;num&gt;\n 1:     4     4\n 2:     4     4\n 3:     4     1\n 4:     3     1\n 5:     3     2\n 6:     3     1\n 7:     3     4\n 8:     4     2\n 9:     4     2\n10:     4     4\n11:     4     4\n12:     3     3\n13:     3     3\n14:     3     3\n15:     3     4\n16:     3     4\n17:     3     4\n18:     4     1\n19:     4     2\n20:     4     1\n21:     3     1\n22:     3     2\n23:     3     2\n24:     3     4\n25:     3     2\n26:     4     1\n27:     5     2\n28:     5     2\n29:     5     4\n30:     5     6\n31:     5     8\n32:     4     2\n     gear  carb\n\n\n\n\n\ndata.table uses a concise syntax based on [i, j, by]: - i: Subset rows (WHERE) - j: Compute on columns (SELECT) - by: Group by columns (GROUP BY)\n\n\n\n# Select cars with 6 cylinders\ndt_cars[cyl == 6]\n\n            model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n           &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:      Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     0     1     4\n2:  Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     0     1     4\n3: Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0     3\n4:        Valiant  18.1     6 225.0   105  2.76 3.460 20.22     1     0     3\n5:       Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     1     0     4\n6:      Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     1     0     4\n7:   Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     0     1     5\n    carb\n   &lt;num&gt;\n1:     4\n2:     4\n3:     1\n4:     1\n5:     4\n6:     4\n7:     6\n\n# Multiple conditions\ndt_cars[cyl == 6 & mpg &gt; 20]\n\n            model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n           &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:      Mazda RX4  21.0     6   160   110  3.90 2.620 16.46     0     1     4\n2:  Mazda RX4 Wag  21.0     6   160   110  3.90 2.875 17.02     0     1     4\n3: Hornet 4 Drive  21.4     6   258   110  3.08 3.215 19.44     1     0     3\n    carb\n   &lt;num&gt;\n1:     4\n2:     4\n3:     1\n\n# Select specific rows by position\ndt_cars[1:5]\n\n               model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n              &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:         Mazda RX4  21.0     6   160   110  3.90 2.620 16.46     0     1\n2:     Mazda RX4 Wag  21.0     6   160   110  3.90 2.875 17.02     0     1\n3:        Datsun 710  22.8     4   108    93  3.85 2.320 18.61     1     1\n4:    Hornet 4 Drive  21.4     6   258   110  3.08 3.215 19.44     1     0\n5: Hornet Sportabout  18.7     8   360   175  3.15 3.440 17.02     0     0\n    gear  carb\n   &lt;num&gt; &lt;num&gt;\n1:     4     4\n2:     4     4\n3:     4     1\n4:     3     1\n5:     3     2\n\n\n\n\n\n\n# Select specific columns\ndt_cars[, .(mpg, hp, cyl)]\n\n      mpg    hp   cyl\n    &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:  21.0   110     6\n 2:  21.0   110     6\n 3:  22.8    93     4\n 4:  21.4   110     6\n 5:  18.7   175     8\n 6:  18.1   105     6\n 7:  14.3   245     8\n 8:  24.4    62     4\n 9:  22.8    95     4\n10:  19.2   123     6\n11:  17.8   123     6\n12:  16.4   180     8\n13:  17.3   180     8\n14:  15.2   180     8\n15:  10.4   205     8\n16:  10.4   215     8\n17:  14.7   230     8\n18:  32.4    66     4\n19:  30.4    52     4\n20:  33.9    65     4\n21:  21.5    97     4\n22:  15.5   150     8\n23:  15.2   150     8\n24:  13.3   245     8\n25:  19.2   175     8\n26:  27.3    66     4\n27:  26.0    91     4\n28:  30.4   113     4\n29:  15.8   264     8\n30:  19.7   175     6\n31:  15.0   335     8\n32:  21.4   109     4\n      mpg    hp   cyl\n\n# Compute new values\ndt_cars[, .(kpl = mpg * 0.425)]\n\n        kpl\n      &lt;num&gt;\n 1:  8.9250\n 2:  8.9250\n 3:  9.6900\n 4:  9.0950\n 5:  7.9475\n 6:  7.6925\n 7:  6.0775\n 8: 10.3700\n 9:  9.6900\n10:  8.1600\n11:  7.5650\n12:  6.9700\n13:  7.3525\n14:  6.4600\n15:  4.4200\n16:  4.4200\n17:  6.2475\n18: 13.7700\n19: 12.9200\n20: 14.4075\n21:  9.1375\n22:  6.5875\n23:  6.4600\n24:  5.6525\n25:  8.1600\n26: 11.6025\n27: 11.0500\n28: 12.9200\n29:  6.7150\n30:  8.3725\n31:  6.3750\n32:  9.0950\n        kpl\n\n# Select and compute multiple columns\ndt_cars[, .(model, kpl = mpg * 0.425, hp_per_cyl = hp/cyl)]\n\n                  model     kpl hp_per_cyl\n                 &lt;char&gt;   &lt;num&gt;      &lt;num&gt;\n 1:           Mazda RX4  8.9250   18.33333\n 2:       Mazda RX4 Wag  8.9250   18.33333\n 3:          Datsun 710  9.6900   23.25000\n 4:      Hornet 4 Drive  9.0950   18.33333\n 5:   Hornet Sportabout  7.9475   21.87500\n 6:             Valiant  7.6925   17.50000\n 7:          Duster 360  6.0775   30.62500\n 8:           Merc 240D 10.3700   15.50000\n 9:            Merc 230  9.6900   23.75000\n10:            Merc 280  8.1600   20.50000\n11:           Merc 280C  7.5650   20.50000\n12:          Merc 450SE  6.9700   22.50000\n13:          Merc 450SL  7.3525   22.50000\n14:         Merc 450SLC  6.4600   22.50000\n15:  Cadillac Fleetwood  4.4200   25.62500\n16: Lincoln Continental  4.4200   26.87500\n17:   Chrysler Imperial  6.2475   28.75000\n18:            Fiat 128 13.7700   16.50000\n19:         Honda Civic 12.9200   13.00000\n20:      Toyota Corolla 14.4075   16.25000\n21:       Toyota Corona  9.1375   24.25000\n22:    Dodge Challenger  6.5875   18.75000\n23:         AMC Javelin  6.4600   18.75000\n24:          Camaro Z28  5.6525   30.62500\n25:    Pontiac Firebird  8.1600   21.87500\n26:           Fiat X1-9 11.6025   16.50000\n27:       Porsche 914-2 11.0500   22.75000\n28:        Lotus Europa 12.9200   28.25000\n29:      Ford Pantera L  6.7150   33.00000\n30:        Ferrari Dino  8.3725   29.16667\n31:       Maserati Bora  6.3750   41.87500\n32:          Volvo 142E  9.0950   27.25000\n                  model     kpl hp_per_cyl\n\n# Apply functions\ndt_cars[, .(avg_mpg = mean(mpg), max_hp = max(hp))]\n\n    avg_mpg max_hp\n      &lt;num&gt;  &lt;num&gt;\n1: 20.09062    335\n\n\n\n\n\n\n# Group by cylinder and calculate statistics\ndt_cars[, .(count = .N, avg_mpg = mean(mpg)), by = cyl]\n\n     cyl count  avg_mpg\n   &lt;num&gt; &lt;int&gt;    &lt;num&gt;\n1:     6     7 19.74286\n2:     4    11 26.66364\n3:     8    14 15.10000\n\n# Multiple grouping variables\ndt_cars[, .(count = .N, avg_mpg = mean(mpg)), by = .(cyl, gear)]\n\n     cyl  gear count avg_mpg\n   &lt;num&gt; &lt;num&gt; &lt;int&gt;   &lt;num&gt;\n1:     6     4     4  19.750\n2:     4     4     8  26.925\n3:     6     3     2  19.750\n4:     8     3    12  15.050\n5:     4     3     1  21.500\n6:     4     5     2  28.200\n7:     8     5     2  15.400\n8:     6     5     1  19.700\n\n# Grouping with expressions\ndt_cars[, .(count = .N), by = .(cyl, high_mpg = mpg &gt; 20)]\n\n     cyl high_mpg count\n   &lt;num&gt;   &lt;lgcl&gt; &lt;int&gt;\n1:     6     TRUE     3\n2:     4     TRUE    11\n3:     8    FALSE    14\n4:     6    FALSE     4\n\n\n\n\n\n\ndata.table provides special symbols for common operations:\n\n# .N: number of rows\ndt_cars[, .N]\n\n[1] 32\n\ndt_cars[, .N, by = cyl]\n\n     cyl     N\n   &lt;num&gt; &lt;int&gt;\n1:     6     7\n2:     4    11\n3:     8    14\n\n# .SD: Subset of Data\ndt_cars[, lapply(.SD, mean), by = cyl, .SDcols = c(\"mpg\", \"hp\", \"wt\")]\n\n     cyl      mpg        hp       wt\n   &lt;num&gt;    &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n1:     6 19.74286 122.28571 3.117143\n2:     4 26.66364  82.63636 2.285727\n3:     8 15.10000 209.21429 3.999214\n\n# .I: Row numbers\ndt_cars[, .I[1:2], by = cyl]  # First two row numbers for each cyl group\n\n     cyl    V1\n   &lt;num&gt; &lt;int&gt;\n1:     6     1\n2:     6     2\n3:     4     3\n4:     4     8\n5:     8     5\n6:     8     7\n\n\n\n\n\ndata.table allows efficient in-place modifications:\n\n# Create a copy to avoid modifying the original\ndt_copy &lt;- copy(dt_cars)\n\n# Add a new column\ndt_copy[, efficiency := mpg/wt]\ndt_copy\n\nIndex: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     0     1\n 2:       Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     0     1\n 3:          Datsun 710  22.8     4 108.0    93  3.85 2.320 18.61     1     1\n 4:      Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0\n 5:   Hornet Sportabout  18.7     8 360.0   175  3.15 3.440 17.02     0     0\n 6:             Valiant  18.1     6 225.0   105  2.76 3.460 20.22     1     0\n 7:          Duster 360  14.3     8 360.0   245  3.21 3.570 15.84     0     0\n 8:           Merc 240D  24.4     4 146.7    62  3.69 3.190 20.00     1     0\n 9:            Merc 230  22.8     4 140.8    95  3.92 3.150 22.90     1     0\n10:            Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     1     0\n11:           Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     1     0\n12:          Merc 450SE  16.4     8 275.8   180  3.07 4.070 17.40     0     0\n13:          Merc 450SL  17.3     8 275.8   180  3.07 3.730 17.60     0     0\n14:         Merc 450SLC  15.2     8 275.8   180  3.07 3.780 18.00     0     0\n15:  Cadillac Fleetwood  10.4     8 472.0   205  2.93 5.250 17.98     0     0\n16: Lincoln Continental  10.4     8 460.0   215  3.00 5.424 17.82     0     0\n17:   Chrysler Imperial  14.7     8 440.0   230  3.23 5.345 17.42     0     0\n18:            Fiat 128  32.4     4  78.7    66  4.08 2.200 19.47     1     1\n19:         Honda Civic  30.4     4  75.7    52  4.93 1.615 18.52     1     1\n20:      Toyota Corolla  33.9     4  71.1    65  4.22 1.835 19.90     1     1\n21:       Toyota Corona  21.5     4 120.1    97  3.70 2.465 20.01     1     0\n22:    Dodge Challenger  15.5     8 318.0   150  2.76 3.520 16.87     0     0\n23:         AMC Javelin  15.2     8 304.0   150  3.15 3.435 17.30     0     0\n24:          Camaro Z28  13.3     8 350.0   245  3.73 3.840 15.41     0     0\n25:    Pontiac Firebird  19.2     8 400.0   175  3.08 3.845 17.05     0     0\n26:           Fiat X1-9  27.3     4  79.0    66  4.08 1.935 18.90     1     1\n27:       Porsche 914-2  26.0     4 120.3    91  4.43 2.140 16.70     0     1\n28:        Lotus Europa  30.4     4  95.1   113  3.77 1.513 16.90     1     1\n29:      Ford Pantera L  15.8     8 351.0   264  4.22 3.170 14.50     0     1\n30:        Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     0     1\n31:       Maserati Bora  15.0     8 301.0   335  3.54 3.570 14.60     0     1\n32:          Volvo 142E  21.4     4 121.0   109  4.11 2.780 18.60     1     1\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n     gear  carb efficiency\n    &lt;num&gt; &lt;num&gt;      &lt;num&gt;\n 1:     4     4   8.015267\n 2:     4     4   7.304348\n 3:     4     1   9.827586\n 4:     3     1   6.656299\n 5:     3     2   5.436047\n 6:     3     1   5.231214\n 7:     3     4   4.005602\n 8:     4     2   7.648903\n 9:     4     2   7.238095\n10:     4     4   5.581395\n11:     4     4   5.174419\n12:     3     3   4.029484\n13:     3     3   4.638070\n14:     3     3   4.021164\n15:     3     4   1.980952\n16:     3     4   1.917404\n17:     3     4   2.750234\n18:     4     1  14.727273\n19:     4     2  18.823529\n20:     4     1  18.474114\n21:     3     1   8.722110\n22:     3     2   4.403409\n23:     3     2   4.425036\n24:     3     4   3.463542\n25:     3     2   4.993498\n26:     4     1  14.108527\n27:     5     2  12.149533\n28:     5     2  20.092531\n29:     5     4   4.984227\n30:     5     6   7.111913\n31:     5     8   4.201681\n32:     4     2   7.697842\n     gear  carb efficiency\n\n# Update existing values\ndt_copy[cyl == 4, mpg := mpg * 1.1]  # Increase mpg by 10% for 4-cylinder cars\ndt_copy\n\nIndex: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4 21.00     6 160.0   110  3.90 2.620 16.46     0     1\n 2:       Mazda RX4 Wag 21.00     6 160.0   110  3.90 2.875 17.02     0     1\n 3:          Datsun 710 25.08     4 108.0    93  3.85 2.320 18.61     1     1\n 4:      Hornet 4 Drive 21.40     6 258.0   110  3.08 3.215 19.44     1     0\n 5:   Hornet Sportabout 18.70     8 360.0   175  3.15 3.440 17.02     0     0\n 6:             Valiant 18.10     6 225.0   105  2.76 3.460 20.22     1     0\n 7:          Duster 360 14.30     8 360.0   245  3.21 3.570 15.84     0     0\n 8:           Merc 240D 26.84     4 146.7    62  3.69 3.190 20.00     1     0\n 9:            Merc 230 25.08     4 140.8    95  3.92 3.150 22.90     1     0\n10:            Merc 280 19.20     6 167.6   123  3.92 3.440 18.30     1     0\n11:           Merc 280C 17.80     6 167.6   123  3.92 3.440 18.90     1     0\n12:          Merc 450SE 16.40     8 275.8   180  3.07 4.070 17.40     0     0\n13:          Merc 450SL 17.30     8 275.8   180  3.07 3.730 17.60     0     0\n14:         Merc 450SLC 15.20     8 275.8   180  3.07 3.780 18.00     0     0\n15:  Cadillac Fleetwood 10.40     8 472.0   205  2.93 5.250 17.98     0     0\n16: Lincoln Continental 10.40     8 460.0   215  3.00 5.424 17.82     0     0\n17:   Chrysler Imperial 14.70     8 440.0   230  3.23 5.345 17.42     0     0\n18:            Fiat 128 35.64     4  78.7    66  4.08 2.200 19.47     1     1\n19:         Honda Civic 33.44     4  75.7    52  4.93 1.615 18.52     1     1\n20:      Toyota Corolla 37.29     4  71.1    65  4.22 1.835 19.90     1     1\n21:       Toyota Corona 23.65     4 120.1    97  3.70 2.465 20.01     1     0\n22:    Dodge Challenger 15.50     8 318.0   150  2.76 3.520 16.87     0     0\n23:         AMC Javelin 15.20     8 304.0   150  3.15 3.435 17.30     0     0\n24:          Camaro Z28 13.30     8 350.0   245  3.73 3.840 15.41     0     0\n25:    Pontiac Firebird 19.20     8 400.0   175  3.08 3.845 17.05     0     0\n26:           Fiat X1-9 30.03     4  79.0    66  4.08 1.935 18.90     1     1\n27:       Porsche 914-2 28.60     4 120.3    91  4.43 2.140 16.70     0     1\n28:        Lotus Europa 33.44     4  95.1   113  3.77 1.513 16.90     1     1\n29:      Ford Pantera L 15.80     8 351.0   264  4.22 3.170 14.50     0     1\n30:        Ferrari Dino 19.70     6 145.0   175  3.62 2.770 15.50     0     1\n31:       Maserati Bora 15.00     8 301.0   335  3.54 3.570 14.60     0     1\n32:          Volvo 142E 23.54     4 121.0   109  4.11 2.780 18.60     1     1\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n     gear  carb efficiency\n    &lt;num&gt; &lt;num&gt;      &lt;num&gt;\n 1:     4     4   8.015267\n 2:     4     4   7.304348\n 3:     4     1   9.827586\n 4:     3     1   6.656299\n 5:     3     2   5.436047\n 6:     3     1   5.231214\n 7:     3     4   4.005602\n 8:     4     2   7.648903\n 9:     4     2   7.238095\n10:     4     4   5.581395\n11:     4     4   5.174419\n12:     3     3   4.029484\n13:     3     3   4.638070\n14:     3     3   4.021164\n15:     3     4   1.980952\n16:     3     4   1.917404\n17:     3     4   2.750234\n18:     4     1  14.727273\n19:     4     2  18.823529\n20:     4     1  18.474114\n21:     3     1   8.722110\n22:     3     2   4.403409\n23:     3     2   4.425036\n24:     3     4   3.463542\n25:     3     2   4.993498\n26:     4     1  14.108527\n27:     5     2  12.149533\n28:     5     2  20.092531\n29:     5     4   4.984227\n30:     5     6   7.111913\n31:     5     8   4.201681\n32:     4     2   7.697842\n     gear  carb efficiency\n\n# Delete columns\ndt_copy[, c(\"carb\", \"vs\") := NULL]\ndt_copy\n\nIndex: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4 21.00     6 160.0   110  3.90 2.620 16.46     1     4\n 2:       Mazda RX4 Wag 21.00     6 160.0   110  3.90 2.875 17.02     1     4\n 3:          Datsun 710 25.08     4 108.0    93  3.85 2.320 18.61     1     4\n 4:      Hornet 4 Drive 21.40     6 258.0   110  3.08 3.215 19.44     0     3\n 5:   Hornet Sportabout 18.70     8 360.0   175  3.15 3.440 17.02     0     3\n 6:             Valiant 18.10     6 225.0   105  2.76 3.460 20.22     0     3\n 7:          Duster 360 14.30     8 360.0   245  3.21 3.570 15.84     0     3\n 8:           Merc 240D 26.84     4 146.7    62  3.69 3.190 20.00     0     4\n 9:            Merc 230 25.08     4 140.8    95  3.92 3.150 22.90     0     4\n10:            Merc 280 19.20     6 167.6   123  3.92 3.440 18.30     0     4\n11:           Merc 280C 17.80     6 167.6   123  3.92 3.440 18.90     0     4\n12:          Merc 450SE 16.40     8 275.8   180  3.07 4.070 17.40     0     3\n13:          Merc 450SL 17.30     8 275.8   180  3.07 3.730 17.60     0     3\n14:         Merc 450SLC 15.20     8 275.8   180  3.07 3.780 18.00     0     3\n15:  Cadillac Fleetwood 10.40     8 472.0   205  2.93 5.250 17.98     0     3\n16: Lincoln Continental 10.40     8 460.0   215  3.00 5.424 17.82     0     3\n17:   Chrysler Imperial 14.70     8 440.0   230  3.23 5.345 17.42     0     3\n18:            Fiat 128 35.64     4  78.7    66  4.08 2.200 19.47     1     4\n19:         Honda Civic 33.44     4  75.7    52  4.93 1.615 18.52     1     4\n20:      Toyota Corolla 37.29     4  71.1    65  4.22 1.835 19.90     1     4\n21:       Toyota Corona 23.65     4 120.1    97  3.70 2.465 20.01     0     3\n22:    Dodge Challenger 15.50     8 318.0   150  2.76 3.520 16.87     0     3\n23:         AMC Javelin 15.20     8 304.0   150  3.15 3.435 17.30     0     3\n24:          Camaro Z28 13.30     8 350.0   245  3.73 3.840 15.41     0     3\n25:    Pontiac Firebird 19.20     8 400.0   175  3.08 3.845 17.05     0     3\n26:           Fiat X1-9 30.03     4  79.0    66  4.08 1.935 18.90     1     4\n27:       Porsche 914-2 28.60     4 120.3    91  4.43 2.140 16.70     1     5\n28:        Lotus Europa 33.44     4  95.1   113  3.77 1.513 16.90     1     5\n29:      Ford Pantera L 15.80     8 351.0   264  4.22 3.170 14.50     1     5\n30:        Ferrari Dino 19.70     6 145.0   175  3.62 2.770 15.50     1     5\n31:       Maserati Bora 15.00     8 301.0   335  3.54 3.570 14.60     1     5\n32:          Volvo 142E 23.54     4 121.0   109  4.11 2.780 18.60     1     4\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n    efficiency\n         &lt;num&gt;\n 1:   8.015267\n 2:   7.304348\n 3:   9.827586\n 4:   6.656299\n 5:   5.436047\n 6:   5.231214\n 7:   4.005602\n 8:   7.648903\n 9:   7.238095\n10:   5.581395\n11:   5.174419\n12:   4.029484\n13:   4.638070\n14:   4.021164\n15:   1.980952\n16:   1.917404\n17:   2.750234\n18:  14.727273\n19:  18.823529\n20:  18.474114\n21:   8.722110\n22:   4.403409\n23:   4.425036\n24:   3.463542\n25:   4.993498\n26:  14.108527\n27:  12.149533\n28:  20.092531\n29:   4.984227\n30:   7.111913\n31:   4.201681\n32:   7.697842\n    efficiency\n\n\n\n\n\nSetting keys enables fast subsetting and joins:\n\n# Set a key\nsetkey(dt_copy, cyl)\ndt_copy\n\nKey: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:          Datsun 710 25.08     4 108.0    93  3.85 2.320 18.61     1     4\n 2:           Merc 240D 26.84     4 146.7    62  3.69 3.190 20.00     0     4\n 3:            Merc 230 25.08     4 140.8    95  3.92 3.150 22.90     0     4\n 4:            Fiat 128 35.64     4  78.7    66  4.08 2.200 19.47     1     4\n 5:         Honda Civic 33.44     4  75.7    52  4.93 1.615 18.52     1     4\n 6:      Toyota Corolla 37.29     4  71.1    65  4.22 1.835 19.90     1     4\n 7:       Toyota Corona 23.65     4 120.1    97  3.70 2.465 20.01     0     3\n 8:           Fiat X1-9 30.03     4  79.0    66  4.08 1.935 18.90     1     4\n 9:       Porsche 914-2 28.60     4 120.3    91  4.43 2.140 16.70     1     5\n10:        Lotus Europa 33.44     4  95.1   113  3.77 1.513 16.90     1     5\n11:          Volvo 142E 23.54     4 121.0   109  4.11 2.780 18.60     1     4\n12:           Mazda RX4 21.00     6 160.0   110  3.90 2.620 16.46     1     4\n13:       Mazda RX4 Wag 21.00     6 160.0   110  3.90 2.875 17.02     1     4\n14:      Hornet 4 Drive 21.40     6 258.0   110  3.08 3.215 19.44     0     3\n15:             Valiant 18.10     6 225.0   105  2.76 3.460 20.22     0     3\n16:            Merc 280 19.20     6 167.6   123  3.92 3.440 18.30     0     4\n17:           Merc 280C 17.80     6 167.6   123  3.92 3.440 18.90     0     4\n18:        Ferrari Dino 19.70     6 145.0   175  3.62 2.770 15.50     1     5\n19:   Hornet Sportabout 18.70     8 360.0   175  3.15 3.440 17.02     0     3\n20:          Duster 360 14.30     8 360.0   245  3.21 3.570 15.84     0     3\n21:          Merc 450SE 16.40     8 275.8   180  3.07 4.070 17.40     0     3\n22:          Merc 450SL 17.30     8 275.8   180  3.07 3.730 17.60     0     3\n23:         Merc 450SLC 15.20     8 275.8   180  3.07 3.780 18.00     0     3\n24:  Cadillac Fleetwood 10.40     8 472.0   205  2.93 5.250 17.98     0     3\n25: Lincoln Continental 10.40     8 460.0   215  3.00 5.424 17.82     0     3\n26:   Chrysler Imperial 14.70     8 440.0   230  3.23 5.345 17.42     0     3\n27:    Dodge Challenger 15.50     8 318.0   150  2.76 3.520 16.87     0     3\n28:         AMC Javelin 15.20     8 304.0   150  3.15 3.435 17.30     0     3\n29:          Camaro Z28 13.30     8 350.0   245  3.73 3.840 15.41     0     3\n30:    Pontiac Firebird 19.20     8 400.0   175  3.08 3.845 17.05     0     3\n31:      Ford Pantera L 15.80     8 351.0   264  4.22 3.170 14.50     1     5\n32:       Maserati Bora 15.00     8 301.0   335  3.54 3.570 14.60     1     5\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n    efficiency\n         &lt;num&gt;\n 1:   9.827586\n 2:   7.648903\n 3:   7.238095\n 4:  14.727273\n 5:  18.823529\n 6:  18.474114\n 7:   8.722110\n 8:  14.108527\n 9:  12.149533\n10:  20.092531\n11:   7.697842\n12:   8.015267\n13:   7.304348\n14:   6.656299\n15:   5.231214\n16:   5.581395\n17:   5.174419\n18:   7.111913\n19:   5.436047\n20:   4.005602\n21:   4.029484\n22:   4.638070\n23:   4.021164\n24:   1.980952\n25:   1.917404\n26:   2.750234\n27:   4.403409\n28:   4.425036\n29:   3.463542\n30:   4.993498\n31:   4.984227\n32:   4.201681\n    efficiency\n\n# Fast subsetting using key\ndt_copy[.(6)]  # All rows where cyl == 6\n\nKey: &lt;cyl&gt;\n            model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n           &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:      Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     1     4\n2:  Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     1     4\n3: Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     0     3\n4:        Valiant  18.1     6 225.0   105  2.76 3.460 20.22     0     3\n5:       Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     0     4\n6:      Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     0     4\n7:   Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     1     5\n   efficiency\n        &lt;num&gt;\n1:   8.015267\n2:   7.304348\n3:   6.656299\n4:   5.231214\n5:   5.581395\n6:   5.174419\n7:   7.111913\n\n# Multiple keys\nsetkey(dt_copy, cyl, gear)\ndt_copy[.(6, 4)]  # All rows where cyl == 6 and gear == 4\n\nKey: &lt;cyl, gear&gt;\n           model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n          &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:     Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     1     4\n2: Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     1     4\n3:      Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     0     4\n4:     Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     0     4\n   efficiency\n        &lt;num&gt;\n1:   8.015267\n2:   7.304348\n3:   5.581395\n4:   5.174419\n\n\n\n\n\ndata.table provides efficient joins using keys:\n\n# Create sample data.tables\nmanufacturers &lt;- data.table(\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Mercedes\"),\n  country = c(\"Japan\", \"Japan\", \"USA\", \"Germany\", \"Germany\")\n)\n\ncars &lt;- data.table(\n  model = c(\"Civic\", \"Corolla\", \"Focus\", \"3 Series\", \"Fiesta\"),\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Ford\")\n)\n\n# Set keys for joining\nsetkey(manufacturers, make)\nsetkey(cars, make)\n\n# Inner join\ncars[manufacturers]\n\nKey: &lt;make&gt;\n      model     make country\n     &lt;char&gt;   &lt;char&gt;  &lt;char&gt;\n1: 3 Series      BMW Germany\n2:    Focus     Ford     USA\n3:   Fiesta     Ford     USA\n4:    Civic    Honda   Japan\n5:     &lt;NA&gt; Mercedes Germany\n6:  Corolla   Toyota   Japan\n\n# Left join\nmanufacturers[cars, nomatch=NA]\n\nKey: &lt;make&gt;\n     make country    model\n   &lt;char&gt;  &lt;char&gt;   &lt;char&gt;\n1:    BMW Germany 3 Series\n2:   Ford     USA    Focus\n3:   Ford     USA   Fiesta\n4:  Honda   Japan    Civic\n5: Toyota   Japan  Corolla\n\n# Non-equi joins\ndt_cars[dt_cars[, .(max_mpg = max(mpg)), by = cyl], on = .(mpg = max_mpg, cyl)]\n\n              model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n             &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:   Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0     3\n2:   Toyota Corolla  33.9     4  71.1    65  4.22 1.835 19.90     1     1     4\n3: Pontiac Firebird  19.2     8 400.0   175  3.08 3.845 17.05     0     0     3\n    carb\n   &lt;num&gt;\n1:     1\n2:     1\n3:     2\n\n\n\n\n\ndata.table provides functions for reshaping data:\n\n# Create a sample data.table\ndt &lt;- data.table(\n  id = rep(1:3, each = 2),\n  variable = rep(c(\"height\", \"weight\"), 3),\n  value = c(170, 68, 155, 52, 182, 75)\n)\ndt\n\n      id variable value\n   &lt;int&gt;   &lt;char&gt; &lt;num&gt;\n1:     1   height   170\n2:     1   weight    68\n3:     2   height   155\n4:     2   weight    52\n5:     3   height   182\n6:     3   weight    75\n\n# Wide to long\ndt_wide &lt;- dcast(dt, id ~ variable, value.var = \"value\")\ndt_wide\n\nKey: &lt;id&gt;\n      id height weight\n   &lt;int&gt;  &lt;num&gt;  &lt;num&gt;\n1:     1    170     68\n2:     2    155     52\n3:     3    182     75\n\n# Long to wide\ndt_long &lt;- melt(dt_wide, id.vars = \"id\", variable.name = \"measure\", value.name = \"value\")\ndt_long\n\n      id measure value\n   &lt;int&gt;  &lt;fctr&gt; &lt;num&gt;\n1:     1  height   170\n2:     2  height   155\n3:     3  height   182\n4:     1  weight    68\n5:     2  weight    52\n6:     3  weight    75\n\n\n\n\n\ndata.table is designed for performance:\n\n# Create a larger dataset for demonstration\nset.seed(123)\nn &lt;- 1e5\ndt_large &lt;- data.table(\n  id = 1:n,\n  x = sample(1:100, n, replace = TRUE),\n  y = sample(letters[1:5], n, replace = TRUE)\n)\n\n# Measure time for a grouped operation\nsystem.time(dt_large[, .(mean_x = mean(x)), by = y])\n\n   user  system elapsed \n   0.00    0.00    0.02 \n\n# Compare with equivalent dplyr operation (if dplyr is installed)\nif (requireNamespace(\"dplyr\", quietly = TRUE)) {\n  df_large &lt;- as.data.frame(dt_large)\n  system.time(\n    dplyr::summarise(dplyr::group_by(df_large, y), mean_x = mean(x))\n  )\n}\n\n   user  system elapsed \n   0.01    0.00    0.01 \n\n\ndata.table is particularly valuable when working with large datasets due to its efficient memory usage and optimized C implementation."
  },
  {
    "objectID": "get-started/data-table.html#introduction-to-data.table",
    "href": "get-started/data-table.html#introduction-to-data.table",
    "title": "Introduction to data.table",
    "section": "",
    "text": "The data.table package is a high-performance extension of R’s data.frame that provides a concise syntax for data manipulation. It’s particularly efficient for large datasets.\n\n\nFirst, let’s install and load the package:\n\n# Install if needed (uncomment to run)\n# install.packages(\"data.table\")\n\n# Load the package\nlibrary(data.table)\n\n# Convert the built-in mtcars dataset to a data.table\ndt_cars &lt;- as.data.table(mtcars, keep.rownames = TRUE)\nsetnames(dt_cars, \"rn\", \"model\")  # Rename the rownames column\ndt_cars\n\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     0     1\n 2:       Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     0     1\n 3:          Datsun 710  22.8     4 108.0    93  3.85 2.320 18.61     1     1\n 4:      Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0\n 5:   Hornet Sportabout  18.7     8 360.0   175  3.15 3.440 17.02     0     0\n 6:             Valiant  18.1     6 225.0   105  2.76 3.460 20.22     1     0\n 7:          Duster 360  14.3     8 360.0   245  3.21 3.570 15.84     0     0\n 8:           Merc 240D  24.4     4 146.7    62  3.69 3.190 20.00     1     0\n 9:            Merc 230  22.8     4 140.8    95  3.92 3.150 22.90     1     0\n10:            Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     1     0\n11:           Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     1     0\n12:          Merc 450SE  16.4     8 275.8   180  3.07 4.070 17.40     0     0\n13:          Merc 450SL  17.3     8 275.8   180  3.07 3.730 17.60     0     0\n14:         Merc 450SLC  15.2     8 275.8   180  3.07 3.780 18.00     0     0\n15:  Cadillac Fleetwood  10.4     8 472.0   205  2.93 5.250 17.98     0     0\n16: Lincoln Continental  10.4     8 460.0   215  3.00 5.424 17.82     0     0\n17:   Chrysler Imperial  14.7     8 440.0   230  3.23 5.345 17.42     0     0\n18:            Fiat 128  32.4     4  78.7    66  4.08 2.200 19.47     1     1\n19:         Honda Civic  30.4     4  75.7    52  4.93 1.615 18.52     1     1\n20:      Toyota Corolla  33.9     4  71.1    65  4.22 1.835 19.90     1     1\n21:       Toyota Corona  21.5     4 120.1    97  3.70 2.465 20.01     1     0\n22:    Dodge Challenger  15.5     8 318.0   150  2.76 3.520 16.87     0     0\n23:         AMC Javelin  15.2     8 304.0   150  3.15 3.435 17.30     0     0\n24:          Camaro Z28  13.3     8 350.0   245  3.73 3.840 15.41     0     0\n25:    Pontiac Firebird  19.2     8 400.0   175  3.08 3.845 17.05     0     0\n26:           Fiat X1-9  27.3     4  79.0    66  4.08 1.935 18.90     1     1\n27:       Porsche 914-2  26.0     4 120.3    91  4.43 2.140 16.70     0     1\n28:        Lotus Europa  30.4     4  95.1   113  3.77 1.513 16.90     1     1\n29:      Ford Pantera L  15.8     8 351.0   264  4.22 3.170 14.50     0     1\n30:        Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     0     1\n31:       Maserati Bora  15.0     8 301.0   335  3.54 3.570 14.60     0     1\n32:          Volvo 142E  21.4     4 121.0   109  4.11 2.780 18.60     1     1\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n     gear  carb\n    &lt;num&gt; &lt;num&gt;\n 1:     4     4\n 2:     4     4\n 3:     4     1\n 4:     3     1\n 5:     3     2\n 6:     3     1\n 7:     3     4\n 8:     4     2\n 9:     4     2\n10:     4     4\n11:     4     4\n12:     3     3\n13:     3     3\n14:     3     3\n15:     3     4\n16:     3     4\n17:     3     4\n18:     4     1\n19:     4     2\n20:     4     1\n21:     3     1\n22:     3     2\n23:     3     2\n24:     3     4\n25:     3     2\n26:     4     1\n27:     5     2\n28:     5     2\n29:     5     4\n30:     5     6\n31:     5     8\n32:     4     2\n     gear  carb\n\n\n\n\n\ndata.table uses a concise syntax based on [i, j, by]: - i: Subset rows (WHERE) - j: Compute on columns (SELECT) - by: Group by columns (GROUP BY)\n\n\n\n# Select cars with 6 cylinders\ndt_cars[cyl == 6]\n\n            model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n           &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:      Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     0     1     4\n2:  Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     0     1     4\n3: Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0     3\n4:        Valiant  18.1     6 225.0   105  2.76 3.460 20.22     1     0     3\n5:       Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     1     0     4\n6:      Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     1     0     4\n7:   Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     0     1     5\n    carb\n   &lt;num&gt;\n1:     4\n2:     4\n3:     1\n4:     1\n5:     4\n6:     4\n7:     6\n\n# Multiple conditions\ndt_cars[cyl == 6 & mpg &gt; 20]\n\n            model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n           &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:      Mazda RX4  21.0     6   160   110  3.90 2.620 16.46     0     1     4\n2:  Mazda RX4 Wag  21.0     6   160   110  3.90 2.875 17.02     0     1     4\n3: Hornet 4 Drive  21.4     6   258   110  3.08 3.215 19.44     1     0     3\n    carb\n   &lt;num&gt;\n1:     4\n2:     4\n3:     1\n\n# Select specific rows by position\ndt_cars[1:5]\n\n               model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n              &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:         Mazda RX4  21.0     6   160   110  3.90 2.620 16.46     0     1\n2:     Mazda RX4 Wag  21.0     6   160   110  3.90 2.875 17.02     0     1\n3:        Datsun 710  22.8     4   108    93  3.85 2.320 18.61     1     1\n4:    Hornet 4 Drive  21.4     6   258   110  3.08 3.215 19.44     1     0\n5: Hornet Sportabout  18.7     8   360   175  3.15 3.440 17.02     0     0\n    gear  carb\n   &lt;num&gt; &lt;num&gt;\n1:     4     4\n2:     4     4\n3:     4     1\n4:     3     1\n5:     3     2\n\n\n\n\n\n\n# Select specific columns\ndt_cars[, .(mpg, hp, cyl)]\n\n      mpg    hp   cyl\n    &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:  21.0   110     6\n 2:  21.0   110     6\n 3:  22.8    93     4\n 4:  21.4   110     6\n 5:  18.7   175     8\n 6:  18.1   105     6\n 7:  14.3   245     8\n 8:  24.4    62     4\n 9:  22.8    95     4\n10:  19.2   123     6\n11:  17.8   123     6\n12:  16.4   180     8\n13:  17.3   180     8\n14:  15.2   180     8\n15:  10.4   205     8\n16:  10.4   215     8\n17:  14.7   230     8\n18:  32.4    66     4\n19:  30.4    52     4\n20:  33.9    65     4\n21:  21.5    97     4\n22:  15.5   150     8\n23:  15.2   150     8\n24:  13.3   245     8\n25:  19.2   175     8\n26:  27.3    66     4\n27:  26.0    91     4\n28:  30.4   113     4\n29:  15.8   264     8\n30:  19.7   175     6\n31:  15.0   335     8\n32:  21.4   109     4\n      mpg    hp   cyl\n\n# Compute new values\ndt_cars[, .(kpl = mpg * 0.425)]\n\n        kpl\n      &lt;num&gt;\n 1:  8.9250\n 2:  8.9250\n 3:  9.6900\n 4:  9.0950\n 5:  7.9475\n 6:  7.6925\n 7:  6.0775\n 8: 10.3700\n 9:  9.6900\n10:  8.1600\n11:  7.5650\n12:  6.9700\n13:  7.3525\n14:  6.4600\n15:  4.4200\n16:  4.4200\n17:  6.2475\n18: 13.7700\n19: 12.9200\n20: 14.4075\n21:  9.1375\n22:  6.5875\n23:  6.4600\n24:  5.6525\n25:  8.1600\n26: 11.6025\n27: 11.0500\n28: 12.9200\n29:  6.7150\n30:  8.3725\n31:  6.3750\n32:  9.0950\n        kpl\n\n# Select and compute multiple columns\ndt_cars[, .(model, kpl = mpg * 0.425, hp_per_cyl = hp/cyl)]\n\n                  model     kpl hp_per_cyl\n                 &lt;char&gt;   &lt;num&gt;      &lt;num&gt;\n 1:           Mazda RX4  8.9250   18.33333\n 2:       Mazda RX4 Wag  8.9250   18.33333\n 3:          Datsun 710  9.6900   23.25000\n 4:      Hornet 4 Drive  9.0950   18.33333\n 5:   Hornet Sportabout  7.9475   21.87500\n 6:             Valiant  7.6925   17.50000\n 7:          Duster 360  6.0775   30.62500\n 8:           Merc 240D 10.3700   15.50000\n 9:            Merc 230  9.6900   23.75000\n10:            Merc 280  8.1600   20.50000\n11:           Merc 280C  7.5650   20.50000\n12:          Merc 450SE  6.9700   22.50000\n13:          Merc 450SL  7.3525   22.50000\n14:         Merc 450SLC  6.4600   22.50000\n15:  Cadillac Fleetwood  4.4200   25.62500\n16: Lincoln Continental  4.4200   26.87500\n17:   Chrysler Imperial  6.2475   28.75000\n18:            Fiat 128 13.7700   16.50000\n19:         Honda Civic 12.9200   13.00000\n20:      Toyota Corolla 14.4075   16.25000\n21:       Toyota Corona  9.1375   24.25000\n22:    Dodge Challenger  6.5875   18.75000\n23:         AMC Javelin  6.4600   18.75000\n24:          Camaro Z28  5.6525   30.62500\n25:    Pontiac Firebird  8.1600   21.87500\n26:           Fiat X1-9 11.6025   16.50000\n27:       Porsche 914-2 11.0500   22.75000\n28:        Lotus Europa 12.9200   28.25000\n29:      Ford Pantera L  6.7150   33.00000\n30:        Ferrari Dino  8.3725   29.16667\n31:       Maserati Bora  6.3750   41.87500\n32:          Volvo 142E  9.0950   27.25000\n                  model     kpl hp_per_cyl\n\n# Apply functions\ndt_cars[, .(avg_mpg = mean(mpg), max_hp = max(hp))]\n\n    avg_mpg max_hp\n      &lt;num&gt;  &lt;num&gt;\n1: 20.09062    335\n\n\n\n\n\n\n# Group by cylinder and calculate statistics\ndt_cars[, .(count = .N, avg_mpg = mean(mpg)), by = cyl]\n\n     cyl count  avg_mpg\n   &lt;num&gt; &lt;int&gt;    &lt;num&gt;\n1:     6     7 19.74286\n2:     4    11 26.66364\n3:     8    14 15.10000\n\n# Multiple grouping variables\ndt_cars[, .(count = .N, avg_mpg = mean(mpg)), by = .(cyl, gear)]\n\n     cyl  gear count avg_mpg\n   &lt;num&gt; &lt;num&gt; &lt;int&gt;   &lt;num&gt;\n1:     6     4     4  19.750\n2:     4     4     8  26.925\n3:     6     3     2  19.750\n4:     8     3    12  15.050\n5:     4     3     1  21.500\n6:     4     5     2  28.200\n7:     8     5     2  15.400\n8:     6     5     1  19.700\n\n# Grouping with expressions\ndt_cars[, .(count = .N), by = .(cyl, high_mpg = mpg &gt; 20)]\n\n     cyl high_mpg count\n   &lt;num&gt;   &lt;lgcl&gt; &lt;int&gt;\n1:     6     TRUE     3\n2:     4     TRUE    11\n3:     8    FALSE    14\n4:     6    FALSE     4\n\n\n\n\n\n\ndata.table provides special symbols for common operations:\n\n# .N: number of rows\ndt_cars[, .N]\n\n[1] 32\n\ndt_cars[, .N, by = cyl]\n\n     cyl     N\n   &lt;num&gt; &lt;int&gt;\n1:     6     7\n2:     4    11\n3:     8    14\n\n# .SD: Subset of Data\ndt_cars[, lapply(.SD, mean), by = cyl, .SDcols = c(\"mpg\", \"hp\", \"wt\")]\n\n     cyl      mpg        hp       wt\n   &lt;num&gt;    &lt;num&gt;     &lt;num&gt;    &lt;num&gt;\n1:     6 19.74286 122.28571 3.117143\n2:     4 26.66364  82.63636 2.285727\n3:     8 15.10000 209.21429 3.999214\n\n# .I: Row numbers\ndt_cars[, .I[1:2], by = cyl]  # First two row numbers for each cyl group\n\n     cyl    V1\n   &lt;num&gt; &lt;int&gt;\n1:     6     1\n2:     6     2\n3:     4     3\n4:     4     8\n5:     8     5\n6:     8     7\n\n\n\n\n\ndata.table allows efficient in-place modifications:\n\n# Create a copy to avoid modifying the original\ndt_copy &lt;- copy(dt_cars)\n\n# Add a new column\ndt_copy[, efficiency := mpg/wt]\ndt_copy\n\nIndex: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     0     1\n 2:       Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     0     1\n 3:          Datsun 710  22.8     4 108.0    93  3.85 2.320 18.61     1     1\n 4:      Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0\n 5:   Hornet Sportabout  18.7     8 360.0   175  3.15 3.440 17.02     0     0\n 6:             Valiant  18.1     6 225.0   105  2.76 3.460 20.22     1     0\n 7:          Duster 360  14.3     8 360.0   245  3.21 3.570 15.84     0     0\n 8:           Merc 240D  24.4     4 146.7    62  3.69 3.190 20.00     1     0\n 9:            Merc 230  22.8     4 140.8    95  3.92 3.150 22.90     1     0\n10:            Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     1     0\n11:           Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     1     0\n12:          Merc 450SE  16.4     8 275.8   180  3.07 4.070 17.40     0     0\n13:          Merc 450SL  17.3     8 275.8   180  3.07 3.730 17.60     0     0\n14:         Merc 450SLC  15.2     8 275.8   180  3.07 3.780 18.00     0     0\n15:  Cadillac Fleetwood  10.4     8 472.0   205  2.93 5.250 17.98     0     0\n16: Lincoln Continental  10.4     8 460.0   215  3.00 5.424 17.82     0     0\n17:   Chrysler Imperial  14.7     8 440.0   230  3.23 5.345 17.42     0     0\n18:            Fiat 128  32.4     4  78.7    66  4.08 2.200 19.47     1     1\n19:         Honda Civic  30.4     4  75.7    52  4.93 1.615 18.52     1     1\n20:      Toyota Corolla  33.9     4  71.1    65  4.22 1.835 19.90     1     1\n21:       Toyota Corona  21.5     4 120.1    97  3.70 2.465 20.01     1     0\n22:    Dodge Challenger  15.5     8 318.0   150  2.76 3.520 16.87     0     0\n23:         AMC Javelin  15.2     8 304.0   150  3.15 3.435 17.30     0     0\n24:          Camaro Z28  13.3     8 350.0   245  3.73 3.840 15.41     0     0\n25:    Pontiac Firebird  19.2     8 400.0   175  3.08 3.845 17.05     0     0\n26:           Fiat X1-9  27.3     4  79.0    66  4.08 1.935 18.90     1     1\n27:       Porsche 914-2  26.0     4 120.3    91  4.43 2.140 16.70     0     1\n28:        Lotus Europa  30.4     4  95.1   113  3.77 1.513 16.90     1     1\n29:      Ford Pantera L  15.8     8 351.0   264  4.22 3.170 14.50     0     1\n30:        Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     0     1\n31:       Maserati Bora  15.0     8 301.0   335  3.54 3.570 14.60     0     1\n32:          Volvo 142E  21.4     4 121.0   109  4.11 2.780 18.60     1     1\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n     gear  carb efficiency\n    &lt;num&gt; &lt;num&gt;      &lt;num&gt;\n 1:     4     4   8.015267\n 2:     4     4   7.304348\n 3:     4     1   9.827586\n 4:     3     1   6.656299\n 5:     3     2   5.436047\n 6:     3     1   5.231214\n 7:     3     4   4.005602\n 8:     4     2   7.648903\n 9:     4     2   7.238095\n10:     4     4   5.581395\n11:     4     4   5.174419\n12:     3     3   4.029484\n13:     3     3   4.638070\n14:     3     3   4.021164\n15:     3     4   1.980952\n16:     3     4   1.917404\n17:     3     4   2.750234\n18:     4     1  14.727273\n19:     4     2  18.823529\n20:     4     1  18.474114\n21:     3     1   8.722110\n22:     3     2   4.403409\n23:     3     2   4.425036\n24:     3     4   3.463542\n25:     3     2   4.993498\n26:     4     1  14.108527\n27:     5     2  12.149533\n28:     5     2  20.092531\n29:     5     4   4.984227\n30:     5     6   7.111913\n31:     5     8   4.201681\n32:     4     2   7.697842\n     gear  carb efficiency\n\n# Update existing values\ndt_copy[cyl == 4, mpg := mpg * 1.1]  # Increase mpg by 10% for 4-cylinder cars\ndt_copy\n\nIndex: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4 21.00     6 160.0   110  3.90 2.620 16.46     0     1\n 2:       Mazda RX4 Wag 21.00     6 160.0   110  3.90 2.875 17.02     0     1\n 3:          Datsun 710 25.08     4 108.0    93  3.85 2.320 18.61     1     1\n 4:      Hornet 4 Drive 21.40     6 258.0   110  3.08 3.215 19.44     1     0\n 5:   Hornet Sportabout 18.70     8 360.0   175  3.15 3.440 17.02     0     0\n 6:             Valiant 18.10     6 225.0   105  2.76 3.460 20.22     1     0\n 7:          Duster 360 14.30     8 360.0   245  3.21 3.570 15.84     0     0\n 8:           Merc 240D 26.84     4 146.7    62  3.69 3.190 20.00     1     0\n 9:            Merc 230 25.08     4 140.8    95  3.92 3.150 22.90     1     0\n10:            Merc 280 19.20     6 167.6   123  3.92 3.440 18.30     1     0\n11:           Merc 280C 17.80     6 167.6   123  3.92 3.440 18.90     1     0\n12:          Merc 450SE 16.40     8 275.8   180  3.07 4.070 17.40     0     0\n13:          Merc 450SL 17.30     8 275.8   180  3.07 3.730 17.60     0     0\n14:         Merc 450SLC 15.20     8 275.8   180  3.07 3.780 18.00     0     0\n15:  Cadillac Fleetwood 10.40     8 472.0   205  2.93 5.250 17.98     0     0\n16: Lincoln Continental 10.40     8 460.0   215  3.00 5.424 17.82     0     0\n17:   Chrysler Imperial 14.70     8 440.0   230  3.23 5.345 17.42     0     0\n18:            Fiat 128 35.64     4  78.7    66  4.08 2.200 19.47     1     1\n19:         Honda Civic 33.44     4  75.7    52  4.93 1.615 18.52     1     1\n20:      Toyota Corolla 37.29     4  71.1    65  4.22 1.835 19.90     1     1\n21:       Toyota Corona 23.65     4 120.1    97  3.70 2.465 20.01     1     0\n22:    Dodge Challenger 15.50     8 318.0   150  2.76 3.520 16.87     0     0\n23:         AMC Javelin 15.20     8 304.0   150  3.15 3.435 17.30     0     0\n24:          Camaro Z28 13.30     8 350.0   245  3.73 3.840 15.41     0     0\n25:    Pontiac Firebird 19.20     8 400.0   175  3.08 3.845 17.05     0     0\n26:           Fiat X1-9 30.03     4  79.0    66  4.08 1.935 18.90     1     1\n27:       Porsche 914-2 28.60     4 120.3    91  4.43 2.140 16.70     0     1\n28:        Lotus Europa 33.44     4  95.1   113  3.77 1.513 16.90     1     1\n29:      Ford Pantera L 15.80     8 351.0   264  4.22 3.170 14.50     0     1\n30:        Ferrari Dino 19.70     6 145.0   175  3.62 2.770 15.50     0     1\n31:       Maserati Bora 15.00     8 301.0   335  3.54 3.570 14.60     0     1\n32:          Volvo 142E 23.54     4 121.0   109  4.11 2.780 18.60     1     1\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n     gear  carb efficiency\n    &lt;num&gt; &lt;num&gt;      &lt;num&gt;\n 1:     4     4   8.015267\n 2:     4     4   7.304348\n 3:     4     1   9.827586\n 4:     3     1   6.656299\n 5:     3     2   5.436047\n 6:     3     1   5.231214\n 7:     3     4   4.005602\n 8:     4     2   7.648903\n 9:     4     2   7.238095\n10:     4     4   5.581395\n11:     4     4   5.174419\n12:     3     3   4.029484\n13:     3     3   4.638070\n14:     3     3   4.021164\n15:     3     4   1.980952\n16:     3     4   1.917404\n17:     3     4   2.750234\n18:     4     1  14.727273\n19:     4     2  18.823529\n20:     4     1  18.474114\n21:     3     1   8.722110\n22:     3     2   4.403409\n23:     3     2   4.425036\n24:     3     4   3.463542\n25:     3     2   4.993498\n26:     4     1  14.108527\n27:     5     2  12.149533\n28:     5     2  20.092531\n29:     5     4   4.984227\n30:     5     6   7.111913\n31:     5     8   4.201681\n32:     4     2   7.697842\n     gear  carb efficiency\n\n# Delete columns\ndt_copy[, c(\"carb\", \"vs\") := NULL]\ndt_copy\n\nIndex: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:           Mazda RX4 21.00     6 160.0   110  3.90 2.620 16.46     1     4\n 2:       Mazda RX4 Wag 21.00     6 160.0   110  3.90 2.875 17.02     1     4\n 3:          Datsun 710 25.08     4 108.0    93  3.85 2.320 18.61     1     4\n 4:      Hornet 4 Drive 21.40     6 258.0   110  3.08 3.215 19.44     0     3\n 5:   Hornet Sportabout 18.70     8 360.0   175  3.15 3.440 17.02     0     3\n 6:             Valiant 18.10     6 225.0   105  2.76 3.460 20.22     0     3\n 7:          Duster 360 14.30     8 360.0   245  3.21 3.570 15.84     0     3\n 8:           Merc 240D 26.84     4 146.7    62  3.69 3.190 20.00     0     4\n 9:            Merc 230 25.08     4 140.8    95  3.92 3.150 22.90     0     4\n10:            Merc 280 19.20     6 167.6   123  3.92 3.440 18.30     0     4\n11:           Merc 280C 17.80     6 167.6   123  3.92 3.440 18.90     0     4\n12:          Merc 450SE 16.40     8 275.8   180  3.07 4.070 17.40     0     3\n13:          Merc 450SL 17.30     8 275.8   180  3.07 3.730 17.60     0     3\n14:         Merc 450SLC 15.20     8 275.8   180  3.07 3.780 18.00     0     3\n15:  Cadillac Fleetwood 10.40     8 472.0   205  2.93 5.250 17.98     0     3\n16: Lincoln Continental 10.40     8 460.0   215  3.00 5.424 17.82     0     3\n17:   Chrysler Imperial 14.70     8 440.0   230  3.23 5.345 17.42     0     3\n18:            Fiat 128 35.64     4  78.7    66  4.08 2.200 19.47     1     4\n19:         Honda Civic 33.44     4  75.7    52  4.93 1.615 18.52     1     4\n20:      Toyota Corolla 37.29     4  71.1    65  4.22 1.835 19.90     1     4\n21:       Toyota Corona 23.65     4 120.1    97  3.70 2.465 20.01     0     3\n22:    Dodge Challenger 15.50     8 318.0   150  2.76 3.520 16.87     0     3\n23:         AMC Javelin 15.20     8 304.0   150  3.15 3.435 17.30     0     3\n24:          Camaro Z28 13.30     8 350.0   245  3.73 3.840 15.41     0     3\n25:    Pontiac Firebird 19.20     8 400.0   175  3.08 3.845 17.05     0     3\n26:           Fiat X1-9 30.03     4  79.0    66  4.08 1.935 18.90     1     4\n27:       Porsche 914-2 28.60     4 120.3    91  4.43 2.140 16.70     1     5\n28:        Lotus Europa 33.44     4  95.1   113  3.77 1.513 16.90     1     5\n29:      Ford Pantera L 15.80     8 351.0   264  4.22 3.170 14.50     1     5\n30:        Ferrari Dino 19.70     6 145.0   175  3.62 2.770 15.50     1     5\n31:       Maserati Bora 15.00     8 301.0   335  3.54 3.570 14.60     1     5\n32:          Volvo 142E 23.54     4 121.0   109  4.11 2.780 18.60     1     4\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n    efficiency\n         &lt;num&gt;\n 1:   8.015267\n 2:   7.304348\n 3:   9.827586\n 4:   6.656299\n 5:   5.436047\n 6:   5.231214\n 7:   4.005602\n 8:   7.648903\n 9:   7.238095\n10:   5.581395\n11:   5.174419\n12:   4.029484\n13:   4.638070\n14:   4.021164\n15:   1.980952\n16:   1.917404\n17:   2.750234\n18:  14.727273\n19:  18.823529\n20:  18.474114\n21:   8.722110\n22:   4.403409\n23:   4.425036\n24:   3.463542\n25:   4.993498\n26:  14.108527\n27:  12.149533\n28:  20.092531\n29:   4.984227\n30:   7.111913\n31:   4.201681\n32:   7.697842\n    efficiency\n\n\n\n\n\nSetting keys enables fast subsetting and joins:\n\n# Set a key\nsetkey(dt_copy, cyl)\ndt_copy\n\nKey: &lt;cyl&gt;\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n                 &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n 1:          Datsun 710 25.08     4 108.0    93  3.85 2.320 18.61     1     4\n 2:           Merc 240D 26.84     4 146.7    62  3.69 3.190 20.00     0     4\n 3:            Merc 230 25.08     4 140.8    95  3.92 3.150 22.90     0     4\n 4:            Fiat 128 35.64     4  78.7    66  4.08 2.200 19.47     1     4\n 5:         Honda Civic 33.44     4  75.7    52  4.93 1.615 18.52     1     4\n 6:      Toyota Corolla 37.29     4  71.1    65  4.22 1.835 19.90     1     4\n 7:       Toyota Corona 23.65     4 120.1    97  3.70 2.465 20.01     0     3\n 8:           Fiat X1-9 30.03     4  79.0    66  4.08 1.935 18.90     1     4\n 9:       Porsche 914-2 28.60     4 120.3    91  4.43 2.140 16.70     1     5\n10:        Lotus Europa 33.44     4  95.1   113  3.77 1.513 16.90     1     5\n11:          Volvo 142E 23.54     4 121.0   109  4.11 2.780 18.60     1     4\n12:           Mazda RX4 21.00     6 160.0   110  3.90 2.620 16.46     1     4\n13:       Mazda RX4 Wag 21.00     6 160.0   110  3.90 2.875 17.02     1     4\n14:      Hornet 4 Drive 21.40     6 258.0   110  3.08 3.215 19.44     0     3\n15:             Valiant 18.10     6 225.0   105  2.76 3.460 20.22     0     3\n16:            Merc 280 19.20     6 167.6   123  3.92 3.440 18.30     0     4\n17:           Merc 280C 17.80     6 167.6   123  3.92 3.440 18.90     0     4\n18:        Ferrari Dino 19.70     6 145.0   175  3.62 2.770 15.50     1     5\n19:   Hornet Sportabout 18.70     8 360.0   175  3.15 3.440 17.02     0     3\n20:          Duster 360 14.30     8 360.0   245  3.21 3.570 15.84     0     3\n21:          Merc 450SE 16.40     8 275.8   180  3.07 4.070 17.40     0     3\n22:          Merc 450SL 17.30     8 275.8   180  3.07 3.730 17.60     0     3\n23:         Merc 450SLC 15.20     8 275.8   180  3.07 3.780 18.00     0     3\n24:  Cadillac Fleetwood 10.40     8 472.0   205  2.93 5.250 17.98     0     3\n25: Lincoln Continental 10.40     8 460.0   215  3.00 5.424 17.82     0     3\n26:   Chrysler Imperial 14.70     8 440.0   230  3.23 5.345 17.42     0     3\n27:    Dodge Challenger 15.50     8 318.0   150  2.76 3.520 16.87     0     3\n28:         AMC Javelin 15.20     8 304.0   150  3.15 3.435 17.30     0     3\n29:          Camaro Z28 13.30     8 350.0   245  3.73 3.840 15.41     0     3\n30:    Pontiac Firebird 19.20     8 400.0   175  3.08 3.845 17.05     0     3\n31:      Ford Pantera L 15.80     8 351.0   264  4.22 3.170 14.50     1     5\n32:       Maserati Bora 15.00     8 301.0   335  3.54 3.570 14.60     1     5\n                  model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n    efficiency\n         &lt;num&gt;\n 1:   9.827586\n 2:   7.648903\n 3:   7.238095\n 4:  14.727273\n 5:  18.823529\n 6:  18.474114\n 7:   8.722110\n 8:  14.108527\n 9:  12.149533\n10:  20.092531\n11:   7.697842\n12:   8.015267\n13:   7.304348\n14:   6.656299\n15:   5.231214\n16:   5.581395\n17:   5.174419\n18:   7.111913\n19:   5.436047\n20:   4.005602\n21:   4.029484\n22:   4.638070\n23:   4.021164\n24:   1.980952\n25:   1.917404\n26:   2.750234\n27:   4.403409\n28:   4.425036\n29:   3.463542\n30:   4.993498\n31:   4.984227\n32:   4.201681\n    efficiency\n\n# Fast subsetting using key\ndt_copy[.(6)]  # All rows where cyl == 6\n\nKey: &lt;cyl&gt;\n            model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n           &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:      Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     1     4\n2:  Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     1     4\n3: Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     0     3\n4:        Valiant  18.1     6 225.0   105  2.76 3.460 20.22     0     3\n5:       Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     0     4\n6:      Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     0     4\n7:   Ferrari Dino  19.7     6 145.0   175  3.62 2.770 15.50     1     5\n   efficiency\n        &lt;num&gt;\n1:   8.015267\n2:   7.304348\n3:   6.656299\n4:   5.231214\n5:   5.581395\n6:   5.174419\n7:   7.111913\n\n# Multiple keys\nsetkey(dt_copy, cyl, gear)\ndt_copy[.(6, 4)]  # All rows where cyl == 6 and gear == 4\n\nKey: &lt;cyl, gear&gt;\n           model   mpg   cyl  disp    hp  drat    wt  qsec    am  gear\n          &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:     Mazda RX4  21.0     6 160.0   110  3.90 2.620 16.46     1     4\n2: Mazda RX4 Wag  21.0     6 160.0   110  3.90 2.875 17.02     1     4\n3:      Merc 280  19.2     6 167.6   123  3.92 3.440 18.30     0     4\n4:     Merc 280C  17.8     6 167.6   123  3.92 3.440 18.90     0     4\n   efficiency\n        &lt;num&gt;\n1:   8.015267\n2:   7.304348\n3:   5.581395\n4:   5.174419\n\n\n\n\n\ndata.table provides efficient joins using keys:\n\n# Create sample data.tables\nmanufacturers &lt;- data.table(\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Mercedes\"),\n  country = c(\"Japan\", \"Japan\", \"USA\", \"Germany\", \"Germany\")\n)\n\ncars &lt;- data.table(\n  model = c(\"Civic\", \"Corolla\", \"Focus\", \"3 Series\", \"Fiesta\"),\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Ford\")\n)\n\n# Set keys for joining\nsetkey(manufacturers, make)\nsetkey(cars, make)\n\n# Inner join\ncars[manufacturers]\n\nKey: &lt;make&gt;\n      model     make country\n     &lt;char&gt;   &lt;char&gt;  &lt;char&gt;\n1: 3 Series      BMW Germany\n2:    Focus     Ford     USA\n3:   Fiesta     Ford     USA\n4:    Civic    Honda   Japan\n5:     &lt;NA&gt; Mercedes Germany\n6:  Corolla   Toyota   Japan\n\n# Left join\nmanufacturers[cars, nomatch=NA]\n\nKey: &lt;make&gt;\n     make country    model\n   &lt;char&gt;  &lt;char&gt;   &lt;char&gt;\n1:    BMW Germany 3 Series\n2:   Ford     USA    Focus\n3:   Ford     USA   Fiesta\n4:  Honda   Japan    Civic\n5: Toyota   Japan  Corolla\n\n# Non-equi joins\ndt_cars[dt_cars[, .(max_mpg = max(mpg)), by = cyl], on = .(mpg = max_mpg, cyl)]\n\n              model   mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n             &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:   Hornet 4 Drive  21.4     6 258.0   110  3.08 3.215 19.44     1     0     3\n2:   Toyota Corolla  33.9     4  71.1    65  4.22 1.835 19.90     1     1     4\n3: Pontiac Firebird  19.2     8 400.0   175  3.08 3.845 17.05     0     0     3\n    carb\n   &lt;num&gt;\n1:     1\n2:     1\n3:     2\n\n\n\n\n\ndata.table provides functions for reshaping data:\n\n# Create a sample data.table\ndt &lt;- data.table(\n  id = rep(1:3, each = 2),\n  variable = rep(c(\"height\", \"weight\"), 3),\n  value = c(170, 68, 155, 52, 182, 75)\n)\ndt\n\n      id variable value\n   &lt;int&gt;   &lt;char&gt; &lt;num&gt;\n1:     1   height   170\n2:     1   weight    68\n3:     2   height   155\n4:     2   weight    52\n5:     3   height   182\n6:     3   weight    75\n\n# Wide to long\ndt_wide &lt;- dcast(dt, id ~ variable, value.var = \"value\")\ndt_wide\n\nKey: &lt;id&gt;\n      id height weight\n   &lt;int&gt;  &lt;num&gt;  &lt;num&gt;\n1:     1    170     68\n2:     2    155     52\n3:     3    182     75\n\n# Long to wide\ndt_long &lt;- melt(dt_wide, id.vars = \"id\", variable.name = \"measure\", value.name = \"value\")\ndt_long\n\n      id measure value\n   &lt;int&gt;  &lt;fctr&gt; &lt;num&gt;\n1:     1  height   170\n2:     2  height   155\n3:     3  height   182\n4:     1  weight    68\n5:     2  weight    52\n6:     3  weight    75\n\n\n\n\n\ndata.table is designed for performance:\n\n# Create a larger dataset for demonstration\nset.seed(123)\nn &lt;- 1e5\ndt_large &lt;- data.table(\n  id = 1:n,\n  x = sample(1:100, n, replace = TRUE),\n  y = sample(letters[1:5], n, replace = TRUE)\n)\n\n# Measure time for a grouped operation\nsystem.time(dt_large[, .(mean_x = mean(x)), by = y])\n\n   user  system elapsed \n   0.00    0.00    0.02 \n\n# Compare with equivalent dplyr operation (if dplyr is installed)\nif (requireNamespace(\"dplyr\", quietly = TRUE)) {\n  df_large &lt;- as.data.frame(dt_large)\n  system.time(\n    dplyr::summarise(dplyr::group_by(df_large, y), mean_x = mean(x))\n  )\n}\n\n   user  system elapsed \n   0.01    0.00    0.01 \n\n\ndata.table is particularly valuable when working with large datasets due to its efficient memory usage and optimized C implementation."
  },
  {
    "objectID": "get-started/dplyr.html",
    "href": "get-started/dplyr.html",
    "title": "Introduction to dplyr",
    "section": "",
    "text": "The dplyr package is part of the tidyverse and provides a grammar for data manipulation in R. It makes data transformation tasks more intuitive and readable.\n\n\nFirst, let’s install and load the package:\n\n# Install if needed (uncomment to run)\n# install.packages(\"dplyr\")\n# install.packages(\"tibble\")\n\n# Load the packages\nlibrary(dplyr)\nlibrary(tibble)  # For rownames_to_column function\n\n# We'll use the built-in mtcars dataset\ndata(mtcars)\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n\n\ndplyr is built around a set of core verbs (functions) that perform common data manipulation tasks:\n\n\n\n# Select cars with 6 cylinders\nfilter(mtcars, cyl == 6)\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n\n# Multiple conditions: cars with 6 cylinders AND mpg &gt; 20\nfilter(mtcars, cyl == 6, mpg &gt; 20)\n\n                mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n\n# OR conditions\nfilter(mtcars, cyl == 6 | mpg &gt; 30)\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n\n\n\n\n\n\n# Select specific columns\nselect(mtcars, mpg, cyl, hp)\n\n                     mpg cyl  hp\nMazda RX4           21.0   6 110\nMazda RX4 Wag       21.0   6 110\nDatsun 710          22.8   4  93\nHornet 4 Drive      21.4   6 110\nHornet Sportabout   18.7   8 175\nValiant             18.1   6 105\nDuster 360          14.3   8 245\nMerc 240D           24.4   4  62\nMerc 230            22.8   4  95\nMerc 280            19.2   6 123\nMerc 280C           17.8   6 123\nMerc 450SE          16.4   8 180\nMerc 450SL          17.3   8 180\nMerc 450SLC         15.2   8 180\nCadillac Fleetwood  10.4   8 205\nLincoln Continental 10.4   8 215\nChrysler Imperial   14.7   8 230\nFiat 128            32.4   4  66\nHonda Civic         30.4   4  52\nToyota Corolla      33.9   4  65\nToyota Corona       21.5   4  97\nDodge Challenger    15.5   8 150\nAMC Javelin         15.2   8 150\nCamaro Z28          13.3   8 245\nPontiac Firebird    19.2   8 175\nFiat X1-9           27.3   4  66\nPorsche 914-2       26.0   4  91\nLotus Europa        30.4   4 113\nFord Pantera L      15.8   8 264\nFerrari Dino        19.7   6 175\nMaserati Bora       15.0   8 335\nVolvo 142E          21.4   4 109\n\n# Select a range of columns\nselect(mtcars, mpg:hp)\n\n                     mpg cyl  disp  hp\nMazda RX4           21.0   6 160.0 110\nMazda RX4 Wag       21.0   6 160.0 110\nDatsun 710          22.8   4 108.0  93\nHornet 4 Drive      21.4   6 258.0 110\nHornet Sportabout   18.7   8 360.0 175\nValiant             18.1   6 225.0 105\nDuster 360          14.3   8 360.0 245\nMerc 240D           24.4   4 146.7  62\nMerc 230            22.8   4 140.8  95\nMerc 280            19.2   6 167.6 123\nMerc 280C           17.8   6 167.6 123\nMerc 450SE          16.4   8 275.8 180\nMerc 450SL          17.3   8 275.8 180\nMerc 450SLC         15.2   8 275.8 180\nCadillac Fleetwood  10.4   8 472.0 205\nLincoln Continental 10.4   8 460.0 215\nChrysler Imperial   14.7   8 440.0 230\nFiat 128            32.4   4  78.7  66\nHonda Civic         30.4   4  75.7  52\nToyota Corolla      33.9   4  71.1  65\nToyota Corona       21.5   4 120.1  97\nDodge Challenger    15.5   8 318.0 150\nAMC Javelin         15.2   8 304.0 150\nCamaro Z28          13.3   8 350.0 245\nPontiac Firebird    19.2   8 400.0 175\nFiat X1-9           27.3   4  79.0  66\nPorsche 914-2       26.0   4 120.3  91\nLotus Europa        30.4   4  95.1 113\nFord Pantera L      15.8   8 351.0 264\nFerrari Dino        19.7   6 145.0 175\nMaserati Bora       15.0   8 301.0 335\nVolvo 142E          21.4   4 121.0 109\n\n# Select all columns except some\nselect(mtcars, -gear, -carb)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1\n\n# Rename columns while selecting\nselect(mtcars, miles_per_gallon = mpg, cylinders = cyl)\n\n                    miles_per_gallon cylinders\nMazda RX4                       21.0         6\nMazda RX4 Wag                   21.0         6\nDatsun 710                      22.8         4\nHornet 4 Drive                  21.4         6\nHornet Sportabout               18.7         8\nValiant                         18.1         6\nDuster 360                      14.3         8\nMerc 240D                       24.4         4\nMerc 230                        22.8         4\nMerc 280                        19.2         6\nMerc 280C                       17.8         6\nMerc 450SE                      16.4         8\nMerc 450SL                      17.3         8\nMerc 450SLC                     15.2         8\nCadillac Fleetwood              10.4         8\nLincoln Continental             10.4         8\nChrysler Imperial               14.7         8\nFiat 128                        32.4         4\nHonda Civic                     30.4         4\nToyota Corolla                  33.9         4\nToyota Corona                   21.5         4\nDodge Challenger                15.5         8\nAMC Javelin                     15.2         8\nCamaro Z28                      13.3         8\nPontiac Firebird                19.2         8\nFiat X1-9                       27.3         4\nPorsche 914-2                   26.0         4\nLotus Europa                    30.4         4\nFord Pantera L                  15.8         8\nFerrari Dino                    19.7         6\nMaserati Bora                   15.0         8\nVolvo 142E                      21.4         4\n\n\n\n\n\n\n# Add a new column\nmutate(mtcars, \n       kpl = mpg * 0.425,  # Convert mpg to km per liter\n       hp_per_cyl = hp / cyl)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb     kpl\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  8.9250\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  8.9250\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1  9.6900\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  9.0950\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  7.9475\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  7.6925\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  6.0775\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 10.3700\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  9.6900\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  8.1600\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  7.5650\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  6.9700\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  7.3525\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  6.4600\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  4.4200\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  4.4200\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  6.2475\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 13.7700\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 12.9200\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 14.4075\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  9.1375\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  6.5875\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  6.4600\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  5.6525\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  8.1600\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 11.6025\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 11.0500\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 12.9200\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  6.7150\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  8.3725\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  6.3750\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  9.0950\n                    hp_per_cyl\nMazda RX4             18.33333\nMazda RX4 Wag         18.33333\nDatsun 710            23.25000\nHornet 4 Drive        18.33333\nHornet Sportabout     21.87500\nValiant               17.50000\nDuster 360            30.62500\nMerc 240D             15.50000\nMerc 230              23.75000\nMerc 280              20.50000\nMerc 280C             20.50000\nMerc 450SE            22.50000\nMerc 450SL            22.50000\nMerc 450SLC           22.50000\nCadillac Fleetwood    25.62500\nLincoln Continental   26.87500\nChrysler Imperial     28.75000\nFiat 128              16.50000\nHonda Civic           13.00000\nToyota Corolla        16.25000\nToyota Corona         24.25000\nDodge Challenger      18.75000\nAMC Javelin           18.75000\nCamaro Z28            30.62500\nPontiac Firebird      21.87500\nFiat X1-9             16.50000\nPorsche 914-2         22.75000\nLotus Europa          28.25000\nFord Pantera L        33.00000\nFerrari Dino          29.16667\nMaserati Bora         41.87500\nVolvo 142E            27.25000\n\n# Modify existing columns and add new ones\nmutate(mtcars,\n       mpg = mpg * 0.425,  # Overwrite mpg with km per liter\n       efficiency = mpg / wt)\n\n                        mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4            8.9250   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag        8.9250   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710           9.6900   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive       9.0950   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout    7.9475   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant              7.6925   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360           6.0775   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           10.3700   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230             9.6900   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280             8.1600   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C            7.5650   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE           6.9700   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL           7.3525   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC          6.4600   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood   4.4200   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental  4.4200   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial    6.2475   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            13.7700   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         12.9200   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      14.4075   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona        9.1375   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger     6.5875   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin          6.4600   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28           5.6525   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird     8.1600   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           11.6025   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       11.0500   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        12.9200   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L       6.7150   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino         8.3725   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora        6.3750   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E           9.0950   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n                    efficiency\nMazda RX4            3.4064885\nMazda RX4 Wag        3.1043478\nDatsun 710           4.1767241\nHornet 4 Drive       2.8289269\nHornet Sportabout    2.3103198\nValiant              2.2232659\nDuster 360           1.7023810\nMerc 240D            3.2507837\nMerc 230             3.0761905\nMerc 280             2.3720930\nMerc 280C            2.1991279\nMerc 450SE           1.7125307\nMerc 450SL           1.9711796\nMerc 450SLC          1.7089947\nCadillac Fleetwood   0.8419048\nLincoln Continental  0.8148968\nChrysler Imperial    1.1688494\nFiat 128             6.2590909\nHonda Civic          8.0000000\nToyota Corolla       7.8514986\nToyota Corona        3.7068966\nDodge Challenger     1.8714489\nAMC Javelin          1.8806405\nCamaro Z28           1.4720052\nPontiac Firebird     2.1222367\nFiat X1-9            5.9961240\nPorsche 914-2        5.1635514\nLotus Europa         8.5393258\nFord Pantera L       2.1182965\nFerrari Dino         3.0225632\nMaserati Bora        1.7857143\nVolvo 142E           3.2715827\n\n\n\n\n\n\n# Sort by mpg (ascending)\narrange(mtcars, mpg)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n\n# Sort by mpg (descending)\narrange(mtcars, desc(mpg))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n# Sort by multiple columns\narrange(mtcars, cyl, desc(mpg))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n\n\n\n\n\n# Calculate summary statistics\nsummarize(mtcars,\n          avg_mpg = mean(mpg),\n          max_hp = max(hp),\n          count = n())\n\n   avg_mpg max_hp count\n1 20.09062    335    32\n\n\n\n\n\n\n# Group by cylinder and calculate statistics per group\nmtcars %&gt;%\n  group_by(cyl) %&gt;%\n  summarize(\n    count = n(),\n    avg_mpg = mean(mpg),\n    avg_hp = mean(hp),\n    .groups = \"drop\"\n  )\n\n# A tibble: 3 × 4\n    cyl count avg_mpg avg_hp\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     4    11    26.7   82.6\n2     6     7    19.7  122. \n3     8    14    15.1  209. \n\n\n\n\n\n\nThe pipe operator makes code more readable by chaining operations:\n\n# Without pipes\nresult1 &lt;- filter(mtcars, cyl == 4)\nresult2 &lt;- select(result1, mpg, hp, wt)\nresult3 &lt;- arrange(result2, desc(mpg))\nresult3\n\n                mpg  hp    wt\nToyota Corolla 33.9  65 1.835\nFiat 128       32.4  66 2.200\nHonda Civic    30.4  52 1.615\nLotus Europa   30.4 113 1.513\nFiat X1-9      27.3  66 1.935\nPorsche 914-2  26.0  91 2.140\nMerc 240D      24.4  62 3.190\nDatsun 710     22.8  93 2.320\nMerc 230       22.8  95 3.150\nToyota Corona  21.5  97 2.465\nVolvo 142E     21.4 109 2.780\n\n# With pipes - same operations, more readable\nmtcars %&gt;%\n  filter(cyl == 4) %&gt;%\n  select(mpg, hp, wt) %&gt;%\n  arrange(desc(mpg))\n\n                mpg  hp    wt\nToyota Corolla 33.9  65 1.835\nFiat 128       32.4  66 2.200\nHonda Civic    30.4  52 1.615\nLotus Europa   30.4 113 1.513\nFiat X1-9      27.3  66 1.935\nPorsche 914-2  26.0  91 2.140\nMerc 240D      24.4  62 3.190\nDatsun 710     22.8  93 2.320\nMerc 230       22.8  95 3.150\nToyota Corona  21.5  97 2.465\nVolvo 142E     21.4 109 2.780\n\n\n\n\n\n\n\n\n# Get unique values of cyl and gear\nmtcars %&gt;%\n  select(cyl, gear) %&gt;%\n  distinct()\n\n                  cyl gear\nMazda RX4           6    4\nDatsun 710          4    4\nHornet 4 Drive      6    3\nHornet Sportabout   8    3\nToyota Corona       4    3\nPorsche 914-2       4    5\nFord Pantera L      8    5\nFerrari Dino        6    5\n\n\n\n\n\n\n# Count cars by cylinder\nmtcars %&gt;%\n  count(cyl, sort = TRUE)\n\n  cyl  n\n1   8 14\n2   4 11\n3   6  7\n\n# Count by multiple variables\nmtcars %&gt;%\n  count(cyl, gear)\n\n  cyl gear  n\n1   4    3  1\n2   4    4  8\n3   4    5  2\n4   6    3  2\n5   6    4  4\n6   6    5  1\n7   8    3 12\n8   8    5  2\n\n\n\n\n\n\n# Select first 5 rows\nmtcars %&gt;%\n  slice(1:5)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n# Select top 3 rows by mpg\nmtcars %&gt;%\n  arrange(desc(mpg)) %&gt;%\n  slice(1:3)\n\n                mpg cyl disp hp drat    wt  qsec vs am gear carb\nToyota Corolla 33.9   4 71.1 65 4.22 1.835 19.90  1  1    4    1\nFiat 128       32.4   4 78.7 66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4 75.7 52 4.93 1.615 18.52  1  1    4    2\n\n\n\n\n\n\n# Extract mpg column as a vector\nmtcars %&gt;%\n  pull(mpg)\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\n\n\n\n\n\nLet’s solve a more complex problem by combining multiple dplyr functions:\n\n# First add rownames as a column\ncars_with_names &lt;- mtcars %&gt;%\n  tibble::rownames_to_column(\"model\")\n\n# Now perform the analysis\ncars_with_names %&gt;%\n  group_by(cyl) %&gt;%\n  filter(mpg == max(mpg)) %&gt;%\n  select(cyl, model, mpg, hp) %&gt;%\n  arrange(cyl) %&gt;%\n  ungroup()\n\n# A tibble: 3 × 4\n    cyl model              mpg    hp\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n1     4 Toyota Corolla    33.9    65\n2     6 Hornet 4 Drive    21.4   110\n3     8 Pontiac Firebird  19.2   175\n\n\n\n\n\ndplyr provides functions for joining datasets:\n\n# Create sample datasets\nmanufacturers &lt;- data.frame(\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Mercedes\"),\n  country = c(\"Japan\", \"Japan\", \"USA\", \"Germany\", \"Germany\"),\n  stringsAsFactors = FALSE\n)\n\ncars &lt;- data.frame(\n  model = c(\"Civic\", \"Corolla\", \"Focus\", \"3 Series\", \"Fiesta\"),\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Ford\"),\n  stringsAsFactors = FALSE\n)\n\n# Inner join - only matching rows\ninner_join(cars, manufacturers, by = \"make\")\n\n     model   make country\n1    Civic  Honda   Japan\n2  Corolla Toyota   Japan\n3    Focus   Ford     USA\n4 3 Series    BMW Germany\n5   Fiesta   Ford     USA\n\n# Left join - all rows from cars\nleft_join(cars, manufacturers, by = \"make\")\n\n     model   make country\n1    Civic  Honda   Japan\n2  Corolla Toyota   Japan\n3    Focus   Ford     USA\n4 3 Series    BMW Germany\n5   Fiesta   Ford     USA\n\n# Full join - all rows from both\nfull_join(cars, manufacturers, by = \"make\")\n\n     model     make country\n1    Civic    Honda   Japan\n2  Corolla   Toyota   Japan\n3    Focus     Ford     USA\n4 3 Series      BMW Germany\n5   Fiesta     Ford     USA\n6     &lt;NA&gt; Mercedes Germany\n\n\ndplyr makes data manipulation in R more intuitive and efficient. Its consistent syntax and the pipe operator allow you to write code that’s both powerful and readable."
  },
  {
    "objectID": "get-started/dplyr.html#introduction-to-dplyr",
    "href": "get-started/dplyr.html#introduction-to-dplyr",
    "title": "Introduction to dplyr",
    "section": "",
    "text": "The dplyr package is part of the tidyverse and provides a grammar for data manipulation in R. It makes data transformation tasks more intuitive and readable.\n\n\nFirst, let’s install and load the package:\n\n# Install if needed (uncomment to run)\n# install.packages(\"dplyr\")\n# install.packages(\"tibble\")\n\n# Load the packages\nlibrary(dplyr)\nlibrary(tibble)  # For rownames_to_column function\n\n# We'll use the built-in mtcars dataset\ndata(mtcars)\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n\n\ndplyr is built around a set of core verbs (functions) that perform common data manipulation tasks:\n\n\n\n# Select cars with 6 cylinders\nfilter(mtcars, cyl == 6)\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n\n# Multiple conditions: cars with 6 cylinders AND mpg &gt; 20\nfilter(mtcars, cyl == 6, mpg &gt; 20)\n\n                mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n\n# OR conditions\nfilter(mtcars, cyl == 6 | mpg &gt; 30)\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nValiant        18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280       19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C      17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nFiat 128       32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n\n\n\n\n\n\n# Select specific columns\nselect(mtcars, mpg, cyl, hp)\n\n                     mpg cyl  hp\nMazda RX4           21.0   6 110\nMazda RX4 Wag       21.0   6 110\nDatsun 710          22.8   4  93\nHornet 4 Drive      21.4   6 110\nHornet Sportabout   18.7   8 175\nValiant             18.1   6 105\nDuster 360          14.3   8 245\nMerc 240D           24.4   4  62\nMerc 230            22.8   4  95\nMerc 280            19.2   6 123\nMerc 280C           17.8   6 123\nMerc 450SE          16.4   8 180\nMerc 450SL          17.3   8 180\nMerc 450SLC         15.2   8 180\nCadillac Fleetwood  10.4   8 205\nLincoln Continental 10.4   8 215\nChrysler Imperial   14.7   8 230\nFiat 128            32.4   4  66\nHonda Civic         30.4   4  52\nToyota Corolla      33.9   4  65\nToyota Corona       21.5   4  97\nDodge Challenger    15.5   8 150\nAMC Javelin         15.2   8 150\nCamaro Z28          13.3   8 245\nPontiac Firebird    19.2   8 175\nFiat X1-9           27.3   4  66\nPorsche 914-2       26.0   4  91\nLotus Europa        30.4   4 113\nFord Pantera L      15.8   8 264\nFerrari Dino        19.7   6 175\nMaserati Bora       15.0   8 335\nVolvo 142E          21.4   4 109\n\n# Select a range of columns\nselect(mtcars, mpg:hp)\n\n                     mpg cyl  disp  hp\nMazda RX4           21.0   6 160.0 110\nMazda RX4 Wag       21.0   6 160.0 110\nDatsun 710          22.8   4 108.0  93\nHornet 4 Drive      21.4   6 258.0 110\nHornet Sportabout   18.7   8 360.0 175\nValiant             18.1   6 225.0 105\nDuster 360          14.3   8 360.0 245\nMerc 240D           24.4   4 146.7  62\nMerc 230            22.8   4 140.8  95\nMerc 280            19.2   6 167.6 123\nMerc 280C           17.8   6 167.6 123\nMerc 450SE          16.4   8 275.8 180\nMerc 450SL          17.3   8 275.8 180\nMerc 450SLC         15.2   8 275.8 180\nCadillac Fleetwood  10.4   8 472.0 205\nLincoln Continental 10.4   8 460.0 215\nChrysler Imperial   14.7   8 440.0 230\nFiat 128            32.4   4  78.7  66\nHonda Civic         30.4   4  75.7  52\nToyota Corolla      33.9   4  71.1  65\nToyota Corona       21.5   4 120.1  97\nDodge Challenger    15.5   8 318.0 150\nAMC Javelin         15.2   8 304.0 150\nCamaro Z28          13.3   8 350.0 245\nPontiac Firebird    19.2   8 400.0 175\nFiat X1-9           27.3   4  79.0  66\nPorsche 914-2       26.0   4 120.3  91\nLotus Europa        30.4   4  95.1 113\nFord Pantera L      15.8   8 351.0 264\nFerrari Dino        19.7   6 145.0 175\nMaserati Bora       15.0   8 301.0 335\nVolvo 142E          21.4   4 121.0 109\n\n# Select all columns except some\nselect(mtcars, -gear, -carb)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1\n\n# Rename columns while selecting\nselect(mtcars, miles_per_gallon = mpg, cylinders = cyl)\n\n                    miles_per_gallon cylinders\nMazda RX4                       21.0         6\nMazda RX4 Wag                   21.0         6\nDatsun 710                      22.8         4\nHornet 4 Drive                  21.4         6\nHornet Sportabout               18.7         8\nValiant                         18.1         6\nDuster 360                      14.3         8\nMerc 240D                       24.4         4\nMerc 230                        22.8         4\nMerc 280                        19.2         6\nMerc 280C                       17.8         6\nMerc 450SE                      16.4         8\nMerc 450SL                      17.3         8\nMerc 450SLC                     15.2         8\nCadillac Fleetwood              10.4         8\nLincoln Continental             10.4         8\nChrysler Imperial               14.7         8\nFiat 128                        32.4         4\nHonda Civic                     30.4         4\nToyota Corolla                  33.9         4\nToyota Corona                   21.5         4\nDodge Challenger                15.5         8\nAMC Javelin                     15.2         8\nCamaro Z28                      13.3         8\nPontiac Firebird                19.2         8\nFiat X1-9                       27.3         4\nPorsche 914-2                   26.0         4\nLotus Europa                    30.4         4\nFord Pantera L                  15.8         8\nFerrari Dino                    19.7         6\nMaserati Bora                   15.0         8\nVolvo 142E                      21.4         4\n\n\n\n\n\n\n# Add a new column\nmutate(mtcars, \n       kpl = mpg * 0.425,  # Convert mpg to km per liter\n       hp_per_cyl = hp / cyl)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb     kpl\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  8.9250\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  8.9250\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1  9.6900\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1  9.0950\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2  7.9475\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1  7.6925\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4  6.0775\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 10.3700\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2  9.6900\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4  8.1600\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4  7.5650\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3  6.9700\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3  7.3525\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3  6.4600\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4  4.4200\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4  4.4200\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4  6.2475\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 13.7700\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 12.9200\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 14.4075\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  9.1375\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2  6.5875\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2  6.4600\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4  5.6525\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2  8.1600\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 11.6025\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 11.0500\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 12.9200\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4  6.7150\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6  8.3725\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8  6.3750\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2  9.0950\n                    hp_per_cyl\nMazda RX4             18.33333\nMazda RX4 Wag         18.33333\nDatsun 710            23.25000\nHornet 4 Drive        18.33333\nHornet Sportabout     21.87500\nValiant               17.50000\nDuster 360            30.62500\nMerc 240D             15.50000\nMerc 230              23.75000\nMerc 280              20.50000\nMerc 280C             20.50000\nMerc 450SE            22.50000\nMerc 450SL            22.50000\nMerc 450SLC           22.50000\nCadillac Fleetwood    25.62500\nLincoln Continental   26.87500\nChrysler Imperial     28.75000\nFiat 128              16.50000\nHonda Civic           13.00000\nToyota Corolla        16.25000\nToyota Corona         24.25000\nDodge Challenger      18.75000\nAMC Javelin           18.75000\nCamaro Z28            30.62500\nPontiac Firebird      21.87500\nFiat X1-9             16.50000\nPorsche 914-2         22.75000\nLotus Europa          28.25000\nFord Pantera L        33.00000\nFerrari Dino          29.16667\nMaserati Bora         41.87500\nVolvo 142E            27.25000\n\n# Modify existing columns and add new ones\nmutate(mtcars,\n       mpg = mpg * 0.425,  # Overwrite mpg with km per liter\n       efficiency = mpg / wt)\n\n                        mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4            8.9250   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag        8.9250   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710           9.6900   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive       9.0950   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout    7.9475   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant              7.6925   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360           6.0775   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           10.3700   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230             9.6900   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280             8.1600   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C            7.5650   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE           6.9700   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL           7.3525   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC          6.4600   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood   4.4200   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental  4.4200   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial    6.2475   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            13.7700   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         12.9200   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      14.4075   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona        9.1375   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger     6.5875   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin          6.4600   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28           5.6525   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird     8.1600   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           11.6025   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       11.0500   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        12.9200   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L       6.7150   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino         8.3725   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora        6.3750   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E           9.0950   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n                    efficiency\nMazda RX4            3.4064885\nMazda RX4 Wag        3.1043478\nDatsun 710           4.1767241\nHornet 4 Drive       2.8289269\nHornet Sportabout    2.3103198\nValiant              2.2232659\nDuster 360           1.7023810\nMerc 240D            3.2507837\nMerc 230             3.0761905\nMerc 280             2.3720930\nMerc 280C            2.1991279\nMerc 450SE           1.7125307\nMerc 450SL           1.9711796\nMerc 450SLC          1.7089947\nCadillac Fleetwood   0.8419048\nLincoln Continental  0.8148968\nChrysler Imperial    1.1688494\nFiat 128             6.2590909\nHonda Civic          8.0000000\nToyota Corolla       7.8514986\nToyota Corona        3.7068966\nDodge Challenger     1.8714489\nAMC Javelin          1.8806405\nCamaro Z28           1.4720052\nPontiac Firebird     2.1222367\nFiat X1-9            5.9961240\nPorsche 914-2        5.1635514\nLotus Europa         8.5393258\nFord Pantera L       2.1182965\nFerrari Dino         3.0225632\nMaserati Bora        1.7857143\nVolvo 142E           3.2715827\n\n\n\n\n\n\n# Sort by mpg (ascending)\narrange(mtcars, mpg)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n\n# Sort by mpg (descending)\narrange(mtcars, desc(mpg))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n# Sort by multiple columns\narrange(mtcars, cyl, desc(mpg))\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n\n\n\n\n\n\n# Calculate summary statistics\nsummarize(mtcars,\n          avg_mpg = mean(mpg),\n          max_hp = max(hp),\n          count = n())\n\n   avg_mpg max_hp count\n1 20.09062    335    32\n\n\n\n\n\n\n# Group by cylinder and calculate statistics per group\nmtcars %&gt;%\n  group_by(cyl) %&gt;%\n  summarize(\n    count = n(),\n    avg_mpg = mean(mpg),\n    avg_hp = mean(hp),\n    .groups = \"drop\"\n  )\n\n# A tibble: 3 × 4\n    cyl count avg_mpg avg_hp\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1     4    11    26.7   82.6\n2     6     7    19.7  122. \n3     8    14    15.1  209. \n\n\n\n\n\n\nThe pipe operator makes code more readable by chaining operations:\n\n# Without pipes\nresult1 &lt;- filter(mtcars, cyl == 4)\nresult2 &lt;- select(result1, mpg, hp, wt)\nresult3 &lt;- arrange(result2, desc(mpg))\nresult3\n\n                mpg  hp    wt\nToyota Corolla 33.9  65 1.835\nFiat 128       32.4  66 2.200\nHonda Civic    30.4  52 1.615\nLotus Europa   30.4 113 1.513\nFiat X1-9      27.3  66 1.935\nPorsche 914-2  26.0  91 2.140\nMerc 240D      24.4  62 3.190\nDatsun 710     22.8  93 2.320\nMerc 230       22.8  95 3.150\nToyota Corona  21.5  97 2.465\nVolvo 142E     21.4 109 2.780\n\n# With pipes - same operations, more readable\nmtcars %&gt;%\n  filter(cyl == 4) %&gt;%\n  select(mpg, hp, wt) %&gt;%\n  arrange(desc(mpg))\n\n                mpg  hp    wt\nToyota Corolla 33.9  65 1.835\nFiat 128       32.4  66 2.200\nHonda Civic    30.4  52 1.615\nLotus Europa   30.4 113 1.513\nFiat X1-9      27.3  66 1.935\nPorsche 914-2  26.0  91 2.140\nMerc 240D      24.4  62 3.190\nDatsun 710     22.8  93 2.320\nMerc 230       22.8  95 3.150\nToyota Corona  21.5  97 2.465\nVolvo 142E     21.4 109 2.780\n\n\n\n\n\n\n\n\n# Get unique values of cyl and gear\nmtcars %&gt;%\n  select(cyl, gear) %&gt;%\n  distinct()\n\n                  cyl gear\nMazda RX4           6    4\nDatsun 710          4    4\nHornet 4 Drive      6    3\nHornet Sportabout   8    3\nToyota Corona       4    3\nPorsche 914-2       4    5\nFord Pantera L      8    5\nFerrari Dino        6    5\n\n\n\n\n\n\n# Count cars by cylinder\nmtcars %&gt;%\n  count(cyl, sort = TRUE)\n\n  cyl  n\n1   8 14\n2   4 11\n3   6  7\n\n# Count by multiple variables\nmtcars %&gt;%\n  count(cyl, gear)\n\n  cyl gear  n\n1   4    3  1\n2   4    4  8\n3   4    5  2\n4   6    3  2\n5   6    4  4\n6   6    5  1\n7   8    3 12\n8   8    5  2\n\n\n\n\n\n\n# Select first 5 rows\nmtcars %&gt;%\n  slice(1:5)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n# Select top 3 rows by mpg\nmtcars %&gt;%\n  arrange(desc(mpg)) %&gt;%\n  slice(1:3)\n\n                mpg cyl disp hp drat    wt  qsec vs am gear carb\nToyota Corolla 33.9   4 71.1 65 4.22 1.835 19.90  1  1    4    1\nFiat 128       32.4   4 78.7 66 4.08 2.200 19.47  1  1    4    1\nHonda Civic    30.4   4 75.7 52 4.93 1.615 18.52  1  1    4    2\n\n\n\n\n\n\n# Extract mpg column as a vector\nmtcars %&gt;%\n  pull(mpg)\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\n\n\n\n\n\nLet’s solve a more complex problem by combining multiple dplyr functions:\n\n# First add rownames as a column\ncars_with_names &lt;- mtcars %&gt;%\n  tibble::rownames_to_column(\"model\")\n\n# Now perform the analysis\ncars_with_names %&gt;%\n  group_by(cyl) %&gt;%\n  filter(mpg == max(mpg)) %&gt;%\n  select(cyl, model, mpg, hp) %&gt;%\n  arrange(cyl) %&gt;%\n  ungroup()\n\n# A tibble: 3 × 4\n    cyl model              mpg    hp\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n1     4 Toyota Corolla    33.9    65\n2     6 Hornet 4 Drive    21.4   110\n3     8 Pontiac Firebird  19.2   175\n\n\n\n\n\ndplyr provides functions for joining datasets:\n\n# Create sample datasets\nmanufacturers &lt;- data.frame(\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Mercedes\"),\n  country = c(\"Japan\", \"Japan\", \"USA\", \"Germany\", \"Germany\"),\n  stringsAsFactors = FALSE\n)\n\ncars &lt;- data.frame(\n  model = c(\"Civic\", \"Corolla\", \"Focus\", \"3 Series\", \"Fiesta\"),\n  make = c(\"Honda\", \"Toyota\", \"Ford\", \"BMW\", \"Ford\"),\n  stringsAsFactors = FALSE\n)\n\n# Inner join - only matching rows\ninner_join(cars, manufacturers, by = \"make\")\n\n     model   make country\n1    Civic  Honda   Japan\n2  Corolla Toyota   Japan\n3    Focus   Ford     USA\n4 3 Series    BMW Germany\n5   Fiesta   Ford     USA\n\n# Left join - all rows from cars\nleft_join(cars, manufacturers, by = \"make\")\n\n     model   make country\n1    Civic  Honda   Japan\n2  Corolla Toyota   Japan\n3    Focus   Ford     USA\n4 3 Series    BMW Germany\n5   Fiesta   Ford     USA\n\n# Full join - all rows from both\nfull_join(cars, manufacturers, by = \"make\")\n\n     model     make country\n1    Civic    Honda   Japan\n2  Corolla   Toyota   Japan\n3    Focus     Ford     USA\n4 3 Series      BMW Germany\n5   Fiesta     Ford     USA\n6     &lt;NA&gt; Mercedes Germany\n\n\ndplyr makes data manipulation in R more intuitive and efficient. Its consistent syntax and the pipe operator allow you to write code that’s both powerful and readable."
  },
  {
    "objectID": "get-started/indexing.html",
    "href": "get-started/indexing.html",
    "title": "Indexing Arrays in R",
    "section": "",
    "text": "R provides powerful and flexible ways to access and manipulate elements in data structures like vectors, matrices, and arrays.\n\n\nVectors are one-dimensional arrays and the most basic data structure in R:\n\n# Create a vector\nx &lt;- c(10, 20, 30, 40, 50)\n\n# Access by position (indexing starts at 1, not 0)\nx[1]        # First element\n\n[1] 10\n\nx[3]        # Third element\n\n[1] 30\n\nx[length(x)] # Last element\n\n[1] 50\n\n# Access multiple elements\nx[c(1, 3, 5)]  # First, third, and fifth elements\n\n[1] 10 30 50\n\nx[1:3]         # First three elements\n\n[1] 10 20 30\n\n# Negative indices exclude elements\nx[-2]          # All elements except the second\n\n[1] 10 30 40 50\n\nx[-(3:5)]      # All elements except third through fifth\n\n[1] 10 20\n\n\n\n\n\nYou can use logical vectors to filter elements:\n\n# Create a vector\nages &lt;- c(25, 18, 45, 32, 16, 50)\n\n# Filter using logical conditions\nages[ages &gt; 30]         # Elements greater than 30\n\n[1] 45 32 50\n\nages[ages &gt;= 18 & ages &lt;= 40]  # Elements between 18 and 40\n\n[1] 25 18 32\n\n# Named logical operations\nadults &lt;- ages &gt;= 18\nages[adults]            # Only adult ages\n\n[1] 25 18 45 32 50\n\n\n\n\n\nMatrices are two-dimensional arrays:\n\n# Create a matrix\nmat &lt;- matrix(1:12, nrow = 3, ncol = 4)\nprint(mat)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n# Access by row and column indices\nmat[1, 2]      # Element at first row, second column\n\n[1] 4\n\nmat[2, ]       # Entire second row\n\n[1]  2  5  8 11\n\nmat[, 3]       # Entire third column\n\n[1] 7 8 9\n\nmat[1:2, 3:4]  # Submatrix (rows 1-2, columns 3-4)\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n\n# Logical indexing in matrices\nmat[mat &gt; 6]   # All elements greater than 6\n\n[1]  7  8  9 10 11 12\n\n\n\n\n\nArrays can have more than two dimensions:\n\n# Create a 3D array (2x3x2)\narr &lt;- array(1:12, dim = c(2, 3, 2))\nprint(arr)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n# Access elements\narr[1, 2, 1]   # Element at position [1,2,1]\n\n[1] 3\n\narr[, , 1]     # First \"layer\" of the array\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\narr[1, , ]     # All elements in first row across all layers\n\n     [,1] [,2]\n[1,]    1    7\n[2,]    3    9\n[3,]    5   11\n\n\n\n\n\nData frames combine features of matrices and lists:\n\n# Create a data frame\ndf &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 40),\n  score = c(88, 92, 79, 94)\n)\nprint(df)\n\n     name age score\n1   Alice  25    88\n2     Bob  30    92\n3 Charlie  35    79\n4   David  40    94\n\n# Access by row and column indices (like matrices)\ndf[1, 2]       # First row, second column\n\n[1] 25\n\ndf[2:3, ]      # Second and third rows\n\n     name age score\n2     Bob  30    92\n3 Charlie  35    79\n\n# Access by column name\ndf$name        # Name column\n\n[1] \"Alice\"   \"Bob\"     \"Charlie\" \"David\"  \n\ndf[, \"age\"]    # Age column\n\n[1] 25 30 35 40\n\ndf[[\"score\"]]  # Score column\n\n[1] 88 92 79 94\n\n# Filter rows by condition\ndf[df$age &gt; 30, ]  # Rows where age is greater than 30\n\n     name age score\n3 Charlie  35    79\n4   David  40    94\n\n\n\n\n\nLists can contain elements of different types:\n\n# Create a list\nmy_list &lt;- list(\n  name = \"John\",\n  numbers = c(1, 2, 3),\n  matrix = matrix(1:4, nrow = 2)\n)\nprint(my_list)\n\n$name\n[1] \"John\"\n\n$numbers\n[1] 1 2 3\n\n$matrix\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n# Access list elements\nmy_list[[1]]       # First element (by position)\n\n[1] \"John\"\n\nmy_list[[\"name\"]]  # Element by name\n\n[1] \"John\"\n\nmy_list$numbers    # Element by name using $ notation\n\n[1] 1 2 3\n\n# Access nested elements\nmy_list$numbers[2]  # Second element of the numbers vector\n\n[1] 2\n\nmy_list$matrix[1,2] # Element at row 1, column 2 of the matrix\n\n[1] 3\n\n\n\n\n\n\n# Using which() for positional indexing from logical conditions\nx &lt;- c(5, 10, 15, 20, 25)\nwhich(x &gt; 15)  # Returns positions where condition is TRUE\n\n[1] 4 5\n\n# Using %in% for membership tests\nfruits &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\")\nfruits %in% c(\"banana\", \"date\", \"fig\")  # Tests which elements are in the second vector\n\n[1] FALSE  TRUE FALSE  TRUE\n\nfruits[fruits %in% c(\"banana\", \"date\", \"fig\")]  # Select matching elements\n\n[1] \"banana\" \"date\"  \n\n\nRemember that R indexing starts at 1, not 0 as in many other programming languages. This is a common source of confusion for beginners coming from languages like Python or JavaScript."
  },
  {
    "objectID": "get-started/indexing.html#indexing-arrays-in-r",
    "href": "get-started/indexing.html#indexing-arrays-in-r",
    "title": "Indexing Arrays in R",
    "section": "",
    "text": "R provides powerful and flexible ways to access and manipulate elements in data structures like vectors, matrices, and arrays.\n\n\nVectors are one-dimensional arrays and the most basic data structure in R:\n\n# Create a vector\nx &lt;- c(10, 20, 30, 40, 50)\n\n# Access by position (indexing starts at 1, not 0)\nx[1]        # First element\n\n[1] 10\n\nx[3]        # Third element\n\n[1] 30\n\nx[length(x)] # Last element\n\n[1] 50\n\n# Access multiple elements\nx[c(1, 3, 5)]  # First, third, and fifth elements\n\n[1] 10 30 50\n\nx[1:3]         # First three elements\n\n[1] 10 20 30\n\n# Negative indices exclude elements\nx[-2]          # All elements except the second\n\n[1] 10 30 40 50\n\nx[-(3:5)]      # All elements except third through fifth\n\n[1] 10 20\n\n\n\n\n\nYou can use logical vectors to filter elements:\n\n# Create a vector\nages &lt;- c(25, 18, 45, 32, 16, 50)\n\n# Filter using logical conditions\nages[ages &gt; 30]         # Elements greater than 30\n\n[1] 45 32 50\n\nages[ages &gt;= 18 & ages &lt;= 40]  # Elements between 18 and 40\n\n[1] 25 18 32\n\n# Named logical operations\nadults &lt;- ages &gt;= 18\nages[adults]            # Only adult ages\n\n[1] 25 18 45 32 50\n\n\n\n\n\nMatrices are two-dimensional arrays:\n\n# Create a matrix\nmat &lt;- matrix(1:12, nrow = 3, ncol = 4)\nprint(mat)\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n# Access by row and column indices\nmat[1, 2]      # Element at first row, second column\n\n[1] 4\n\nmat[2, ]       # Entire second row\n\n[1]  2  5  8 11\n\nmat[, 3]       # Entire third column\n\n[1] 7 8 9\n\nmat[1:2, 3:4]  # Submatrix (rows 1-2, columns 3-4)\n\n     [,1] [,2]\n[1,]    7   10\n[2,]    8   11\n\n# Logical indexing in matrices\nmat[mat &gt; 6]   # All elements greater than 6\n\n[1]  7  8  9 10 11 12\n\n\n\n\n\nArrays can have more than two dimensions:\n\n# Create a 3D array (2x3x2)\narr &lt;- array(1:12, dim = c(2, 3, 2))\nprint(arr)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n# Access elements\narr[1, 2, 1]   # Element at position [1,2,1]\n\n[1] 3\n\narr[, , 1]     # First \"layer\" of the array\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\narr[1, , ]     # All elements in first row across all layers\n\n     [,1] [,2]\n[1,]    1    7\n[2,]    3    9\n[3,]    5   11\n\n\n\n\n\nData frames combine features of matrices and lists:\n\n# Create a data frame\ndf &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\"),\n  age = c(25, 30, 35, 40),\n  score = c(88, 92, 79, 94)\n)\nprint(df)\n\n     name age score\n1   Alice  25    88\n2     Bob  30    92\n3 Charlie  35    79\n4   David  40    94\n\n# Access by row and column indices (like matrices)\ndf[1, 2]       # First row, second column\n\n[1] 25\n\ndf[2:3, ]      # Second and third rows\n\n     name age score\n2     Bob  30    92\n3 Charlie  35    79\n\n# Access by column name\ndf$name        # Name column\n\n[1] \"Alice\"   \"Bob\"     \"Charlie\" \"David\"  \n\ndf[, \"age\"]    # Age column\n\n[1] 25 30 35 40\n\ndf[[\"score\"]]  # Score column\n\n[1] 88 92 79 94\n\n# Filter rows by condition\ndf[df$age &gt; 30, ]  # Rows where age is greater than 30\n\n     name age score\n3 Charlie  35    79\n4   David  40    94\n\n\n\n\n\nLists can contain elements of different types:\n\n# Create a list\nmy_list &lt;- list(\n  name = \"John\",\n  numbers = c(1, 2, 3),\n  matrix = matrix(1:4, nrow = 2)\n)\nprint(my_list)\n\n$name\n[1] \"John\"\n\n$numbers\n[1] 1 2 3\n\n$matrix\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n# Access list elements\nmy_list[[1]]       # First element (by position)\n\n[1] \"John\"\n\nmy_list[[\"name\"]]  # Element by name\n\n[1] \"John\"\n\nmy_list$numbers    # Element by name using $ notation\n\n[1] 1 2 3\n\n# Access nested elements\nmy_list$numbers[2]  # Second element of the numbers vector\n\n[1] 2\n\nmy_list$matrix[1,2] # Element at row 1, column 2 of the matrix\n\n[1] 3\n\n\n\n\n\n\n# Using which() for positional indexing from logical conditions\nx &lt;- c(5, 10, 15, 20, 25)\nwhich(x &gt; 15)  # Returns positions where condition is TRUE\n\n[1] 4 5\n\n# Using %in% for membership tests\nfruits &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\")\nfruits %in% c(\"banana\", \"date\", \"fig\")  # Tests which elements are in the second vector\n\n[1] FALSE  TRUE FALSE  TRUE\n\nfruits[fruits %in% c(\"banana\", \"date\", \"fig\")]  # Select matching elements\n\n[1] \"banana\" \"date\"  \n\n\nRemember that R indexing starts at 1, not 0 as in many other programming languages. This is a common source of confusion for beginners coming from languages like Python or JavaScript."
  },
  {
    "objectID": "get-started/r-package-management.html",
    "href": "get-started/r-package-management.html",
    "title": "Installing and Managing R Packages",
    "section": "",
    "text": "R’s true power comes from its vast ecosystem of packages. This guide will show you how to effectively install, update, and manage packages for your data analysis projects."
  },
  {
    "objectID": "get-started/r-package-management.html#installing-packages",
    "href": "get-started/r-package-management.html#installing-packages",
    "title": "Installing and Managing R Packages",
    "section": "Installing Packages",
    "text": "Installing Packages\nR packages can be installed from CRAN (the Comprehensive R Archive Network) using the install.packages() function:\n\n# Install a single package\ninstall.packages(\"dplyr\")\n\n# Install multiple packages at once\ninstall.packages(c(\"ggplot2\", \"tidyr\", \"readr\"))\n\nSome packages may require you to select a CRAN mirror for downloading. Simply choose a location near you from the list that appears."
  },
  {
    "objectID": "get-started/r-package-management.html#loading-packages",
    "href": "get-started/r-package-management.html#loading-packages",
    "title": "Installing and Managing R Packages",
    "section": "Loading Packages",
    "text": "Loading Packages\nOnce installed, you need to load packages in each R session before using them:\n\n# Load a package\nlibrary(ggplot2)\n\n# You can now use functions from the package\nggplot(mtcars, aes(x = wt, y = mpg)) + \n  geom_point() + \n  theme_minimal()"
  },
  {
    "objectID": "get-started/r-package-management.html#checking-installed-packages",
    "href": "get-started/r-package-management.html#checking-installed-packages",
    "title": "Installing and Managing R Packages",
    "section": "Checking Installed Packages",
    "text": "Checking Installed Packages\nTo see what packages are installed on your system:\n\n# List all installed packages\ninstalled.packages()[, c(\"Package\", \"Version\")]\n\n# Check if a specific package is installed\n\"dplyr\" %in% rownames(installed.packages())"
  },
  {
    "objectID": "get-started/r-package-management.html#updating-packages",
    "href": "get-started/r-package-management.html#updating-packages",
    "title": "Installing and Managing R Packages",
    "section": "Updating Packages",
    "text": "Updating Packages\nKeeping packages up-to-date ensures you have the latest features and bug fixes:\n\n# Update all packages\nupdate.packages()\n\n# Update without asking for confirmation\nupdate.packages(ask = FALSE)"
  },
  {
    "objectID": "get-started/r-package-management.html#installing-from-github",
    "href": "get-started/r-package-management.html#installing-from-github",
    "title": "Installing and Managing R Packages",
    "section": "Installing from GitHub",
    "text": "Installing from GitHub\nMany cutting-edge packages are available on GitHub before they reach CRAN:\n\n# First, install the devtools package if you haven't already\ninstall.packages(\"devtools\")\n\n# Then use it to install packages from GitHub\nlibrary(devtools)\ninstall_github(\"tidyverse/ggplot2\")"
  },
  {
    "objectID": "get-started/r-package-management.html#package-dependencies",
    "href": "get-started/r-package-management.html#package-dependencies",
    "title": "Installing and Managing R Packages",
    "section": "Package Dependencies",
    "text": "Package Dependencies\nR automatically handles dependencies (other packages required by your target package). However, sometimes you may encounter issues with dependencies that require manual intervention:\n\n# Force reinstallation of a package and its dependencies\ninstall.packages(\"problematic_package\", dependencies = TRUE)"
  },
  {
    "objectID": "get-started/r-package-management.html#creating-a-reproducible-environment",
    "href": "get-started/r-package-management.html#creating-a-reproducible-environment",
    "title": "Installing and Managing R Packages",
    "section": "Creating a Reproducible Environment",
    "text": "Creating a Reproducible Environment\nFor collaborative or production work, it’s important to track package versions:\n\n# Record packages and versions with renv\ninstall.packages(\"renv\")\nlibrary(renv)\nrenv::init()      # Initialize a project environment\nrenv::snapshot()  # Save the current state of packages\n\nThe renv package creates isolated, reproducible environments similar to Python’s virtual environments."
  },
  {
    "objectID": "get-started/r-package-management.html#managing-package-conflicts",
    "href": "get-started/r-package-management.html#managing-package-conflicts",
    "title": "Installing and Managing R Packages",
    "section": "Managing Package Conflicts",
    "text": "Managing Package Conflicts\nSometimes packages have functions with the same name, causing conflicts:\n\n# Specify the package explicitly\ndplyr::filter(df, x &gt; 10)  # Use filter from dplyr\nstats::filter(x, rep(1/3, 3))  # Use filter from stats"
  },
  {
    "objectID": "get-started/r-package-management.html#pro-tip-package-installation-script",
    "href": "get-started/r-package-management.html#pro-tip-package-installation-script",
    "title": "Installing and Managing R Packages",
    "section": "Pro Tip: Package Installation Script",
    "text": "Pro Tip: Package Installation Script\nFor projects requiring multiple packages, create an installation script:\n\n# Create a function to check and install packages\ninstall_if_missing &lt;- function(pkg) {\n  if (!require(pkg, character.only = TRUE)) {\n    install.packages(pkg)\n    library(pkg, character.only = TRUE)\n  }\n}\n\n# List all required packages\npackages &lt;- c(\"tidyverse\", \"data.table\", \"caret\", \"lubridate\", \"janitor\")\n\n# Install all packages\ninvisible(sapply(packages, install_if_missing))\n\nThis script installs packages only if they’re not already available, saving time when setting up on a new machine or sharing code with collaborators."
  },
  {
    "objectID": "get-started/variables.html",
    "href": "get-started/variables.html",
    "title": "Variables in R",
    "section": "",
    "text": "Variables in R are used to store data that can be referenced and manipulated throughout your code. Here’s how to create and work with variables:\n\n\n\n# Using the assignment operator (&lt;-)\nx &lt;- 10\ny &lt;- \"Hello, R!\"\nz &lt;- TRUE\n\n# Print the variables\nx\n\n[1] 10\n\ny\n\n[1] \"Hello, R!\"\n\nz\n\n[1] TRUE\n\n\n\n\n\n\n# Using the equals sign (=)\nage = 25\n\n# Using the assignment operator in reverse (-&gt;)\n\"Data Scientist\" -&gt; job_title\n\n# Print the variables\nage\n\n[1] 25\n\njob_title\n\n[1] \"Data Scientist\"\n\n\n\n\n\n\nNames can contain letters, numbers, dots (.) and underscores (_)\nNames must start with a letter or a dot\nIf a name starts with a dot, it cannot be followed by a number\nNames are case-sensitive (Value and value are different variables)\n\n\n# Valid variable names\nvalid_name &lt;- 1\nvalidName &lt;- 2\nvalid.name &lt;- 3\n.hidden &lt;- 4\n\n# Print variables\nvalid_name\n\n[1] 1\n\nvalidName\n\n[1] 2\n\nvalid.name\n\n[1] 3\n\n.hidden\n\n[1] 4\n\n\n\n\n\nR has several basic data types:\n\n# Numeric\nnum &lt;- 42.5\ntypeof(num)\n\n[1] \"double\"\n\n# Integer (note the L suffix)\nint &lt;- 42L\ntypeof(int)\n\n[1] \"integer\"\n\n# Character\ntext &lt;- \"R programming\"\ntypeof(text)\n\n[1] \"character\"\n\n# Logical\nflag &lt;- TRUE\ntypeof(flag)\n\n[1] \"logical\"\n\n\n\n\n\n\n# Check if a variable is of a specific type\nis.numeric(num)\n\n[1] TRUE\n\nis.character(text)\n\n[1] TRUE\n\n# Convert between types\nas.character(num)\n\n[1] \"42.5\"\n\nas.numeric(\"100\")\n\n[1] 100\n\nas.logical(1)\n\n[1] TRUE\n\n\n\n\n\n\n# Get information about a variable\nx &lt;- c(1, 2, 3, 4, 5)\nclass(x)\n\n[1] \"numeric\"\n\nlength(x)\n\n[1] 5\n\nstr(x)\n\n num [1:5] 1 2 3 4 5\n\n\nRemember that R is dynamically typed, so variables can change types during execution. This flexibility is one of R’s strengths for data analysis."
  },
  {
    "objectID": "get-started/variables.html#creating-variables-in-r",
    "href": "get-started/variables.html#creating-variables-in-r",
    "title": "Variables in R",
    "section": "",
    "text": "Variables in R are used to store data that can be referenced and manipulated throughout your code. Here’s how to create and work with variables:\n\n\n\n# Using the assignment operator (&lt;-)\nx &lt;- 10\ny &lt;- \"Hello, R!\"\nz &lt;- TRUE\n\n# Print the variables\nx\n\n[1] 10\n\ny\n\n[1] \"Hello, R!\"\n\nz\n\n[1] TRUE\n\n\n\n\n\n\n# Using the equals sign (=)\nage = 25\n\n# Using the assignment operator in reverse (-&gt;)\n\"Data Scientist\" -&gt; job_title\n\n# Print the variables\nage\n\n[1] 25\n\njob_title\n\n[1] \"Data Scientist\"\n\n\n\n\n\n\nNames can contain letters, numbers, dots (.) and underscores (_)\nNames must start with a letter or a dot\nIf a name starts with a dot, it cannot be followed by a number\nNames are case-sensitive (Value and value are different variables)\n\n\n# Valid variable names\nvalid_name &lt;- 1\nvalidName &lt;- 2\nvalid.name &lt;- 3\n.hidden &lt;- 4\n\n# Print variables\nvalid_name\n\n[1] 1\n\nvalidName\n\n[1] 2\n\nvalid.name\n\n[1] 3\n\n.hidden\n\n[1] 4\n\n\n\n\n\nR has several basic data types:\n\n# Numeric\nnum &lt;- 42.5\ntypeof(num)\n\n[1] \"double\"\n\n# Integer (note the L suffix)\nint &lt;- 42L\ntypeof(int)\n\n[1] \"integer\"\n\n# Character\ntext &lt;- \"R programming\"\ntypeof(text)\n\n[1] \"character\"\n\n# Logical\nflag &lt;- TRUE\ntypeof(flag)\n\n[1] \"logical\"\n\n\n\n\n\n\n# Check if a variable is of a specific type\nis.numeric(num)\n\n[1] TRUE\n\nis.character(text)\n\n[1] TRUE\n\n# Convert between types\nas.character(num)\n\n[1] \"42.5\"\n\nas.numeric(\"100\")\n\n[1] 100\n\nas.logical(1)\n\n[1] TRUE\n\n\n\n\n\n\n# Get information about a variable\nx &lt;- c(1, 2, 3, 4, 5)\nclass(x)\n\n[1] \"numeric\"\n\nlength(x)\n\n[1] 5\n\nstr(x)\n\n num [1:5] 1 2 3 4 5\n\n\nRemember that R is dynamically typed, so variables can change types during execution. This flexibility is one of R’s strengths for data analysis."
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "This guide will walk you through the process of installing R and RStudio on your computer. These are the essential tools you’ll need to start your journey with R programming.\n\n\nR is a free, open-source programming language and software environment designed for statistical computing and graphics. It’s widely used among statisticians, data scientists, and researchers for data analysis and visualization.\n\n\n\nRStudio is an integrated development environment (IDE) for R. It makes working with R much easier by providing a user-friendly interface with features like syntax highlighting, code completion, and visualization tools."
  },
  {
    "objectID": "installation.html#getting-started-with-r",
    "href": "installation.html#getting-started-with-r",
    "title": "Installing R and RStudio",
    "section": "",
    "text": "This guide will walk you through the process of installing R and RStudio on your computer. These are the essential tools you’ll need to start your journey with R programming.\n\n\nR is a free, open-source programming language and software environment designed for statistical computing and graphics. It’s widely used among statisticians, data scientists, and researchers for data analysis and visualization.\n\n\n\nRStudio is an integrated development environment (IDE) for R. It makes working with R much easier by providing a user-friendly interface with features like syntax highlighting, code completion, and visualization tools."
  },
  {
    "objectID": "installation.html#installation-guide",
    "href": "installation.html#installation-guide",
    "title": "Installing R and RStudio",
    "section": "Installation Guide",
    "text": "Installation Guide\n\nInstalling R\n\nWindows\n\nGo to the CRAN (Comprehensive R Archive Network) website\nClick on “Download R for Windows”\nClick on “base”\nClick on the download link for the latest version (e.g., “Download R-4.x.x for Windows”)\nRun the downloaded installer and follow the installation prompts\n\nAccept the default settings unless you have specific preferences\nNote the installation location in case you need it later\n\n\n\n\nmacOS\n\nGo to the CRAN website\nClick on “Download R for macOS”\nDownload the latest .pkg file for your macOS version\nOpen the downloaded file and follow the installation instructions\n\n\n\nLinux (Ubuntu/Debian)\n\nOpen a terminal window\nUpdate your system’s package index:\nsudo apt update\nInstall R:\nsudo apt install r-base\n\n\n\n\nInstalling RStudio\nAfter installing R, you should install RStudio:\n\nGo to the RStudio download page\nScroll down to find the installer for your operating system\nDownload the appropriate installer\nRun the installer and follow the installation prompts"
  },
  {
    "objectID": "installation.html#verifying-your-installation",
    "href": "installation.html#verifying-your-installation",
    "title": "Installing R and RStudio",
    "section": "Verifying Your Installation",
    "text": "Verifying Your Installation\nTo verify that R and RStudio are installed correctly:\n\nOpen RStudio\nIn the Console pane (usually at the bottom left), type:\nR.version\nPress Enter. You should see information about your R installation."
  },
  {
    "objectID": "installation.html#installing-r-packages",
    "href": "installation.html#installing-r-packages",
    "title": "Installing R and RStudio",
    "section": "Installing R Packages",
    "text": "Installing R Packages\nR’s functionality can be extended with packages. Here’s how to install a package:\n\nIn RStudio, go to the Console\nType the following command to install a package (replace “packagename” with the actual package name):\ninstall.packages(\"packagename\")\nFor example, to install the tidyverse collection of packages:\ninstall.packages(\"tidyverse\")\n\n\nEssential Packages for Beginners\nConsider installing these useful packages to get started:\n# Run these commands in the RStudio console\ninstall.packages(\"tidyverse\")  # Data manipulation and visualization\ninstall.packages(\"rmarkdown\")  # For creating dynamic documents\ninstall.packages(\"knitr\")      # For report generation\ninstall.packages(\"shiny\")      # For interactive web applications"
  },
  {
    "objectID": "installation.html#troubleshooting",
    "href": "installation.html#troubleshooting",
    "title": "Installing R and RStudio",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nCommon Issues on Windows\n\nPermission errors: Run RStudio as administrator\nPath too long errors: Install R in a directory with a shorter path\n\n\n\nCommon Issues on macOS\n\nPackage installation failures: Make sure you have the necessary development tools installed:\nxcode-select --install\n\n\n\nCommon Issues on Linux\n\nMissing dependencies: Install common R dependencies:\nsudo apt install libcurl4-openssl-dev libssl-dev libxml2-dev"
  },
  {
    "objectID": "installation.html#next-steps",
    "href": "installation.html#next-steps",
    "title": "Installing R and RStudio",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you have R and RStudio installed, you’re ready to start your R programming journey! Check out our Introduction to Analytics with R post to begin learning."
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html",
    "href": "posts/bayesian-optimization-xgboost.html",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "",
    "text": "Tuning machine learning models can be time-consuming and computationally expensive. This post shows how to use Bayesian optimization to efficiently find optimal XGBoost hyperparameters – saving time and improving model performance."
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html#required-packages",
    "href": "posts/bayesian-optimization-xgboost.html#required-packages",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "Required Packages",
    "text": "Required Packages\n\n# Load required packages\nlibrary(xgboost)\nlibrary(ParBayesianOptimization)\nlibrary(mlbench)\nlibrary(dplyr)\nlibrary(recipes)\nlibrary(rsample)"
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html#data-preparation",
    "href": "posts/bayesian-optimization-xgboost.html#data-preparation",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "Data Preparation",
    "text": "Data Preparation\nWe’ll use the Boston Housing dataset – a classic regression problem with both numeric and categorical variables.\n\n# Load the Boston Housing dataset\ndata(\"BostonHousing2\")\n\n# Quick look at the data structure\nstr(BostonHousing2)\n\n'data.frame':   506 obs. of  19 variables:\n $ town   : Factor w/ 92 levels \"Arlington\",\"Ashland\",..: 54 77 77 46 46 46 69 69 69 69 ...\n $ tract  : int  2011 2021 2022 2031 2032 2033 2041 2042 2043 2044 ...\n $ lon    : num  -71 -71 -70.9 -70.9 -70.9 ...\n $ lat    : num  42.3 42.3 42.3 42.3 42.3 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...\n $ cmedv  : num  24 21.6 34.7 33.4 36.2 28.7 22.9 22.1 16.5 18.9 ...\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : int  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ b      : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n\n\nXGBoost requires numeric inputs, so we’ll use the recipes package to transform our categorical variables:\n\n# Create a recipe for preprocessing\nrec &lt;- recipe(cmedv ~ ., data = BostonHousing2) %&gt;%\n  # Collapse categories where population is &lt; 3%\n  step_other(town, chas, threshold = .03, other = \"Other\") %&gt;% \n  # Create dummy variables for all factor variables \n  step_dummy(all_nominal_predictors())\n\n# Train the recipe on the dataset\nprep &lt;- prep(rec, training = BostonHousing2)\n\n# Create the final model matrix\nmodel_df &lt;- bake(prep, new_data = BostonHousing2)\n\n# Check the column names after one-hot encoding\ncolnames(model_df)\n\n [1] \"tract\"                  \"lon\"                    \"lat\"                   \n [4] \"medv\"                   \"crim\"                   \"zn\"                    \n [7] \"indus\"                  \"nox\"                    \"rm\"                    \n[10] \"age\"                    \"dis\"                    \"rad\"                   \n[13] \"tax\"                    \"ptratio\"                \"b\"                     \n[16] \"lstat\"                  \"cmedv\"                  \"town_Boston.Savin.Hill\"\n[19] \"town_Cambridge\"         \"town_Lynn\"              \"town_Newton\"           \n[22] \"town_Other\"             \"chas_X1\"               \n\n\nNext, we’ll split our data into training and testing sets:\n\n# Create a 70/30 train-test split\nsplits &lt;- rsample::initial_split(model_df, prop = 0.7)\ntrain_df &lt;- rsample::training(splits)\ntest_df &lt;- rsample::testing(splits)\n\n# Prepare the training data for XGBoost\nX &lt;- train_df %&gt;%\n  select(!medv, !cmedv) %&gt;%\n  as.matrix()\n\n# Get the target variable\ny &lt;- train_df %&gt;% pull(cmedv)\n\n# Create cross-validation folds\nfolds &lt;- list(\n  fold1 = as.integer(seq(1, nrow(X), by = 5)),\n  fold2 = as.integer(seq(2, nrow(X), by = 5))\n)"
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html#setting-up-bayesian-optimization",
    "href": "posts/bayesian-optimization-xgboost.html#setting-up-bayesian-optimization",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "Setting Up Bayesian Optimization",
    "text": "Setting Up Bayesian Optimization\nBayesian optimization requires two key components:\n\nAn objective function that evaluates model performance\nThe parameter bounds we want to explore\n\n\n# Our objective function takes hyperparameters as inputs\nobj_func &lt;- function(eta, max_depth, min_child_weight, subsample, lambda, alpha) {\n  \n  param &lt;- list(\n    # Learning parameters\n    eta = eta,                       # Learning rate\n    max_depth = max_depth,           # Tree depth\n    min_child_weight = min_child_weight, # Min observations per node\n    subsample = subsample,           # Data subsampling\n    lambda = lambda,                 # L2 regularization\n    alpha = alpha,                   # L1 regularization\n    \n    booster = \"gbtree\",             # Use tree model\n    objective = \"reg:squarederror\",  # Regression task\n    eval_metric = \"mape\"            # Mean Absolute Percentage Error\n  )\n  \n  xgbcv &lt;- xgb.cv(params = param,\n                  data = X,\n                  label = y,\n                  nround = 50,\n                  folds = folds,\n                  prediction = TRUE,\n                  early_stopping_rounds = 5,\n                  verbose = 0,\n                  maximize = FALSE)\n  \n  lst &lt;- list(\n    # First argument must be named as \"Score\"\n    # Function finds maxima so inverting the output\n    Score = -min(xgbcv$evaluation_log$test_mape_mean),\n    \n    # Get number of trees for the best performing model\n    nrounds = xgbcv$best_iteration\n  )\n  \n  return(lst)\n}\n\n# Define the search space for each parameter\nbounds &lt;- list(\n  eta = c(0.001, 0.2),             # Learning rate range\n  max_depth = c(1L, 10L),           # Tree depth range\n  min_child_weight = c(1, 50),      # Min observations range\n  subsample = c(0.1, 1),            # Subsampling range\n  lambda = c(1, 10),                # L2 regularization range\n  alpha = c(1, 10)                  # L1 regularization range\n)"
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html#running-bayesian-optimization",
    "href": "posts/bayesian-optimization-xgboost.html#running-bayesian-optimization",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "Running Bayesian Optimization",
    "text": "Running Bayesian Optimization\nNow we’ll run the optimization process to intelligently search for the best parameters:\n\nset.seed(1234)\nbayes_out &lt;- bayesOpt(\n  FUN = obj_func,                    # Our objective function\n  bounds = bounds,                   # Parameter bounds\n  initPoints = length(bounds) + 2,   # Initial random points\n  iters.n = 10,                      # Number of iterations\n  verbose = 0                        # Suppress output\n)\n\n# View top results\nbayes_out$scoreSummary[1:5, c(3:8, 13)]\n\n          eta max_depth min_child_weight subsample   lambda    alpha      Score\n        &lt;num&gt;     &lt;num&gt;            &lt;num&gt;     &lt;num&gt;    &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n1: 0.13392137         8         4.913332 0.2105925 4.721124 3.887629 -0.1292920\n2: 0.19400811         2        25.454160 0.9594105 9.329695 3.173695 -0.1790158\n3: 0.16079775         2        14.035652 0.5118349 1.229953 5.093530 -0.1662595\n4: 0.08957707         4        12.534842 0.3844404 4.358837 1.788342 -0.1672395\n5: 0.02876388         4        36.586761 0.8107181 6.137100 6.039125 -0.3320015\n\n# Get the best parameters\nbest_params &lt;- getBestPars(bayes_out)\ndata.frame(best_params)\n\n        eta max_depth min_child_weight subsample lambda    alpha\n1 0.1251447        10                1         1      1 5.905011"
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html#training-the-final-model",
    "href": "posts/bayesian-optimization-xgboost.html#training-the-final-model",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "Training the Final Model",
    "text": "Training the Final Model\nWith the optimal hyperparameters identified, we can now train our final XGBoost model.\n\n# Combine best params with base params\nopt_params &lt;- append(\n  list(booster = \"gbtree\", \n       objective = \"reg:squarederror\", \n       eval_metric = \"mae\"), \n  best_params\n)\n\n# Run cross-validation to determine optimal number of rounds\nxgbcv &lt;- xgb.cv(\n  params = opt_params,\n  data = X,\n  label = y,\n  nround = 100,\n  folds = folds,\n  prediction = TRUE,\n  early_stopping_rounds = 5,\n  verbose = 0,\n  maximize = FALSE\n)\n\n# Get optimal number of rounds\nnrounds = xgbcv$best_iteration\n\n# Fit the final XGBoost model\nmdl &lt;- xgboost(\n  data = X, \n  label = y, \n  params = opt_params, \n  maximize = FALSE, \n  early_stopping_rounds = 5, \n  nrounds = nrounds, \n  verbose = 0\n)\n\n# Make predictions on the test set\nactuals &lt;- test_df$cmedv\npredicted &lt;- test_df %&gt;%\n  select_at(mdl$feature_names) %&gt;%\n  as.matrix() %&gt;%\n  predict(mdl, newdata = .)\n\n# Evaluate performance using Mean Absolute Percentage Error (MAPE)\nmape &lt;- mean(abs(actuals - predicted)/actuals)\ncat(\"MAPE on test set:\", mape)\n\nMAPE on test set: 0.006424492"
  },
  {
    "objectID": "posts/bayesian-optimization-xgboost.html#why-bayesian-optimization",
    "href": "posts/bayesian-optimization-xgboost.html#why-bayesian-optimization",
    "title": "Using Bayesian Optimization to Tune XGBoost Models in R",
    "section": "Why Bayesian Optimization",
    "text": "Why Bayesian Optimization\nBayesian optimization offers several key advantages over traditional grid search:\n\nEfficiency: Finds optimal parameters in fewer iterations\nIntelligence: Learns from previous evaluations to focus on promising areas\nScalability: Remains efficient even with many hyperparameters\nSpeed: Completes in a fraction of the time while achieving comparable or better results\n\nThis approach becomes increasingly valuable as model complexity grows. For production models, consider increasing the iterations (iters.n) to ensure thorough exploration of the parameter space.\nThe ParBayesianOptimization package makes this powerful technique accessible to R users, allowing you to build better models with less computational overhead."
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html",
    "href": "posts/custom-charting-functions-ggplot2.html",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "",
    "text": "While R has a variety of options for 2D graphics and data visualization, it’s hard to beat ggplot2 in terms of features, functionality, and overall visual quality. This post demonstrates how to create customized charting functions for specific chart types using ggplot2 as the underlying visualization engine."
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#required-libraries",
    "href": "posts/custom-charting-functions-ggplot2.html#required-libraries",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Required Libraries",
    "text": "Required Libraries\n\n# Load required packages\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(stringr)"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#sample-dataset",
    "href": "posts/custom-charting-functions-ggplot2.html#sample-dataset",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Sample Dataset",
    "text": "Sample Dataset\nFor this demonstration, we’ll use a summarized version of the COVID-19 Data Repository hosted by Johns Hopkins University.\n\n# Load COVID-19 data\ndf &lt;- read.csv(\"https://bit.ly/3G8G63u\")\n\n# Get top 5 countries by death count\ntop_countries &lt;- df %&gt;% \n  group_by(country) %&gt;% \n  summarise(count = sum(deaths_daily)) %&gt;% \n  top_n(5) %&gt;% \n  .$country\n\nprint(top_countries)\n\n[1] \"Brazil\" \"India\"  \"Mexico\" \"Russia\" \"US\"    \n\n\nLet’s prepare our data for visualization by creating a 7-day moving average of daily confirmed cases for the top five countries:\n\n# Create a data frame with the required information\n# Note that a centered 7-day moving average is used\nplotdf &lt;- df %&gt;% \n  mutate(date = as.Date(date, format = \"%m/%d/%Y\")) %&gt;% \n  filter(country %in% top_countries) %&gt;% \n  group_by(country, date) %&gt;% \n  summarise(count = sum(confirmed_daily)) %&gt;%\n  arrange(country, date) %&gt;% \n  group_by(country) %&gt;% \n  mutate(MA = zoo::rollapply(count, FUN = mean, width = 7, by = 1, fill = NA, align = \"center\"))"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#building-a-simple-line-chart-function",
    "href": "posts/custom-charting-functions-ggplot2.html#building-a-simple-line-chart-function",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Building a Simple Line Chart Function",
    "text": "Building a Simple Line Chart Function\nLet’s start by creating a basic line chart function. Note the use of aes_string() instead of just aes(). This allows us to supply arguments to ggplot2 as strings, making our function more flexible.\n\n# Function definition\nline_chart &lt;- function(df, \n                       x, \n                       y, \n                       group_color = NULL, \n                       line_width = 1, \n                       line_type = 1){\n  \n  ggplot(df, aes(x = !! sym(x), \n                 y = !! sym(y), \n                 color = !! sym(group_color))) + \n    geom_line(linewidth = line_width, \n              linetype = line_type)\n}\n\n# Test run\nline_chart(plotdf,\n           x = \"date\",\n           y = \"MA\",\n           group_color = \"country\", \n           line_type = 1, \n           line_width = 1.2)"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#creating-a-custom-theme",
    "href": "posts/custom-charting-functions-ggplot2.html#creating-a-custom-theme",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Creating a Custom Theme",
    "text": "Creating a Custom Theme\nNow that we know how to encapsulate the call to ggplot2 in a more intuitive manner, we can create a customized theme for our charts. This is useful since this theme can be applied to any chart.\n\ncustom_theme &lt;- function(plt, \n                         base_size = 11, \n                         base_line_size = 1, \n                         palette = \"Set1\"){\n  \n  # Note the use of \"+\" and not \"%&gt;%\"\n  plt + \n    # Adjust overall font size\n    theme_minimal(base_size = base_size, \n                  base_line_size = base_line_size) + \n    \n    # Put legend at the bottom\n    theme(legend.position = \"bottom\") + \n    \n    # Different colour scale\n    scale_color_brewer(palette = palette)\n}\n\n# Test run\nline_chart(plotdf, \"date\", \"MA\", \"country\") %&gt;% custom_theme()"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#enhancing-our-functions",
    "href": "posts/custom-charting-functions-ggplot2.html#enhancing-our-functions",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Enhancing Our Functions",
    "text": "Enhancing Our Functions\nLet’s add more features to our line_chart() function to make it more versatile:\n\nline_chart &lt;- function(df, \n                       x, y, \n                       group_color = NULL, \n                       line_width = 1, \n                       line_type = 1, \n                       xlab = NULL, \n                       ylab = NULL, \n                       title = NULL, \n                       subtitle = NULL, \n                       caption = NULL){\n  # Base plot\n  ggplot(df, aes(x = !! sym(x), \n                 y = !! sym(y), \n                 color = !! sym(group_color))) + \n    \n    # Line chart \n    geom_line(size = line_width, \n              linetype = line_type) + \n    \n    # Titles and subtitles\n    labs(x = xlab, \n         y = ylab, \n         title = title, \n         subtitle = subtitle, \n         caption = caption)\n}\n\nWe’ll also enhance our custom_theme() function to handle different axis formatting options:\n\ncustom_theme &lt;- function(plt, \n                         palette = \"Set1\", \n                         format_x_axis_as = NULL, \n                         format_y_axis_as = NULL, \n                         x_axis_scale = 1, \n                         y_axis_scale = 1, \n                         x_axis_text_size = 10, \n                         y_axis_text_size = 10, \n                         base_size = 11, \n                         base_line_size = 1, \n                         x_angle = 45){\n  \n  mappings &lt;- names(unlist(plt$mapping))\n  \n  p &lt;- plt + \n    \n    # Adjust overall font size\n    theme_minimal(base_size = base_size, \n                  base_line_size = base_line_size) + \n    \n    # Put legend at the bottom\n    theme(legend.position = \"bottom\", \n          axis.text.x = element_text(angle = x_angle)) + \n    \n    # Different colour palette\n    {if(\"colour\" %in% mappings) scale_color_brewer(palette = palette)}+\n    \n    {if(\"fill\" %in% mappings) scale_fill_brewer(palette = palette)}+\n    \n    # Change some theme options\n    theme(plot.background = element_rect(fill = \"#f7f7f7\"), \n          plot.subtitle = element_text(face = \"italic\"), \n          axis.title.x = element_text(face = \"bold\", \n                                      size = x_axis_text_size), \n          axis.title.y = element_text(face = \"bold\", \n                                      size = y_axis_text_size)) + \n    \n    # Change x-axis formatting\n    {if(!is.null(format_x_axis_as))\n      switch(format_x_axis_as, \n             \"date\" = scale_x_date(breaks = pretty_breaks(n = 12)), \n             \"number\" = scale_x_continuous(labels = number_format(accuracy = 0.1, \n                                                                  decimal.mark = \",\", \n                                                                  scale = x_axis_scale)), \n             \"percent\" = scale_x_continuous(labels = percent))} + \n    \n    # Change y-axis formatting\n    {if(!is.null(format_y_axis_as))\n      \n      switch(format_y_axis_as, \n             \"date\" = scale_y_date(breaks = pretty_breaks(n = 12)), \n             \"number\" = scale_y_continuous(labels = number_format(accuracy = 0.1, \n                                                                  decimal.mark = \",\", \n                                                                  scale = y_axis_scale)), \n             \"percent\" = scale_y_continuous(labels = percent))}\n  \n  # Capitalise all names\n  vec &lt;- lapply(p$labels, str_to_title)\n  names(vec) &lt;- names(p$labels)\n  p$labels &lt;- vec\n  \n  return(p)\n}"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#putting-it-all-together",
    "href": "posts/custom-charting-functions-ggplot2.html#putting-it-all-together",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Putting It All Together",
    "text": "Putting It All Together\nNow let’s see how our enhanced functions work together to create a polished visualization:\n\nline_chart(plotdf,\n           x = \"date\", \n           y = \"MA\", \n           group_color = \"country\", \n           xlab = \"Date\", \n           ylab = \"Moving Avg. (in '000)\", \n           title = \"Daily COVID19 Case Load\", \n           subtitle = \"Top 5 countries by volume\") %&gt;% \n  \n  custom_theme(format_x_axis_as = \"date\", \n               format_y_axis_as = \"number\", \n               y_axis_scale = 0.001)"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#applying-the-custom-theme-to-other-chart-types",
    "href": "posts/custom-charting-functions-ggplot2.html#applying-the-custom-theme-to-other-chart-types",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Applying the Custom Theme to Other Chart Types",
    "text": "Applying the Custom Theme to Other Chart Types\nThe beauty of our custom_theme() function is that it can be applied to any ggplot2 object. Let’s create a bar chart to demonstrate this flexibility:\n\np &lt;- plotdf %&gt;%  \n  mutate(month = format(date, \"%m-%b\")) %&gt;% \n  ggplot(aes(x = month, y = MA, fill = country)) + \n  geom_col(position = \"dodge\") + \n  labs(title = \"Monthly COVID19 Case load trend\", \n       subtitle = \"Top 5 countries\", \n       x = \"Month\", \n       y = \"Moving Average ('000)\")\n\ncustom_theme(p, \n             palette = \"Set2\", \n             format_y_axis_as = \"number\", \n             y_axis_scale = 0.001)"
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#benefits-of-custom-charting-functions",
    "href": "posts/custom-charting-functions-ggplot2.html#benefits-of-custom-charting-functions",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "Benefits of Custom Charting Functions",
    "text": "Benefits of Custom Charting Functions\nCreating custom charting functions with ggplot2 offers several advantages:\n\nConsistency: Ensures all charts in your reports or dashboards have a consistent look and feel.\nEfficiency: Reduces the amount of code you need to write for commonly used chart types.\nMaintainability: Makes it easier to update the style of all charts by modifying a single function.\nSimplicity: Abstracts away the complexity of ggplot2 for team members who may not be as familiar with the package."
  },
  {
    "objectID": "posts/custom-charting-functions-ggplot2.html#when-to-use-custom-functions-vs.-direct-ggplot2",
    "href": "posts/custom-charting-functions-ggplot2.html#when-to-use-custom-functions-vs.-direct-ggplot2",
    "title": "Custom Charting Functions Using ggplot2",
    "section": "When to Use Custom Functions vs. Direct ggplot2",
    "text": "When to Use Custom Functions vs. Direct ggplot2\nIt’s worth noting that building customized charting functions using ggplot2 is most useful when you need to create the same type of chart(s) repeatedly. When doing exploratory work, using ggplot2 directly is often easier and more flexible since you can build all kinds of charts (or layer different chart types) within the same pipeline."
  },
  {
    "objectID": "posts/getting-started-with-reticulate.html",
    "href": "posts/getting-started-with-reticulate.html",
    "title": "Getting Started with Python using R and reticulate",
    "section": "",
    "text": "Want to use Python’s powerful libraries without leaving R? The reticulate package gives you the best of both worlds - R’s elegant data handling and visualization with Python’s machine learning and scientific computing tools. This post shows you how to set up and use this powerful bridge between languages."
  },
  {
    "objectID": "posts/getting-started-with-reticulate.html#quick-setup-in-4-steps",
    "href": "posts/getting-started-with-reticulate.html#quick-setup-in-4-steps",
    "title": "Getting Started with Python using R and reticulate",
    "section": "Quick Setup in 4 Steps",
    "text": "Quick Setup in 4 Steps\n\n1. Install reticulate\n\ninstall.packages(\"reticulate\")\nlibrary(reticulate)\n\n\n\n2. Install Python via Miniconda\nThe easiest approach is to let reticulate handle Python installation for you:\n\ninstall_miniconda(path = \"c:/miniconda\")\n\n\n\n3. Connect to Python\nReticulate creates a default environment called r-reticulate. Let’s connect to it:\n\n# Check available environments\nconda_list()\n\n# Connect to the default environment\nuse_condaenv(\"r-reticulate\")\n\n\n\n4. Install Python Packages\nNow you can install any Python packages you need:\n\npy_install(c(\"pandas\", \"scikit-learn\", \"matplotlib\"))"
  },
  {
    "objectID": "posts/getting-started-with-reticulate.html#three-ways-to-use-python-in-r",
    "href": "posts/getting-started-with-reticulate.html#three-ways-to-use-python-in-r",
    "title": "Getting Started with Python using R and reticulate",
    "section": "Three Ways to Use Python in R",
    "text": "Three Ways to Use Python in R\n\n1. Import Python Modules Directly\n\n# Import pandas and use it like any R package\npd &lt;- import(\"pandas\")\n\n# Create a pandas Series\npd$Series(c(1, 2, 3, 4, 5))\n\n# Import numpy for numerical operations\nnp &lt;- import(\"numpy\")\nnp$mean(c(1:100))  # Calculate mean using numpy\n\n\n\n2. Write Python Code in R Markdown\nYou can mix R and Python code in the same document by using Python code chunks:\n\n# This is Python code!\nimport pandas as pd\nimport numpy as np\n\n# Create a simple DataFrame\ndf = pd.DataFrame({\n    'A': np.random.randn(5),\n    'B': np.random.randn(5)\n})\n\nprint(df.describe())\n\n\n\n3. Use Python Libraries in R Workflows\nThe most powerful approach is using Python’s machine learning libraries within R:\n\n# Import scikit-learn\nsk &lt;- import(\"sklearn.linear_model\")\n\n# Create and fit a linear regression model\nmodel &lt;- sk$LinearRegression()\nmodel$fit(X = as.matrix(mtcars[, c(\"disp\", \"hp\", \"wt\")]), \n         y = mtcars$mpg)\n\n# Get predictions and coefficients\npredictions &lt;- model$predict(as.matrix(mtcars[, c(\"disp\", \"hp\", \"wt\")]))\ncoefficients &lt;- data.frame(\n  Feature = c(\"Intercept\", \"disp\", \"hp\", \"wt\"),\n  Coefficient = c(model$intercept_, model$coef_)\n)\n\ncoefficients"
  },
  {
    "objectID": "posts/getting-started-with-reticulate.html#real-world-applications",
    "href": "posts/getting-started-with-reticulate.html#real-world-applications",
    "title": "Getting Started with Python using R and reticulate",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nHere are some powerful ways to combine R and Python in your data science workflow:\n\nData Science Pipeline\n\n# 1. Data cleaning with R's tidyverse\nlibrary(readr)\nclean_data &lt;- read_csv(\"data.csv\") %&gt;%\n  filter(!is.na(important_column)) %&gt;%\n  mutate(new_feature = feature1 / feature2)\n\n# 2. Machine learning with Python's scikit-learn\nsk &lt;- import(\"sklearn.ensemble\")\nmodel &lt;- sk$RandomForestClassifier(n_estimators=100)\nmodel$fit(X = as.matrix(clean_data[, features]), \n         y = clean_data$target)\n\n# 3. Visualization with R's ggplot2\npredictions &lt;- model$predict_proba(as.matrix(clean_data[, features]))[,2]\nclean_data %&gt;%\n  mutate(prediction = predictions) %&gt;%\n  ggplot(aes(x=feature1, y=feature2, color=prediction)) +\n  geom_point() +\n  scale_color_viridis_c()\n\n\n\nWhen to Use Each Language\nUse R for:\n\nData manipulation with dplyr/data.table\nStatistical modeling and hypothesis testing\nPublication-quality visualization\nInteractive reports and dashboards\n\nUse Python for:\n\nDeep learning with TensorFlow/PyTorch\nNatural language processing\nComputer vision\nAdvanced machine learning algorithms\n\nWith reticulate, you don’t have to choose - use the best tool for each part of your analysis!"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html",
    "href": "posts/measuring-model-performance-gains-table.html",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "In credit risk modeling, analysts often use a tool called a gains table (or KS table) to measure and quantify the performance of classification models. This post explores how to build and interpret such a table using R.\n\n\nA gains table discretizes the population (typically a test or validation set) into groups based on the model’s output (probability, log odds, or scores). Usually, each group represents 10% of the total population (deciles). The table then presents summary statistics for each group and analyzes the cumulative distributions of events (defaults) and non-events to quantify the model’s performance.\n\n\n\n\n# Load required packages\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(scales)\n\n\n\n\nWe’ll use a sample from the Lending Club dataset, which contains information about loans and their outcomes.\n\n# Load the sample data\nsample &lt;- read.csv(\"https://bit.ly/42ypcnJ\")\n\n# Check dimensions\ndim(sample)\n\n[1] 10000   153\n\n\n\n\n\nFirst, we need to create a target (outcome) variable to model. Since this is a credit risk use case, we’ll identify borrowers who defaulted on their payments.\n\n# Check unique loan statuses\nunique(sample$loan_status)\n\n[1] \"Fully Paid\"                                         \n[2] \"Current\"                                            \n[3] \"Charged Off\"                                        \n[4] \"Late (31-120 days)\"                                 \n[5] \"Late (16-30 days)\"                                  \n[6] \"In Grace Period\"                                    \n[7] \"Does not meet the credit policy. Status:Fully Paid\" \n[8] \"Does not meet the credit policy. Status:Charged Off\"\n\n# Define \"bad\" loans as those that are charged off\ncodes &lt;- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\n\n# Create a binary flag for defaults\nsample %&lt;&gt;% mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))\n\n# Check overall event rates\nsample %&gt;% \n  summarise(events = sum(bad_flag == 1), \n            non_events = sum(bad_flag == 0)) %&gt;% \n  mutate(event_rate = events/(events + non_events))\n\n  events non_events event_rate\n1   1162       8838     0.1162\n\n\n\n\n\nNext, let’s build a quick model, the output of which we’ll use to create the gains table.\n\n# Replace NA values with a default value\nsample[is.na(sample)] &lt;- -1\n\n# Clean the data\nsample %&lt;&gt;% \n  # Remove cases where home ownership and payment plan are not reported\n  filter(!home_ownership %in% c(\"\", \"NONE\"),\n         pymnt_plan != \"\") %&gt;% \n  # Convert categorical variables to factors\n  mutate(home_ownership = factor(home_ownership), \n         pymnt_plan = factor(pymnt_plan))\n\n# Train-test split (70-30)\nidx &lt;- sample(1:nrow(sample), size = 0.7 * nrow(sample), replace = FALSE)\ntrain &lt;- sample[idx,]\ntest &lt;- sample[-idx,]\n\n\n# Build a logistic regression model\nmdl &lt;- glm(\n  formula = bad_flag ~ \n    loan_amnt + term + mths_since_last_delinq + total_pymnt + \n    home_ownership + acc_now_delinq + \n    inq_last_6mths + delinq_amnt + \n    mths_since_last_record + mths_since_recent_revol_delinq + \n    mths_since_last_major_derog + mths_since_recent_inq + \n    mths_since_recent_bc + num_accts_ever_120_pd,\n  family = \"binomial\", \n  data = train\n)\n\n# Generate predictions on the test set\ntest$pred &lt;- predict(mdl, newdata = test)\n\n\n\n\nNow let’s build the gains table step by step:\n\n\n\n# Create deciles based on model predictions\nq &lt;- quantile(test$pred, probs = seq(0, 1, length.out = 11))\n\n# Add bins to test dataset\ntest$bins &lt;- cut(test$pred, breaks = q, include.lowest = TRUE, \n                right = TRUE, ordered_result = TRUE)\n\n# Check the bin levels (note they're in increasing order)\nlevels(test$bins)\n\n [1] \"[-5.37,-3.3]\"  \"(-3.3,-2.9]\"   \"(-2.9,-2.66]\"  \"(-2.66,-2.45]\"\n [5] \"(-2.45,-2.25]\" \"(-2.25,-2.07]\" \"(-2.07,-1.86]\" \"(-1.86,-1.61]\"\n [9] \"(-1.61,-1.23]\" \"(-1.23,1.6]\"  \n\n\n\n\n\n\n# Create initial gains table with counts\ngains_table &lt;- test %&gt;% \n  group_by(bins) %&gt;% \n  summarise(total = n(), \n            events = sum(bad_flag == 1), \n            non_events = sum(bad_flag == 0))\n\n# Add event rate column\ngains_table %&lt;&gt;%\n  mutate(event_rate = percent(events / total, 0.1, 100))\n\n# Display the table\nkable(gains_table)\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\n\n\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n\n\n\n\n\n\n\n\n\n# Add population percentage and cumulative distributions\ngains_table %&lt;&gt;%\n  mutate(pop_pct = percent(total/sum(total), 0.1, 100), \n         \n         # Calculate cumulative percentages\n         c.events_pct = cumsum(events) / sum(events),\n         c.non_events_pct = cumsum(non_events) / sum(non_events))\n\n# Display the updated table\nkable(gains_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\npop_pct\nc.events_pct\nc.non_events_pct\n\n\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n10.0%\n0.0145773\n0.1110275\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n10.0%\n0.0379009\n0.2209259\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n10.0%\n0.0612245\n0.3308242\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n10.0%\n0.0932945\n0.4395935\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n10.0%\n0.1574344\n0.5442228\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n10.0%\n0.2565598\n0.6443357\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n10.0%\n0.4198251\n0.7361686\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n10.0%\n0.6093294\n0.8246142\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n10.0%\n0.7813411\n0.9153180\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n10.0%\n1.0000000\n1.0000000\n\n\n\n\n\n\n\n\n\n# Add KS statistic, capture rate, and cumulative event rate\ngains_table %&lt;&gt;%\n  mutate(\n    # KS statistic (difference between cumulative distributions)\n    ks = round(abs(c.events_pct - c.non_events_pct), 2), \n    \n    # Capture rate (percentage of total events captured)\n    cap_rate = percent(cumsum(events)/sum(events), 1, 100), \n    \n    # Cumulative event rate\n    c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), \n    \n    # Format percentage columns\n    c.events_pct = percent(c.events_pct, 0.1, 100),\n    c.non_events_pct = percent(c.non_events_pct, 0.1, 100))\n\n# Display the final table\nkable(gains_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\npop_pct\nc.events_pct\nc.non_events_pct\nks\ncap_rate\nc_event_rate\n\n\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n10.0%\n1.5%\n11.1%\n0.10\n1%\n1.7%\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n10.0%\n3.8%\n22.1%\n0.18\n4%\n2.2%\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n10.0%\n6.1%\n33.1%\n0.27\n6%\n2.3%\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n10.0%\n9.3%\n44.0%\n0.35\n9%\n2.7%\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n10.0%\n15.7%\n54.4%\n0.39\n16%\n3.6%\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n10.0%\n25.7%\n64.4%\n0.39\n26%\n4.9%\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n10.0%\n42.0%\n73.6%\n0.32\n42%\n6.9%\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n10.0%\n60.9%\n82.5%\n0.22\n61%\n8.7%\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n10.0%\n78.1%\n91.5%\n0.13\n78%\n9.9%\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n10.0%\n100.0%\n100.0%\n0.00\n100%\n11.4%\n\n\n\n\n\n\n\n\n\nLet’s encapsulate all the above steps into a single function that can be reused for any binary classification model:\n\ngains_table &lt;- function(act, pred, increasing = TRUE, nBins = 10) {\n  \n  # Create bins based on predictions\n  q &lt;- quantile(pred, probs = seq(0, 1, length.out = nBins + 1))\n  bins &lt;- cut(pred, breaks = q, include.lowest = TRUE, right = TRUE, ordered_result = TRUE)\n  \n  df &lt;- data.frame(act, pred, bins)\n  \n  df %&gt;% \n    # Group by bins and calculate statistics\n    group_by(bins) %&gt;% \n    summarise(total = n(), \n              events = sum(act == 1), \n              non_events = sum(act == 0)) %&gt;% \n    mutate(event_rate = percent(events / total, 0.1, 100)) %&gt;% \n    \n    # Sort the table based on the 'increasing' parameter\n    {if(increasing == TRUE) {\n      arrange(., bins)\n    } else {\n      arrange(., desc(bins))\n    }} %&gt;% \n    \n    # Add all performance metrics\n    mutate(pop_pct = percent(total/sum(total), 0.1, 100), \n           c.events_pct = cumsum(events) / sum(events),\n           c.non_events_pct = cumsum(non_events) / sum(non_events), \n           ks = round(abs(c.events_pct - c.non_events_pct), 2), \n           cap_rate = percent(cumsum(events)/sum(events), 1, 100), \n           c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), \n           c.events_pct = percent(c.events_pct, 0.1, 100),\n           c.non_events_pct = percent(c.non_events_pct, 0.1, 100))\n}\n\n\n\n\n# Generate a gains table with bins in descending order\ntab &lt;- gains_table(test$bad_flag, test$pred, FALSE, 10)\nkable(tab)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\npop_pct\nc.events_pct\nc.non_events_pct\nks\ncap_rate\nc_event_rate\n\n\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n10.0%\n21.9%\n8.5%\n0.13\n22%\n25.0%\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n10.0%\n39.1%\n17.5%\n0.22\n39%\n22.3%\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n10.0%\n58.0%\n26.4%\n0.32\n58%\n22.1%\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n10.0%\n74.3%\n35.6%\n0.39\n74%\n21.2%\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n10.0%\n84.3%\n45.6%\n0.39\n84%\n19.3%\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n10.0%\n90.7%\n56.0%\n0.35\n91%\n17.3%\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n10.0%\n93.9%\n66.9%\n0.27\n94%\n15.3%\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n10.0%\n96.2%\n77.9%\n0.18\n96%\n13.8%\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n10.0%\n98.5%\n88.9%\n0.10\n99%\n12.5%\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n10.0%\n100.0%\n100.0%\n0.00\n100%\n11.4%\n\n\n\n\n\n\n\n\n\nA gains table provides several key insights into model performance:\n\nMonotonicity: The event rates should consistently increase (or decrease) across bins. This confirms that the model effectively rank-orders risk.\nBin Consistency: If bin sizes are not consistent (ideally ~10% each), it suggests the model is assigning the same output/score to many borrowers (clumping), which could pose issues when deciding cutoffs.\nKS Statistic: The maximum value of the KS column indicates the model’s discriminatory power. A higher value (closer to 1) indicates better separation between good and bad borrowers.\nCapture Rate: Shows what percentage of all bad accounts are captured at each cutoff point.\nCumulative Event Rate: Indicates the bad rate among all accounts up to that bin, useful for setting approval thresholds.\n\n\n\n\nIn credit risk management, the gains table helps with:\n\nSetting Cutoffs: Identifying appropriate score thresholds for approving or rejecting applications.\nStrategy Development: Creating tiered strategies (e.g., approve, review, decline) based on risk levels.\nPerformance Monitoring: Tracking model performance over time by comparing actual vs. expected distributions.\nModel Comparison: Evaluating different models by comparing their KS statistics and capture rates.\n\nThe gains table is a powerful tool for evaluating binary classification models, especially in credit risk applications. By providing a structured view of how well a model separates good and bad cases across the score distribution, it helps analysts make informed decisions about model quality and operational implementation."
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#what-is-a-gains-table",
    "href": "posts/measuring-model-performance-gains-table.html#what-is-a-gains-table",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "A gains table discretizes the population (typically a test or validation set) into groups based on the model’s output (probability, log odds, or scores). Usually, each group represents 10% of the total population (deciles). The table then presents summary statistics for each group and analyzes the cumulative distributions of events (defaults) and non-events to quantify the model’s performance."
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#required-libraries",
    "href": "posts/measuring-model-performance-gains-table.html#required-libraries",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "# Load required packages\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(scales)"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#sample-dataset",
    "href": "posts/measuring-model-performance-gains-table.html#sample-dataset",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "We’ll use a sample from the Lending Club dataset, which contains information about loans and their outcomes.\n\n# Load the sample data\nsample &lt;- read.csv(\"https://bit.ly/42ypcnJ\")\n\n# Check dimensions\ndim(sample)\n\n[1] 10000   153"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#defining-the-target-variable",
    "href": "posts/measuring-model-performance-gains-table.html#defining-the-target-variable",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "First, we need to create a target (outcome) variable to model. Since this is a credit risk use case, we’ll identify borrowers who defaulted on their payments.\n\n# Check unique loan statuses\nunique(sample$loan_status)\n\n[1] \"Fully Paid\"                                         \n[2] \"Current\"                                            \n[3] \"Charged Off\"                                        \n[4] \"Late (31-120 days)\"                                 \n[5] \"Late (16-30 days)\"                                  \n[6] \"In Grace Period\"                                    \n[7] \"Does not meet the credit policy. Status:Fully Paid\" \n[8] \"Does not meet the credit policy. Status:Charged Off\"\n\n# Define \"bad\" loans as those that are charged off\ncodes &lt;- c(\"Charged Off\", \"Does not meet the credit policy. Status:Charged Off\")\n\n# Create a binary flag for defaults\nsample %&lt;&gt;% mutate(bad_flag = ifelse(loan_status %in% codes, 1, 0))\n\n# Check overall event rates\nsample %&gt;% \n  summarise(events = sum(bad_flag == 1), \n            non_events = sum(bad_flag == 0)) %&gt;% \n  mutate(event_rate = events/(events + non_events))\n\n  events non_events event_rate\n1   1162       8838     0.1162"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#building-a-simple-model",
    "href": "posts/measuring-model-performance-gains-table.html#building-a-simple-model",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "Next, let’s build a quick model, the output of which we’ll use to create the gains table.\n\n# Replace NA values with a default value\nsample[is.na(sample)] &lt;- -1\n\n# Clean the data\nsample %&lt;&gt;% \n  # Remove cases where home ownership and payment plan are not reported\n  filter(!home_ownership %in% c(\"\", \"NONE\"),\n         pymnt_plan != \"\") %&gt;% \n  # Convert categorical variables to factors\n  mutate(home_ownership = factor(home_ownership), \n         pymnt_plan = factor(pymnt_plan))\n\n# Train-test split (70-30)\nidx &lt;- sample(1:nrow(sample), size = 0.7 * nrow(sample), replace = FALSE)\ntrain &lt;- sample[idx,]\ntest &lt;- sample[-idx,]\n\n\n# Build a logistic regression model\nmdl &lt;- glm(\n  formula = bad_flag ~ \n    loan_amnt + term + mths_since_last_delinq + total_pymnt + \n    home_ownership + acc_now_delinq + \n    inq_last_6mths + delinq_amnt + \n    mths_since_last_record + mths_since_recent_revol_delinq + \n    mths_since_last_major_derog + mths_since_recent_inq + \n    mths_since_recent_bc + num_accts_ever_120_pd,\n  family = \"binomial\", \n  data = train\n)\n\n# Generate predictions on the test set\ntest$pred &lt;- predict(mdl, newdata = test)"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#creating-the-gains-table",
    "href": "posts/measuring-model-performance-gains-table.html#creating-the-gains-table",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "Now let’s build the gains table step by step:\n\n\n\n# Create deciles based on model predictions\nq &lt;- quantile(test$pred, probs = seq(0, 1, length.out = 11))\n\n# Add bins to test dataset\ntest$bins &lt;- cut(test$pred, breaks = q, include.lowest = TRUE, \n                right = TRUE, ordered_result = TRUE)\n\n# Check the bin levels (note they're in increasing order)\nlevels(test$bins)\n\n [1] \"[-5.37,-3.3]\"  \"(-3.3,-2.9]\"   \"(-2.9,-2.66]\"  \"(-2.66,-2.45]\"\n [5] \"(-2.45,-2.25]\" \"(-2.25,-2.07]\" \"(-2.07,-1.86]\" \"(-1.86,-1.61]\"\n [9] \"(-1.61,-1.23]\" \"(-1.23,1.6]\"  \n\n\n\n\n\n\n# Create initial gains table with counts\ngains_table &lt;- test %&gt;% \n  group_by(bins) %&gt;% \n  summarise(total = n(), \n            events = sum(bad_flag == 1), \n            non_events = sum(bad_flag == 0))\n\n# Add event rate column\ngains_table %&lt;&gt;%\n  mutate(event_rate = percent(events / total, 0.1, 100))\n\n# Display the table\nkable(gains_table)\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\n\n\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n\n\n\n\n\n\n\n\n\n# Add population percentage and cumulative distributions\ngains_table %&lt;&gt;%\n  mutate(pop_pct = percent(total/sum(total), 0.1, 100), \n         \n         # Calculate cumulative percentages\n         c.events_pct = cumsum(events) / sum(events),\n         c.non_events_pct = cumsum(non_events) / sum(non_events))\n\n# Display the updated table\nkable(gains_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\npop_pct\nc.events_pct\nc.non_events_pct\n\n\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n10.0%\n0.0145773\n0.1110275\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n10.0%\n0.0379009\n0.2209259\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n10.0%\n0.0612245\n0.3308242\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n10.0%\n0.0932945\n0.4395935\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n10.0%\n0.1574344\n0.5442228\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n10.0%\n0.2565598\n0.6443357\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n10.0%\n0.4198251\n0.7361686\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n10.0%\n0.6093294\n0.8246142\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n10.0%\n0.7813411\n0.9153180\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n10.0%\n1.0000000\n1.0000000\n\n\n\n\n\n\n\n\n\n# Add KS statistic, capture rate, and cumulative event rate\ngains_table %&lt;&gt;%\n  mutate(\n    # KS statistic (difference between cumulative distributions)\n    ks = round(abs(c.events_pct - c.non_events_pct), 2), \n    \n    # Capture rate (percentage of total events captured)\n    cap_rate = percent(cumsum(events)/sum(events), 1, 100), \n    \n    # Cumulative event rate\n    c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), \n    \n    # Format percentage columns\n    c.events_pct = percent(c.events_pct, 0.1, 100),\n    c.non_events_pct = percent(c.non_events_pct, 0.1, 100))\n\n# Display the final table\nkable(gains_table)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\npop_pct\nc.events_pct\nc.non_events_pct\nks\ncap_rate\nc_event_rate\n\n\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n10.0%\n1.5%\n11.1%\n0.10\n1%\n1.7%\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n10.0%\n3.8%\n22.1%\n0.18\n4%\n2.2%\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n10.0%\n6.1%\n33.1%\n0.27\n6%\n2.3%\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n10.0%\n9.3%\n44.0%\n0.35\n9%\n2.7%\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n10.0%\n15.7%\n54.4%\n0.39\n16%\n3.6%\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n10.0%\n25.7%\n64.4%\n0.39\n26%\n4.9%\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n10.0%\n42.0%\n73.6%\n0.32\n42%\n6.9%\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n10.0%\n60.9%\n82.5%\n0.22\n61%\n8.7%\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n10.0%\n78.1%\n91.5%\n0.13\n78%\n9.9%\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n10.0%\n100.0%\n100.0%\n0.00\n100%\n11.4%"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#creating-a-reusable-function",
    "href": "posts/measuring-model-performance-gains-table.html#creating-a-reusable-function",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "Let’s encapsulate all the above steps into a single function that can be reused for any binary classification model:\n\ngains_table &lt;- function(act, pred, increasing = TRUE, nBins = 10) {\n  \n  # Create bins based on predictions\n  q &lt;- quantile(pred, probs = seq(0, 1, length.out = nBins + 1))\n  bins &lt;- cut(pred, breaks = q, include.lowest = TRUE, right = TRUE, ordered_result = TRUE)\n  \n  df &lt;- data.frame(act, pred, bins)\n  \n  df %&gt;% \n    # Group by bins and calculate statistics\n    group_by(bins) %&gt;% \n    summarise(total = n(), \n              events = sum(act == 1), \n              non_events = sum(act == 0)) %&gt;% \n    mutate(event_rate = percent(events / total, 0.1, 100)) %&gt;% \n    \n    # Sort the table based on the 'increasing' parameter\n    {if(increasing == TRUE) {\n      arrange(., bins)\n    } else {\n      arrange(., desc(bins))\n    }} %&gt;% \n    \n    # Add all performance metrics\n    mutate(pop_pct = percent(total/sum(total), 0.1, 100), \n           c.events_pct = cumsum(events) / sum(events),\n           c.non_events_pct = cumsum(non_events) / sum(non_events), \n           ks = round(abs(c.events_pct - c.non_events_pct), 2), \n           cap_rate = percent(cumsum(events)/sum(events), 1, 100), \n           c_event_rate = percent(cumsum(events)/cumsum(total), 0.1, 100), \n           c.events_pct = percent(c.events_pct, 0.1, 100),\n           c.non_events_pct = percent(c.non_events_pct, 0.1, 100))\n}\n\n\n\n\n# Generate a gains table with bins in descending order\ntab &lt;- gains_table(test$bad_flag, test$pred, FALSE, 10)\nkable(tab)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbins\ntotal\nevents\nnon_events\nevent_rate\npop_pct\nc.events_pct\nc.non_events_pct\nks\ncap_rate\nc_event_rate\n\n\n\n\n(-1.23,1.6]\n300\n75\n225\n25.0%\n10.0%\n21.9%\n8.5%\n0.13\n22%\n25.0%\n\n\n(-1.61,-1.23]\n300\n59\n241\n19.7%\n10.0%\n39.1%\n17.5%\n0.22\n39%\n22.3%\n\n\n(-1.86,-1.61]\n300\n65\n235\n21.7%\n10.0%\n58.0%\n26.4%\n0.32\n58%\n22.1%\n\n\n(-2.07,-1.86]\n300\n56\n244\n18.7%\n10.0%\n74.3%\n35.6%\n0.39\n74%\n21.2%\n\n\n(-2.25,-2.07]\n300\n34\n266\n11.3%\n10.0%\n84.3%\n45.6%\n0.39\n84%\n19.3%\n\n\n(-2.45,-2.25]\n300\n22\n278\n7.3%\n10.0%\n90.7%\n56.0%\n0.35\n91%\n17.3%\n\n\n(-2.66,-2.45]\n300\n11\n289\n3.7%\n10.0%\n93.9%\n66.9%\n0.27\n94%\n15.3%\n\n\n(-2.9,-2.66]\n300\n8\n292\n2.7%\n10.0%\n96.2%\n77.9%\n0.18\n96%\n13.8%\n\n\n(-3.3,-2.9]\n300\n8\n292\n2.7%\n10.0%\n98.5%\n88.9%\n0.10\n99%\n12.5%\n\n\n[-5.37,-3.3]\n300\n5\n295\n1.7%\n10.0%\n100.0%\n100.0%\n0.00\n100%\n11.4%"
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#interpreting-the-gains-table",
    "href": "posts/measuring-model-performance-gains-table.html#interpreting-the-gains-table",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "A gains table provides several key insights into model performance:\n\nMonotonicity: The event rates should consistently increase (or decrease) across bins. This confirms that the model effectively rank-orders risk.\nBin Consistency: If bin sizes are not consistent (ideally ~10% each), it suggests the model is assigning the same output/score to many borrowers (clumping), which could pose issues when deciding cutoffs.\nKS Statistic: The maximum value of the KS column indicates the model’s discriminatory power. A higher value (closer to 1) indicates better separation between good and bad borrowers.\nCapture Rate: Shows what percentage of all bad accounts are captured at each cutoff point.\nCumulative Event Rate: Indicates the bad rate among all accounts up to that bin, useful for setting approval thresholds."
  },
  {
    "objectID": "posts/measuring-model-performance-gains-table.html#practical-applications",
    "href": "posts/measuring-model-performance-gains-table.html#practical-applications",
    "title": "Measuring Model Performance Using a Gains Table",
    "section": "",
    "text": "In credit risk management, the gains table helps with:\n\nSetting Cutoffs: Identifying appropriate score thresholds for approving or rejecting applications.\nStrategy Development: Creating tiered strategies (e.g., approve, review, decline) based on risk levels.\nPerformance Monitoring: Tracking model performance over time by comparing actual vs. expected distributions.\nModel Comparison: Evaluating different models by comparing their KS statistics and capture rates.\n\nThe gains table is a powerful tool for evaluating binary classification models, especially in credit risk applications. By providing a structured view of how well a model separates good and bad cases across the score distribution, it helps analysts make informed decisions about model quality and operational implementation."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html",
    "href": "posts/particle-swarm-optimization.html",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "Portfolio optimization is a critical task in investment management, where the goal is to allocate capital across different assets to maximize returns while controlling risk. In this post, we’ll explore how to use Particle Swarm Optimization (PSO) to perform mean-variance portfolio optimization with various constraints.\nPSO is a computational method inspired by the social behavior of bird flocking or fish schooling. It optimizes a problem by having a population of candidate solutions (particles) that move around the search space according to mathematical formulas. Each particle’s movement is influenced by its local best-known position and also guided toward the best-known positions found by other particles in the swarm.\nThis approach is particularly valuable for portfolio optimization because: 1. It can handle non-convex and complex constraint functions 2. It doesn’t require derivatives of the objective function 3. It can escape local optima through its stochastic nature\nFor additional information on mean-variance optimization and the CAPM model, refer to this paper.\n\n\nBefore we begin, let’s load the R packages we’ll need for this analysis:\n\n# Load required packages\nlibrary(pso)       # For PSO implementation (provides psoptim function)\nlibrary(ggplot2)   # For data visualization\nlibrary(dplyr)     # For data manipulation and transformation\nlibrary(quantmod)  # For downloading financial data\nlibrary(tidyr)     # For reshaping data (pivot_wider, gather functions)\nlibrary(plotly)    # For creating interactive 3D visualizations\n\n\n\n\nThe first step in portfolio optimization is gathering the necessary data. We’ll need historical price data to calculate returns and risk metrics.\n\n\nFor this demonstration, we’ll use stocks from the NIFTY50 index, which includes the 50 largest Indian companies by market capitalization:\n\n# Read ticker list from NSE (National Stock Exchange of India) website\nticker_list &lt;- read.csv(\"https://raw.githubusercontent.com/royr2/datasets/refs/heads/main/ind_nifty50list.csv\")\n\n# View the first few rows to understand the data structure\nhead(ticker_list[,1:3], 5)\n\n                                Company.Name           Industry     Symbol\n1                     Adani Enterprises Ltd.    Metals & Mining   ADANIENT\n2 Adani Ports and Special Economic Zone Ltd.           Services ADANIPORTS\n3           Apollo Hospitals Enterprise Ltd.         Healthcare APOLLOHOSP\n4                          Asian Paints Ltd.  Consumer Durables ASIANPAINT\n5                             Axis Bank Ltd. Financial Services   AXISBANK\n\n\n\n\n\nNow we’ll download historical price data for these stocks using the quantmod package, which provides an interface to Yahoo Finance:\n\n# Append \".NS\" to tickers for Yahoo Finance format (NS = National Stock Exchange)\ntickers &lt;- paste0(ticker_list$Symbol, \".NS\")\ntickers &lt;- tickers[!tickers %in% c(\"ETERNAL.NS\", \"JIOFIN.NS\")]\n\n# Initialize empty dataframe to store all ticker data\nticker_df &lt;- data.frame()\n\n# Create a progress bar to monitor the download process\n# pb &lt;- txtProgressBar(min = 1, max = length(tickers), style = 3)\n\n# Loop through each ticker and download its historical data\nfor(nms in tickers){\n  # Download data from Yahoo Finance\n  df &lt;- getSymbols(Symbols = nms, verbose = FALSE, auto.assign = FALSE)\n  \n  # Rename columns for clarity\n  colnames(df) &lt;- c(\"open\", \"high\", \"low\", \"close\", \"volume\", \"adjusted\")\n  df$date = rownames(df)\n  \n  # Convert to dataframe and add ticker and date information\n  df &lt;- data.frame(df)\n  df$ticker &lt;- nms\n  df$date &lt;- rownames(df)\n  \n  # Append to the main dataframe\n  ticker_df &lt;- rbind(ticker_df, df)\n  \n  Sys.sleep(0.2)\n  \n  # Update progress bar\n  # setTxtProgressBar(pb, which(tickers == nms))\n}\n\n# Reshape data to wide format with dates as rows and tickers as columns\n# This makes it easier to calculate returns across all stocks\nprices_df &lt;- pivot_wider(data = ticker_df, id_cols = \"date\", names_from = \"ticker\", values_from = \"close\")\n\n# Remove rows with missing values to ensure complete data\nprices_df &lt;- na.omit(prices_df)\n\n# Check the date range of our data\nrange(prices_df$date)\n\n[1] \"2017-11-17\" \"2025-04-17\"\n\n# Check dimensions (number of trading days × number of stocks + date column)\ndim(prices_df)\n\n[1] 1830   49\n\n\n\n\n\nBefore proceeding with analysis, it’s always good practice to visualize the data to check for anomalies and understand the general trends. Let’s visualize the price data for a subset of stocks (focusing on the metals industry):\n\n# Plot closing prices for metal stocks\nprices_df %&gt;% \n  # Convert from wide to long format for easier plotting with ggplot2\n  pivot_longer(-date, names_to = \"ticker\", values_to = \"price\") %&gt;% \n  \n  # Attach industry information from our original ticker list\n  left_join(ticker_list %&gt;% \n              mutate(ticker = paste0(Symbol, \".NS\")) %&gt;% \n              select(ticker, industry = Industry),\n            by = \"ticker\") %&gt;% \n  \n  # Convert date strings to Date objects\n  mutate(date = as.Date(date)) %&gt;% \n  \n  # Filter to show only metal industry stocks for clarity\n  filter(stringr::str_detect(tolower(industry), \"metal\")) %&gt;% \n  \n  # Create the line plot\n  ggplot(aes(x = date, y = price, color = ticker)) + \n  geom_line(linewidth = 0.8) + \n  theme_minimal() + \n  scale_color_brewer(palette = \"RdBu\") +  # Use a color-blind friendly palette\n  labs(title = \"Closing Prices\", \n       subtitle = \"Nifty 50 metal stocks\",\n       x = \"Date\", \n       y = \"Closing Price\") + \n  theme(legend.position = \"top\", \n        legend.title = element_text(colour = \"transparent\"), \n        axis.title.x = element_text(face = \"bold\"), \n        axis.title.y = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nClosing prices for metal stocks\n\n\nThe visualization shows the price movements of metal stocks over time. We can observe periods of both correlation and divergence between different stocks, highlighting the importance of diversification in portfolio construction.\n\n\n\nFor portfolio optimization, we need to work with returns rather than prices. Returns better represent the investment performance and have more desirable statistical properties (like stationarity):\n\n# Calculate daily returns for all stocks\n# Formula: (Price_today / Price_yesterday) - 1\nreturns_df &lt;- apply(prices_df[,-1], 2, function(vec){\n  ret &lt;- vec/lag(vec) - 1  # Simple returns calculation\n  return(ret)\n})\n\n# Convert to dataframe for easier manipulation\nreturns_df &lt;- as.data.frame(returns_df)\n\n# Remove first row which contains NA values (no previous day to calculate return)\nreturns_df &lt;- returns_df[-1,]  \n\n# Pre-compute average returns and covariance matrix for optimization\n# These are key inputs to the mean-variance optimization\nmean_returns &lt;- sapply(returns_df, mean)  # Expected returns\ncov_mat &lt;- cov(returns_df)  # Risk (covariance) matrix\n\nThe mean returns represent our expectations for each asset’s performance, while the covariance matrix captures both the individual volatilities and the relationships between assets. These will be the primary inputs to our optimization process.\n\n\n\n\n\n\nThe core of portfolio optimization is the objective function, which defines what we’re trying to maximize or minimize. In mean-variance optimization, we balance three key components:\n\nExpected returns (reward): The weighted average of expected returns for each asset\nPortfolio variance (risk): A measure of the portfolio’s volatility, calculated using the covariance matrix\nRisk aversion parameter: Controls the trade-off between risk and return (higher values prioritize risk reduction)\n\nWe’ll also incorporate constraints through penalty terms:\n\nobj_func &lt;- function(wts, \n                     risk_av = 10,  # Risk aversion parameter\n                     lambda1 = 10,  # Penalty weight for full investment constraint\n                     lambda2 = 1e2,  # Reserved for additional constraints\n                     ret_vec, cov_mat){\n  \n  # Calculate expected portfolio return (weighted average of asset returns)\n  port_returns &lt;- ret_vec %*% wts\n  \n  # Calculate portfolio risk (quadratic form using covariance matrix)\n  port_risk &lt;- t(wts) %*% cov_mat %*% wts\n  \n  # Mean-variance utility function: return - risk_aversion * risk\n  # This is the core Markowitz portfolio optimization formula\n  obj &lt;- port_returns - risk_av * port_risk\n  \n  # Add penalty for violating the full investment constraint (sum of weights = 1)\n  # The squared term ensures the penalty increases quadratically with violation size\n  obj &lt;- obj - lambda1 * (sum(wts) - 1)^2\n  \n  # Return negative value since PSO minimizes by default, but we want to maximize\n  # our objective (higher returns, lower risk)\n  return(-obj)\n}\n\nThis objective function implements the classic mean-variance utility with a quadratic penalty for the full investment constraint. The risk aversion parameter allows us to move along the efficient frontier to find portfolios with different risk-return profiles.\n\n\n\n\nBefore tackling the full portfolio optimization problem, let’s start with a simple two-asset example. This will help us visualize how PSO works and validate our approach:\n\n# Use only the first two assets for this example\n# Calculate their average returns and covariance matrix\nmean_returns_small &lt;- apply(returns_df[,1:2], 2, mean)\ncov_mat_small &lt;- cov(returns_df[,1:2])\n\n# Define a custom PSO optimizer function to track the optimization process\npso_optim &lt;- function(obj_func,\n                      c1 = 0.05,      # Cognitive parameter (personal best influence)\n                      c2 = 0.05,      # Social parameter (global best influence)\n                      w = 0.8,        # Inertia weight (controls momentum)\n                      init_fact = 0.1, # Initial velocity factor\n                      n_particles = 20, # Number of particles in the swarm\n                      n_dim = 2,       # Dimensionality (number of assets)\n                      n_iter = 50,     # Maximum iterations\n                      upper = 1,       # Upper bound for weights\n                      lower = 0,       # Lower bound for weights (no short selling)\n                      n_avg = 10,      # Number of iterations for averaging\n                      ...){\n  \n  # Initialize particle positions randomly within bounds\n  X &lt;- matrix(runif(n_particles * n_dim), nrow = n_particles)\n  X &lt;- X * (upper - lower) + lower  # Scale to fit within bounds\n  \n  # Initialize particle velocities (movement speeds)\n  dX &lt;- matrix(runif(n_particles * n_dim) * init_fact, ncol = n_dim)\n  dX &lt;- dX * (upper - lower) + lower\n  \n  # Initialize personal best positions and objective values\n  pbest &lt;- X  # Each particle's best position so far\n  pbest_obj &lt;- apply(X, 1, obj_func, ...)  # Objective value at personal best\n  \n  # Initialize global best position and objective value\n  gbest &lt;- pbest[which.min(pbest_obj),]  # Best position across all particles\n  gbest_obj &lt;- min(pbest_obj)  # Best objective value found\n  \n  # Store initial positions for visualization\n  loc_df &lt;- data.frame(X, iter = 0, obj = pbest_obj)\n  iter &lt;- 1\n  \n  # Main PSO loop\n  while(iter &lt; n_iter){\n    \n    # Update velocities using PSO formula:\n    # New velocity = inertia + cognitive component + social component\n    dX &lt;- w * dX +                         # Inertia (continue in same direction)\n          c1*runif(1)*(pbest - X) +        # Pull toward personal best\n          c2*runif(1)*t(gbest - t(X))      # Pull toward global best\n    \n    # Update positions based on velocities\n    X &lt;- X + dX\n    \n    # Evaluate objective function at new positions\n    obj &lt;- apply(X, 1, obj_func, ...)\n    \n    # Update personal bests if new positions are better\n    idx &lt;- which(obj &lt;= pbest_obj)\n    pbest[idx,] &lt;- X[idx,]\n    pbest_obj[idx] &lt;- obj[idx]\n    \n    # Update global best if a better solution is found\n    idx &lt;- which.min(pbest_obj)\n    gbest &lt;- pbest[idx,]\n    gbest_obj &lt;- min(pbest_obj)\n    \n    # Store current state for visualization\n    iter &lt;- iter + 1\n    loc_df &lt;- rbind(loc_df, data.frame(X, iter = iter, obj = pbest_obj))\n  }\n  \n  # Return optimization results\n  lst &lt;- list(X = loc_df,          # All particle positions throughout optimization\n              obj = gbest_obj,     # Best objective value found\n              obj_loc = gbest)     # Weights that achieved the best objective\n  return(lst)\n}\n\n# Run the optimization for our two-asset portfolio\nout &lt;- pso_optim(obj_func,\n                 ret_vec = mean_returns_small,  # Expected returns\n                 cov_mat = cov_mat_small,       # Covariance matrix\n                 lambda1 = 10, risk_av = 100,    # Constraint and risk parameters\n                 n_particles = 100,              # Use 100 particles for better coverage\n                 n_dim = 2,                      # Two-asset portfolio\n                 n_iter = 200,                   # Run for 200 iterations\n                 upper = 1, lower = 0,           # Bounds for weights\n                 c1 = 0.02, c2 = 0.02,           # Lower influence parameters for stability\n                 w = 0.05, init_fact = 0.01)     # Low inertia for better convergence\n\n# Verify that the weights sum to approximately 1 (full investment constraint)\nsum(out$obj_loc)\n\n[1] 0.9973249\n\n\nIn this implementation, we’re tracking the movement of all particles throughout the optimization process. This will allow us to visualize how the swarm converges toward the optimal solution.\n\n\nOne of the advantages of starting with a two-asset example is that we can visualize the entire search space and see how the PSO algorithm explores it. Let’s create a 3D visualization of the objective function landscape and the path each particle took during optimization:\n\n# Create a fine grid of points covering the feasible region (all possible weight combinations)\ngrid &lt;- expand.grid(x = seq(0, 1, by = 0.01),  # First asset weight from 0 to 1\n                    y = seq(0, 1, by = 0.01))   # Second asset weight from 0 to 1\n\n# Evaluate the objective function at each grid point to create the landscape\ngrid$obj &lt;- apply(grid, 1, obj_func, \n                  ret_vec = mean_returns_small, \n                  cov_mat = cov_mat_small, \n                  lambda1 = 10, risk_av = 100)\n\n# Create an interactive 3D plot showing both the objective function surface\n# and the particle trajectories throughout the optimization\np &lt;- plot_ly() %&gt;% \n  # Add the objective function surface as a mesh\n  add_mesh(data = grid, x = ~x, y = ~y, z = ~obj, \n           inherit = FALSE, color = \"red\") %&gt;% \n  \n  # Add particles as markers, colored by iteration to show progression\n  add_markers(data = out$X, x = ~X1, y = ~X2, z = ~obj, \n              color = ~ iter, inherit = FALSE, \n              marker = list(size = 2))\n\nThis visualization shows: 1. The objective function landscape as a 3D surface 2. The particles (small dots) exploring the search space 3. How the swarm converges toward the optimal solution over iterations (color gradient)\nThe concentration of particles in certain regions shows where the algorithm found promising solutions. The global best solution is where the particles ultimately converge.\n\n\n\n\nNow that we understand the basic principles, let’s scale up to optimize a portfolio containing all the assets in our dataset. Instead of using our custom PSO implementation, we’ll leverage the more efficient psoptim function from the pso package:\n\n# Get the number of stocks in our dataset\nn_stocks &lt;- ncol(returns_df)\n\n# Run the PSO optimization for the full portfolio\nopt &lt;- psoptim(\n  # Initial particle positions (starting with equal weights)\n  par = rep(0, n_stocks),\n  \n  # Objective function to minimize\n  fn = obj_func,\n  \n  # Pass the expected returns and covariance matrix\n  ret_vec = mean_returns, \n  cov_mat = cov_mat,\n  \n  # Set constraint parameters\n  lambda1 = 10,  # Weight for full investment constraint\n  risk_av = 1000,  # Higher risk aversion for a more conservative portfolio\n  \n  # Set bounds for weights (no short selling allowed)\n  lower = rep(0, n_stocks),\n  upper = rep(1, n_stocks),\n  \n  # Configure the PSO algorithm\n  control = list(\n    maxit = 200,          # Maximum iterations\n    s = 100,               # Swarm size (number of particles)\n    maxit.stagnate = 500   # Stop if no improvement after this many iterations\n  )\n)\n\n# Calculate and display the expected return of the optimized portfolio\npaste(\"Portfolio returns:\", round(opt$par %*% mean_returns, 5))\n\n[1] \"Portfolio returns: 0.00063\"\n\n# Calculate and display the standard deviation (risk) of the optimized portfolio\npaste(\"Portfolio Std dev:\", round(sqrt(opt$par %*% cov_mat %*% opt$par), 5))\n\n[1] \"Portfolio Std dev: 0.00888\"\n\n# Verify that the weights sum to approximately 1 (full investment constraint)\nsum(opt$par)\n\n[1] 0.9915935\n\n\nThe optimization has found a portfolio allocation that balances return and risk according to our specified risk aversion parameter. The high risk aversion value (1000) means we’re prioritizing risk reduction over return maximization.\n\n\n\nOne of the advantages of PSO is its flexibility in handling various constraints. Let’s demonstrate this by adding a tracking error constraint, which is common in institutional portfolio management. Tracking error measures how closely a portfolio follows a benchmark:\n\n# Define benchmark portfolio (equally weighted across all stocks)\nbench_wts &lt;- rep(1/n_stocks, n_stocks)\n\n# Calculate the time series of benchmark returns\nbench_returns &lt;- as.matrix(returns_df) %*% t(t(bench_wts))\n\n# Create a new objective function that includes tracking error\nobj_func_TE &lt;- function(wts,  \n                        risk_av = 10,     # Risk aversion parameter\n                        lambda1 = 10,    # Full investment constraint weight\n                        lambda2 = 50,    # Tracking error constraint weight\n                        ret_vec, cov_mat){\n  \n  # Calculate portfolio metrics\n  port_returns &lt;- ret_vec %*% wts                      # Expected portfolio return\n  port_risk &lt;- t(wts) %*% cov_mat %*% wts             # Portfolio variance\n  port_returns_ts &lt;- as.matrix(returns_df) %*% t(t(wts))  # Time series of portfolio returns\n  \n  # Original mean-variance objective\n  obj &lt;- port_returns - risk_av * port_risk\n  \n  # Full investment constraint (weights sum to 1)\n  obj &lt;- obj - lambda1 * (sum(wts) - 1)^2\n  \n  # Tracking error constraint (penalize deviation from benchmark)\n  # Tracking error is measured as the standard deviation of the difference\n  # between portfolio returns and benchmark returns\n  obj &lt;- obj - lambda2 * sd(port_returns_ts - bench_returns)\n  \n  return(-obj)  # Return negative for minimization\n}\n\n# Run optimization with the tracking error constraint\nopt &lt;- psoptim(\n  # Initial particle positions\n  par = rep(0, n_stocks),\n  \n  # Use our new objective function with tracking error\n  fn = obj_func_TE,\n  \n  # Pass the expected returns and covariance matrix\n  ret_vec = mean_returns, \n  cov_mat = cov_mat,\n  \n  # Set constraint parameters\n  lambda1 = 10,    # Weight for full investment constraint\n  risk_av = 1000,  # Risk aversion parameter\n  \n  # Set bounds for weights\n  lower = rep(0, n_stocks),\n  upper = rep(1, n_stocks),\n  \n  # Configure the PSO algorithm\n  control = list(\n    maxit = 200,          # Maximum iterations\n    s = 100,               # Swarm size\n    maxit.stagnate = 500   # Stop if no improvement after this many iterations\n  )\n)\n\n# Calculate and display the expected return of the optimized portfolio\npaste(\"Portfolio returns:\", round(opt$par %*% mean_returns, 5))\n\n[1] \"Portfolio returns: 0.00076\"\n\n# Calculate and display the standard deviation (risk) of the optimized portfolio\npaste(\"Portfolio Std dev:\", round(sqrt(opt$par %*% cov_mat %*% opt$par), 5))\n\n[1] \"Portfolio Std dev: 0.01102\"\n\n# Verify that the weights sum to approximately 1\nsum(opt$par)\n\n[1] 0.9944118\n\n\nBy adding the tracking error constraint, we’ve created a portfolio that not only balances risk and return but also tracks the performance of an equally-weighted benchmark to a specified degree. The lambda2 parameter controls how closely we want to track the benchmark - higher values will result in portfolios that more closely resemble the benchmark.\n\n\n\n\n\n\nFlexibility: PSO can handle non-convex, non-differentiable objective functions, making it suitable for complex portfolio constraints that traditional optimizers struggle with\nSimplicity: The algorithm is intuitive and relatively easy to implement compared to other global optimization techniques\nConstraints: Various constraints can be easily incorporated through penalty functions without reformulating the entire problem\nGlobal Search: PSO explores the search space more thoroughly and is less likely to get stuck in local optima compared to gradient-based methods\nParallelization: The algorithm is naturally parallelizable, as particles can be evaluated independently\n\n\n\n\n\nVariability: Results can vary between runs due to the stochastic nature of the algorithm, potentially leading to inconsistent portfolio recommendations\nParameter Tuning: Performance significantly depends on parameters like inertia weight and acceleration coefficients, which may require careful tuning\nConvergence: There’s no mathematical guarantee of convergence to the global optimum, unlike some convex optimization methods\nComputational Cost: Can be computationally intensive for high-dimensional problems with many assets\nConstraint Handling: While flexible, the penalty function approach may not always satisfy constraints exactly\n\n\n\n\n\nPSO-based portfolio optimization is particularly valuable in scenarios where:\n\nTraditional quadratic programming approaches fail due to complex constraints\nThe objective function includes non-linear terms like higher moments (skewness, kurtosis)\nMultiple competing objectives need to be balanced\nThe portfolio needs to satisfy regulatory or client-specific constraints\n\n\n\n\nParticle Swarm Optimization provides a powerful and flexible approach to portfolio optimization that can overcome many limitations of traditional methods. It can handle complex objective functions and constraints that might be difficult to solve with classical optimization techniques.\nThe approach demonstrated in this post can be extended to include additional constraints such as:\n\nSector or industry exposure limits\nMaximum position sizes\nTurnover or transaction cost constraints\nRisk factor exposures and limits\nCardinality constraints (limiting the number of assets)\n\nFor more robust results in practice, consider these enhancements:\n\nRun the algorithm multiple times with different random seeds and average the results\nImplement a hybrid approach that uses PSO for global exploration followed by a local optimizer for refinement\nAdd constraints gradually to better understand their impact on the portfolio\n\nPSO represents just one of many metaheuristic approaches that can be applied to portfolio optimization. Other techniques like genetic algorithms, simulated annealing, or differential evolution might also be worth exploring depending on your specific requirements."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#required-libraries",
    "href": "posts/particle-swarm-optimization.html#required-libraries",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "Before we begin, let’s load the R packages we’ll need for this analysis:\n\n# Load required packages\nlibrary(pso)       # For PSO implementation (provides psoptim function)\nlibrary(ggplot2)   # For data visualization\nlibrary(dplyr)     # For data manipulation and transformation\nlibrary(quantmod)  # For downloading financial data\nlibrary(tidyr)     # For reshaping data (pivot_wider, gather functions)\nlibrary(plotly)    # For creating interactive 3D visualizations"
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#data-collection-and-preparation",
    "href": "posts/particle-swarm-optimization.html#data-collection-and-preparation",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "The first step in portfolio optimization is gathering the necessary data. We’ll need historical price data to calculate returns and risk metrics.\n\n\nFor this demonstration, we’ll use stocks from the NIFTY50 index, which includes the 50 largest Indian companies by market capitalization:\n\n# Read ticker list from NSE (National Stock Exchange of India) website\nticker_list &lt;- read.csv(\"https://raw.githubusercontent.com/royr2/datasets/refs/heads/main/ind_nifty50list.csv\")\n\n# View the first few rows to understand the data structure\nhead(ticker_list[,1:3], 5)\n\n                                Company.Name           Industry     Symbol\n1                     Adani Enterprises Ltd.    Metals & Mining   ADANIENT\n2 Adani Ports and Special Economic Zone Ltd.           Services ADANIPORTS\n3           Apollo Hospitals Enterprise Ltd.         Healthcare APOLLOHOSP\n4                          Asian Paints Ltd.  Consumer Durables ASIANPAINT\n5                             Axis Bank Ltd. Financial Services   AXISBANK\n\n\n\n\n\nNow we’ll download historical price data for these stocks using the quantmod package, which provides an interface to Yahoo Finance:\n\n# Append \".NS\" to tickers for Yahoo Finance format (NS = National Stock Exchange)\ntickers &lt;- paste0(ticker_list$Symbol, \".NS\")\ntickers &lt;- tickers[!tickers %in% c(\"ETERNAL.NS\", \"JIOFIN.NS\")]\n\n# Initialize empty dataframe to store all ticker data\nticker_df &lt;- data.frame()\n\n# Create a progress bar to monitor the download process\n# pb &lt;- txtProgressBar(min = 1, max = length(tickers), style = 3)\n\n# Loop through each ticker and download its historical data\nfor(nms in tickers){\n  # Download data from Yahoo Finance\n  df &lt;- getSymbols(Symbols = nms, verbose = FALSE, auto.assign = FALSE)\n  \n  # Rename columns for clarity\n  colnames(df) &lt;- c(\"open\", \"high\", \"low\", \"close\", \"volume\", \"adjusted\")\n  df$date = rownames(df)\n  \n  # Convert to dataframe and add ticker and date information\n  df &lt;- data.frame(df)\n  df$ticker &lt;- nms\n  df$date &lt;- rownames(df)\n  \n  # Append to the main dataframe\n  ticker_df &lt;- rbind(ticker_df, df)\n  \n  Sys.sleep(0.2)\n  \n  # Update progress bar\n  # setTxtProgressBar(pb, which(tickers == nms))\n}\n\n# Reshape data to wide format with dates as rows and tickers as columns\n# This makes it easier to calculate returns across all stocks\nprices_df &lt;- pivot_wider(data = ticker_df, id_cols = \"date\", names_from = \"ticker\", values_from = \"close\")\n\n# Remove rows with missing values to ensure complete data\nprices_df &lt;- na.omit(prices_df)\n\n# Check the date range of our data\nrange(prices_df$date)\n\n[1] \"2017-11-17\" \"2025-04-17\"\n\n# Check dimensions (number of trading days × number of stocks + date column)\ndim(prices_df)\n\n[1] 1830   49\n\n\n\n\n\nBefore proceeding with analysis, it’s always good practice to visualize the data to check for anomalies and understand the general trends. Let’s visualize the price data for a subset of stocks (focusing on the metals industry):\n\n# Plot closing prices for metal stocks\nprices_df %&gt;% \n  # Convert from wide to long format for easier plotting with ggplot2\n  pivot_longer(-date, names_to = \"ticker\", values_to = \"price\") %&gt;% \n  \n  # Attach industry information from our original ticker list\n  left_join(ticker_list %&gt;% \n              mutate(ticker = paste0(Symbol, \".NS\")) %&gt;% \n              select(ticker, industry = Industry),\n            by = \"ticker\") %&gt;% \n  \n  # Convert date strings to Date objects\n  mutate(date = as.Date(date)) %&gt;% \n  \n  # Filter to show only metal industry stocks for clarity\n  filter(stringr::str_detect(tolower(industry), \"metal\")) %&gt;% \n  \n  # Create the line plot\n  ggplot(aes(x = date, y = price, color = ticker)) + \n  geom_line(linewidth = 0.8) + \n  theme_minimal() + \n  scale_color_brewer(palette = \"RdBu\") +  # Use a color-blind friendly palette\n  labs(title = \"Closing Prices\", \n       subtitle = \"Nifty 50 metal stocks\",\n       x = \"Date\", \n       y = \"Closing Price\") + \n  theme(legend.position = \"top\", \n        legend.title = element_text(colour = \"transparent\"), \n        axis.title.x = element_text(face = \"bold\"), \n        axis.title.y = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nClosing prices for metal stocks\n\n\nThe visualization shows the price movements of metal stocks over time. We can observe periods of both correlation and divergence between different stocks, highlighting the importance of diversification in portfolio construction.\n\n\n\nFor portfolio optimization, we need to work with returns rather than prices. Returns better represent the investment performance and have more desirable statistical properties (like stationarity):\n\n# Calculate daily returns for all stocks\n# Formula: (Price_today / Price_yesterday) - 1\nreturns_df &lt;- apply(prices_df[,-1], 2, function(vec){\n  ret &lt;- vec/lag(vec) - 1  # Simple returns calculation\n  return(ret)\n})\n\n# Convert to dataframe for easier manipulation\nreturns_df &lt;- as.data.frame(returns_df)\n\n# Remove first row which contains NA values (no previous day to calculate return)\nreturns_df &lt;- returns_df[-1,]  \n\n# Pre-compute average returns and covariance matrix for optimization\n# These are key inputs to the mean-variance optimization\nmean_returns &lt;- sapply(returns_df, mean)  # Expected returns\ncov_mat &lt;- cov(returns_df)  # Risk (covariance) matrix\n\nThe mean returns represent our expectations for each asset’s performance, while the covariance matrix captures both the individual volatilities and the relationships between assets. These will be the primary inputs to our optimization process."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#portfolio-optimization-framework",
    "href": "posts/particle-swarm-optimization.html#portfolio-optimization-framework",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "The core of portfolio optimization is the objective function, which defines what we’re trying to maximize or minimize. In mean-variance optimization, we balance three key components:\n\nExpected returns (reward): The weighted average of expected returns for each asset\nPortfolio variance (risk): A measure of the portfolio’s volatility, calculated using the covariance matrix\nRisk aversion parameter: Controls the trade-off between risk and return (higher values prioritize risk reduction)\n\nWe’ll also incorporate constraints through penalty terms:\n\nobj_func &lt;- function(wts, \n                     risk_av = 10,  # Risk aversion parameter\n                     lambda1 = 10,  # Penalty weight for full investment constraint\n                     lambda2 = 1e2,  # Reserved for additional constraints\n                     ret_vec, cov_mat){\n  \n  # Calculate expected portfolio return (weighted average of asset returns)\n  port_returns &lt;- ret_vec %*% wts\n  \n  # Calculate portfolio risk (quadratic form using covariance matrix)\n  port_risk &lt;- t(wts) %*% cov_mat %*% wts\n  \n  # Mean-variance utility function: return - risk_aversion * risk\n  # This is the core Markowitz portfolio optimization formula\n  obj &lt;- port_returns - risk_av * port_risk\n  \n  # Add penalty for violating the full investment constraint (sum of weights = 1)\n  # The squared term ensures the penalty increases quadratically with violation size\n  obj &lt;- obj - lambda1 * (sum(wts) - 1)^2\n  \n  # Return negative value since PSO minimizes by default, but we want to maximize\n  # our objective (higher returns, lower risk)\n  return(-obj)\n}\n\nThis objective function implements the classic mean-variance utility with a quadratic penalty for the full investment constraint. The risk aversion parameter allows us to move along the efficient frontier to find portfolios with different risk-return profiles."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#two-asset-example",
    "href": "posts/particle-swarm-optimization.html#two-asset-example",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "Before tackling the full portfolio optimization problem, let’s start with a simple two-asset example. This will help us visualize how PSO works and validate our approach:\n\n# Use only the first two assets for this example\n# Calculate their average returns and covariance matrix\nmean_returns_small &lt;- apply(returns_df[,1:2], 2, mean)\ncov_mat_small &lt;- cov(returns_df[,1:2])\n\n# Define a custom PSO optimizer function to track the optimization process\npso_optim &lt;- function(obj_func,\n                      c1 = 0.05,      # Cognitive parameter (personal best influence)\n                      c2 = 0.05,      # Social parameter (global best influence)\n                      w = 0.8,        # Inertia weight (controls momentum)\n                      init_fact = 0.1, # Initial velocity factor\n                      n_particles = 20, # Number of particles in the swarm\n                      n_dim = 2,       # Dimensionality (number of assets)\n                      n_iter = 50,     # Maximum iterations\n                      upper = 1,       # Upper bound for weights\n                      lower = 0,       # Lower bound for weights (no short selling)\n                      n_avg = 10,      # Number of iterations for averaging\n                      ...){\n  \n  # Initialize particle positions randomly within bounds\n  X &lt;- matrix(runif(n_particles * n_dim), nrow = n_particles)\n  X &lt;- X * (upper - lower) + lower  # Scale to fit within bounds\n  \n  # Initialize particle velocities (movement speeds)\n  dX &lt;- matrix(runif(n_particles * n_dim) * init_fact, ncol = n_dim)\n  dX &lt;- dX * (upper - lower) + lower\n  \n  # Initialize personal best positions and objective values\n  pbest &lt;- X  # Each particle's best position so far\n  pbest_obj &lt;- apply(X, 1, obj_func, ...)  # Objective value at personal best\n  \n  # Initialize global best position and objective value\n  gbest &lt;- pbest[which.min(pbest_obj),]  # Best position across all particles\n  gbest_obj &lt;- min(pbest_obj)  # Best objective value found\n  \n  # Store initial positions for visualization\n  loc_df &lt;- data.frame(X, iter = 0, obj = pbest_obj)\n  iter &lt;- 1\n  \n  # Main PSO loop\n  while(iter &lt; n_iter){\n    \n    # Update velocities using PSO formula:\n    # New velocity = inertia + cognitive component + social component\n    dX &lt;- w * dX +                         # Inertia (continue in same direction)\n          c1*runif(1)*(pbest - X) +        # Pull toward personal best\n          c2*runif(1)*t(gbest - t(X))      # Pull toward global best\n    \n    # Update positions based on velocities\n    X &lt;- X + dX\n    \n    # Evaluate objective function at new positions\n    obj &lt;- apply(X, 1, obj_func, ...)\n    \n    # Update personal bests if new positions are better\n    idx &lt;- which(obj &lt;= pbest_obj)\n    pbest[idx,] &lt;- X[idx,]\n    pbest_obj[idx] &lt;- obj[idx]\n    \n    # Update global best if a better solution is found\n    idx &lt;- which.min(pbest_obj)\n    gbest &lt;- pbest[idx,]\n    gbest_obj &lt;- min(pbest_obj)\n    \n    # Store current state for visualization\n    iter &lt;- iter + 1\n    loc_df &lt;- rbind(loc_df, data.frame(X, iter = iter, obj = pbest_obj))\n  }\n  \n  # Return optimization results\n  lst &lt;- list(X = loc_df,          # All particle positions throughout optimization\n              obj = gbest_obj,     # Best objective value found\n              obj_loc = gbest)     # Weights that achieved the best objective\n  return(lst)\n}\n\n# Run the optimization for our two-asset portfolio\nout &lt;- pso_optim(obj_func,\n                 ret_vec = mean_returns_small,  # Expected returns\n                 cov_mat = cov_mat_small,       # Covariance matrix\n                 lambda1 = 10, risk_av = 100,    # Constraint and risk parameters\n                 n_particles = 100,              # Use 100 particles for better coverage\n                 n_dim = 2,                      # Two-asset portfolio\n                 n_iter = 200,                   # Run for 200 iterations\n                 upper = 1, lower = 0,           # Bounds for weights\n                 c1 = 0.02, c2 = 0.02,           # Lower influence parameters for stability\n                 w = 0.05, init_fact = 0.01)     # Low inertia for better convergence\n\n# Verify that the weights sum to approximately 1 (full investment constraint)\nsum(out$obj_loc)\n\n[1] 0.9973249\n\n\nIn this implementation, we’re tracking the movement of all particles throughout the optimization process. This will allow us to visualize how the swarm converges toward the optimal solution.\n\n\nOne of the advantages of starting with a two-asset example is that we can visualize the entire search space and see how the PSO algorithm explores it. Let’s create a 3D visualization of the objective function landscape and the path each particle took during optimization:\n\n# Create a fine grid of points covering the feasible region (all possible weight combinations)\ngrid &lt;- expand.grid(x = seq(0, 1, by = 0.01),  # First asset weight from 0 to 1\n                    y = seq(0, 1, by = 0.01))   # Second asset weight from 0 to 1\n\n# Evaluate the objective function at each grid point to create the landscape\ngrid$obj &lt;- apply(grid, 1, obj_func, \n                  ret_vec = mean_returns_small, \n                  cov_mat = cov_mat_small, \n                  lambda1 = 10, risk_av = 100)\n\n# Create an interactive 3D plot showing both the objective function surface\n# and the particle trajectories throughout the optimization\np &lt;- plot_ly() %&gt;% \n  # Add the objective function surface as a mesh\n  add_mesh(data = grid, x = ~x, y = ~y, z = ~obj, \n           inherit = FALSE, color = \"red\") %&gt;% \n  \n  # Add particles as markers, colored by iteration to show progression\n  add_markers(data = out$X, x = ~X1, y = ~X2, z = ~obj, \n              color = ~ iter, inherit = FALSE, \n              marker = list(size = 2))\n\nThis visualization shows: 1. The objective function landscape as a 3D surface 2. The particles (small dots) exploring the search space 3. How the swarm converges toward the optimal solution over iterations (color gradient)\nThe concentration of particles in certain regions shows where the algorithm found promising solutions. The global best solution is where the particles ultimately converge."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#multi-asset-portfolio-optimization",
    "href": "posts/particle-swarm-optimization.html#multi-asset-portfolio-optimization",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "Now that we understand the basic principles, let’s scale up to optimize a portfolio containing all the assets in our dataset. Instead of using our custom PSO implementation, we’ll leverage the more efficient psoptim function from the pso package:\n\n# Get the number of stocks in our dataset\nn_stocks &lt;- ncol(returns_df)\n\n# Run the PSO optimization for the full portfolio\nopt &lt;- psoptim(\n  # Initial particle positions (starting with equal weights)\n  par = rep(0, n_stocks),\n  \n  # Objective function to minimize\n  fn = obj_func,\n  \n  # Pass the expected returns and covariance matrix\n  ret_vec = mean_returns, \n  cov_mat = cov_mat,\n  \n  # Set constraint parameters\n  lambda1 = 10,  # Weight for full investment constraint\n  risk_av = 1000,  # Higher risk aversion for a more conservative portfolio\n  \n  # Set bounds for weights (no short selling allowed)\n  lower = rep(0, n_stocks),\n  upper = rep(1, n_stocks),\n  \n  # Configure the PSO algorithm\n  control = list(\n    maxit = 200,          # Maximum iterations\n    s = 100,               # Swarm size (number of particles)\n    maxit.stagnate = 500   # Stop if no improvement after this many iterations\n  )\n)\n\n# Calculate and display the expected return of the optimized portfolio\npaste(\"Portfolio returns:\", round(opt$par %*% mean_returns, 5))\n\n[1] \"Portfolio returns: 0.00063\"\n\n# Calculate and display the standard deviation (risk) of the optimized portfolio\npaste(\"Portfolio Std dev:\", round(sqrt(opt$par %*% cov_mat %*% opt$par), 5))\n\n[1] \"Portfolio Std dev: 0.00888\"\n\n# Verify that the weights sum to approximately 1 (full investment constraint)\nsum(opt$par)\n\n[1] 0.9915935\n\n\nThe optimization has found a portfolio allocation that balances return and risk according to our specified risk aversion parameter. The high risk aversion value (1000) means we’re prioritizing risk reduction over return maximization."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#adding-tracking-error-constraint",
    "href": "posts/particle-swarm-optimization.html#adding-tracking-error-constraint",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "One of the advantages of PSO is its flexibility in handling various constraints. Let’s demonstrate this by adding a tracking error constraint, which is common in institutional portfolio management. Tracking error measures how closely a portfolio follows a benchmark:\n\n# Define benchmark portfolio (equally weighted across all stocks)\nbench_wts &lt;- rep(1/n_stocks, n_stocks)\n\n# Calculate the time series of benchmark returns\nbench_returns &lt;- as.matrix(returns_df) %*% t(t(bench_wts))\n\n# Create a new objective function that includes tracking error\nobj_func_TE &lt;- function(wts,  \n                        risk_av = 10,     # Risk aversion parameter\n                        lambda1 = 10,    # Full investment constraint weight\n                        lambda2 = 50,    # Tracking error constraint weight\n                        ret_vec, cov_mat){\n  \n  # Calculate portfolio metrics\n  port_returns &lt;- ret_vec %*% wts                      # Expected portfolio return\n  port_risk &lt;- t(wts) %*% cov_mat %*% wts             # Portfolio variance\n  port_returns_ts &lt;- as.matrix(returns_df) %*% t(t(wts))  # Time series of portfolio returns\n  \n  # Original mean-variance objective\n  obj &lt;- port_returns - risk_av * port_risk\n  \n  # Full investment constraint (weights sum to 1)\n  obj &lt;- obj - lambda1 * (sum(wts) - 1)^2\n  \n  # Tracking error constraint (penalize deviation from benchmark)\n  # Tracking error is measured as the standard deviation of the difference\n  # between portfolio returns and benchmark returns\n  obj &lt;- obj - lambda2 * sd(port_returns_ts - bench_returns)\n  \n  return(-obj)  # Return negative for minimization\n}\n\n# Run optimization with the tracking error constraint\nopt &lt;- psoptim(\n  # Initial particle positions\n  par = rep(0, n_stocks),\n  \n  # Use our new objective function with tracking error\n  fn = obj_func_TE,\n  \n  # Pass the expected returns and covariance matrix\n  ret_vec = mean_returns, \n  cov_mat = cov_mat,\n  \n  # Set constraint parameters\n  lambda1 = 10,    # Weight for full investment constraint\n  risk_av = 1000,  # Risk aversion parameter\n  \n  # Set bounds for weights\n  lower = rep(0, n_stocks),\n  upper = rep(1, n_stocks),\n  \n  # Configure the PSO algorithm\n  control = list(\n    maxit = 200,          # Maximum iterations\n    s = 100,               # Swarm size\n    maxit.stagnate = 500   # Stop if no improvement after this many iterations\n  )\n)\n\n# Calculate and display the expected return of the optimized portfolio\npaste(\"Portfolio returns:\", round(opt$par %*% mean_returns, 5))\n\n[1] \"Portfolio returns: 0.00076\"\n\n# Calculate and display the standard deviation (risk) of the optimized portfolio\npaste(\"Portfolio Std dev:\", round(sqrt(opt$par %*% cov_mat %*% opt$par), 5))\n\n[1] \"Portfolio Std dev: 0.01102\"\n\n# Verify that the weights sum to approximately 1\nsum(opt$par)\n\n[1] 0.9944118\n\n\nBy adding the tracking error constraint, we’ve created a portfolio that not only balances risk and return but also tracks the performance of an equally-weighted benchmark to a specified degree. The lambda2 parameter controls how closely we want to track the benchmark - higher values will result in portfolios that more closely resemble the benchmark."
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#advantages-and-limitations-of-pso",
    "href": "posts/particle-swarm-optimization.html#advantages-and-limitations-of-pso",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "Flexibility: PSO can handle non-convex, non-differentiable objective functions, making it suitable for complex portfolio constraints that traditional optimizers struggle with\nSimplicity: The algorithm is intuitive and relatively easy to implement compared to other global optimization techniques\nConstraints: Various constraints can be easily incorporated through penalty functions without reformulating the entire problem\nGlobal Search: PSO explores the search space more thoroughly and is less likely to get stuck in local optima compared to gradient-based methods\nParallelization: The algorithm is naturally parallelizable, as particles can be evaluated independently\n\n\n\n\n\nVariability: Results can vary between runs due to the stochastic nature of the algorithm, potentially leading to inconsistent portfolio recommendations\nParameter Tuning: Performance significantly depends on parameters like inertia weight and acceleration coefficients, which may require careful tuning\nConvergence: There’s no mathematical guarantee of convergence to the global optimum, unlike some convex optimization methods\nComputational Cost: Can be computationally intensive for high-dimensional problems with many assets\nConstraint Handling: While flexible, the penalty function approach may not always satisfy constraints exactly"
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#practical-applications",
    "href": "posts/particle-swarm-optimization.html#practical-applications",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "PSO-based portfolio optimization is particularly valuable in scenarios where:\n\nTraditional quadratic programming approaches fail due to complex constraints\nThe objective function includes non-linear terms like higher moments (skewness, kurtosis)\nMultiple competing objectives need to be balanced\nThe portfolio needs to satisfy regulatory or client-specific constraints"
  },
  {
    "objectID": "posts/particle-swarm-optimization.html#conclusion",
    "href": "posts/particle-swarm-optimization.html#conclusion",
    "title": "Portfolio Optimization Using Particle Swarm Optimization in R",
    "section": "",
    "text": "Particle Swarm Optimization provides a powerful and flexible approach to portfolio optimization that can overcome many limitations of traditional methods. It can handle complex objective functions and constraints that might be difficult to solve with classical optimization techniques.\nThe approach demonstrated in this post can be extended to include additional constraints such as:\n\nSector or industry exposure limits\nMaximum position sizes\nTurnover or transaction cost constraints\nRisk factor exposures and limits\nCardinality constraints (limiting the number of assets)\n\nFor more robust results in practice, consider these enhancements:\n\nRun the algorithm multiple times with different random seeds and average the results\nImplement a hybrid approach that uses PSO for global exploration followed by a local optimizer for refinement\nAdd constraints gradually to better understand their impact on the portfolio\n\nPSO represents just one of many metaheuristic approaches that can be applied to portfolio optimization. Other techniques like genetic algorithms, simulated annealing, or differential evolution might also be worth exploring depending on your specific requirements."
  }
]